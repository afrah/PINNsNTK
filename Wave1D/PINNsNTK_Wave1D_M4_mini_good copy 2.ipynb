{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7WkCgnRiYQSY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from Compute_Jacobian import jacobian # Please download 'Compute_Jacobian.py' in the repository \n",
        "import numpy as np\n",
        "import timeit\n",
        "from scipy.interpolate import griddata\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "os.environ[\"KMP_WARNINGS\"] = \"FALSE\" \n",
        "import timeit\n",
        "\n",
        "import sys\n",
        "\n",
        "import scipy\n",
        "import scipy.io\n",
        "import time\n",
        "class Sampler:\n",
        "    # Initialize the class\n",
        "    def __init__(self, dim, coords, func, name = None):\n",
        "        self.dim = dim\n",
        "        self.coords = coords\n",
        "        self.func = func\n",
        "        self.name = name\n",
        "    def sample(self, N):\n",
        "        x = self.coords[0:1,:] + (self.coords[1:2,:]-self.coords[0:1,:])*np.random.rand(N, self.dim)\n",
        "        y = self.func(x)\n",
        "        return x, y\n",
        "\n",
        "# Define the exact solution and its derivatives\n",
        "def u(x, a, c):\n",
        "    \"\"\"\n",
        "    :param x: x = (t, x)\n",
        "    \"\"\"\n",
        "    t = x[:,0:1]\n",
        "    x = x[:,1:2]\n",
        "    return np.sin(np.pi * x) * np.cos(c * np.pi * t) + a * np.sin(2 * c * np.pi* x) * np.cos(4 * c  * np.pi * t)\n",
        "\n",
        "def u_t(x,a, c):\n",
        "    t = x[:,0:1]\n",
        "    x = x[:,1:2]\n",
        "    u_t = -  c * np.pi * np.sin(np.pi * x) * np.sin(c * np.pi * t) -  a * 4 * c * np.pi * np.sin(2 * c * np.pi* x) * np.sin(4 * c * np.pi * t)\n",
        "    return u_t\n",
        "\n",
        "def u_tt(x, a, c):\n",
        "    t = x[:,0:1]\n",
        "    x = x[:,1:2]\n",
        "    u_tt = -(c * np.pi)**2 * np.sin( np.pi * x) * np.cos(c * np.pi * t) - a * (4 * c * np.pi)**2 *  np.sin(2 * c * np.pi* x) * np.cos(4 * c * np.pi * t)\n",
        "    return u_tt\n",
        "\n",
        "def u_xx(x, a, c):\n",
        "    t = x[:,0:1]\n",
        "    x = x[:,1:2]\n",
        "    u_xx = - np.pi**2 * np.sin( np.pi * x) * np.cos(c * np.pi * t) -  a * (2 * c * np.pi)** 2 * np.sin(2 * c * np.pi* x) * np.cos(4 * c * np.pi * t)\n",
        "    return  u_xx\n",
        "\n",
        "\n",
        "def r(x, a, c):\n",
        "    return u_tt(x, a, c) - c**2 * u_xx(x, a, c)\n",
        "\n",
        "def operator(u, t, x, c, sigma_t=1.0, sigma_x=1.0):\n",
        "    u_t = tf.gradients(u, t)[0] / sigma_t\n",
        "    u_x = tf.gradients(u, x)[0] / sigma_x\n",
        "    u_tt = tf.gradients(u_t, t)[0] / sigma_t\n",
        "    u_xx = tf.gradients(u_x, x)[0] / sigma_x\n",
        "    residual = u_tt - c**2 * u_xx\n",
        "    return residual\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-y7cHTcJfBTR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SDqDWN3nfSAg"
      },
      "outputs": [],
      "source": [
        "class PINN:\n",
        "    # Initialize the class\n",
        "    def __init__(self, layers, operator, ics_sampler, bcs_sampler, res_sampler, c, kernel_size , sess):\n",
        "        # Normalization \n",
        "        X, _ = res_sampler.sample(np.int32(1e5))\n",
        "        self.mu_X, self.sigma_X = X.mean(0), X.std(0)\n",
        "        self.mu_t, self.sigma_t = self.mu_X[0], self.sigma_X[0]\n",
        "        self.mu_x, self.sigma_x = self.mu_X[1], self.sigma_X[1]\n",
        "\n",
        "        self.activFun = 'xsig'\n",
        "        # Samplers\n",
        "        self.operator = operator\n",
        "        self.ics_sampler = ics_sampler\n",
        "        self.bcs_sampler = bcs_sampler\n",
        "        self.res_sampler = res_sampler\n",
        "\n",
        "        self.sess = sess\n",
        "        # Initialize network weights and biases\n",
        "        self.layers = layers\n",
        "        self.weights, self.biases = self.initialize_NN(layers)\n",
        "        \n",
        "        # weights\n",
        "        self.lam_u_val = np.array(2.0)\n",
        "        self.lam_ut_val = np.array(2.0)\n",
        "        self.lam_res_val = np.array(1.0)\n",
        "        self.lam_bc1_val = np.array(2.0)\n",
        "        self.lam_bc2_val = np.array(2.0)\n",
        "      \n",
        "        # Wave constant\n",
        "        self.c = tf.constant(c, dtype=tf.float32)\n",
        "        \n",
        "        self.kernel_size = kernel_size # Size of the NTK matrix\n",
        "\n",
        "        # Define Tensorflow session\n",
        "        self.sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
        "\n",
        "        # Define placeholders and computational graph\n",
        "        self.t_u_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.x_u_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "\n",
        "        self.t_ics_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.x_ics_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.u_ics_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "\n",
        "        self.t_bc1_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.x_bc1_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "\n",
        "        self.t_bc2_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.x_bc2_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "\n",
        "        self.t_r_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.x_r_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        \n",
        "        self.lam_u_tf = tf.placeholder(tf.float32, shape=self.lam_u_val.shape)\n",
        "        self.lam_ut_tf = tf.placeholder(tf.float32, shape=self.lam_u_val.shape)\n",
        "        # self.lam_r_tf = tf.placeholder(tf.float32, shape=self.lam_u_val.shape)\n",
        "        self.lam_bc_tf = tf.placeholder(tf.float32, shape=self.lam_bc1_val.shape)\n",
        "        # self.lam_bc2_tf = tf.placeholder(tf.float32, shape=self.lam_bc2_val.shape)\n",
        "        self.lam_res_tf = tf.placeholder(tf.float32, shape=self.lam_res_val.shape)\n",
        "\n",
        "\n",
        "        self.u_pred = self.net_u(self.t_u_tf, self.x_u_tf)\n",
        "\n",
        "\n",
        "        # Evaluate predictions\n",
        "        self.u_ics_pred = self.net_u(self.t_ics_tf, self.x_ics_tf)\n",
        "        self.u_bc1_pred = self.net_u(self.t_bc1_tf, self.x_bc1_tf)\n",
        "        self.u_bc2_pred = self.net_u(self.t_bc2_tf, self.x_bc2_tf)\n",
        "\n",
        "        self.r_pred = self.net_r(self.t_r_tf, self.x_r_tf)\n",
        "        \n",
        "        \n",
        "        # Boundary loss and Initial loss\n",
        "        self.loss_ics_u = tf.reduce_mean(tf.square(self.u_ics_tf - self.u_ics_pred))\n",
        "        self.loss_ics_ut = tf.reduce_mean(tf.square( tf.gradients(self.u_ics_pred, self.t_ics_tf)[0] / self.sigma_t) )\n",
        "        self.loss_bc1 = tf.reduce_mean(tf.square(self.u_bc1_pred)) #+ tf.reduce_mean(tf.square(self.u_bc2_pred))\n",
        "        self.loss_bc2 = tf.reduce_mean(tf.square(self.u_bc2_pred))\n",
        "\n",
        "        # Residual loss\n",
        "        self.loss_res = tf.reduce_mean(tf.square(self.r_pred))\n",
        "\n",
        "        # Total loss\n",
        "        self.loss =  self.lam_res_tf *self.loss_res + self.lam_bc_tf *( self.loss_bc1 + self.loss_bc2 )+ self.lam_u_tf * (self.loss_ics_u + self.loss_ics_ut )\n",
        "\n",
        "        # Define optimizer with learning rate schedule\n",
        "        self.global_step = tf.Variable(0, trainable=False)\n",
        "        starter_learning_rate = 1e-3\n",
        "        self.learning_rate = tf.train.exponential_decay(starter_learning_rate, self.global_step,  1000, 0.9, staircase=False)\n",
        "        # Passing global_step to minimize() will increment it at each step.\n",
        "        self.train_op = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss, global_step=self.global_step)\n",
        "        \n",
        "         # Initialize Tensorflow variables\n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess.run(init)\n",
        "\n",
        "    # Initialize network weights and biases using Xavier initialization\n",
        "    def initialize_NN(self, layers):\n",
        "        # Xavier initialization\n",
        "        def xavier_init(size):\n",
        "            in_dim = size[0]\n",
        "            out_dim = size[1]\n",
        "            xavier_stddev = 1. / np.sqrt((in_dim + out_dim) / 2.)\n",
        "            return tf.Variable(tf.random.normal([in_dim, out_dim], dtype=tf.float32) * xavier_stddev,  dtype=tf.float32)\n",
        "\n",
        "        weights = []\n",
        "        biases = []\n",
        "        num_layers = len(layers)\n",
        "        for l in range(0, num_layers - 1):\n",
        "            W = xavier_init(size=[layers[l], layers[l + 1]])\n",
        "            b = tf.Variable(tf.zeros([1, layers[l + 1]], dtype=tf.float32), dtype=tf.float32)\n",
        "            weights.append(W)\n",
        "            biases.append(b)\n",
        "        return weights, biases\n",
        "\n",
        "    # Evaluates the forward pass\n",
        "    def forward_pass(self, H, layers, weights, biases):\n",
        "        # num_layers = len(layers)\n",
        "        # for l in range(0, num_layers - 2):\n",
        "        #     W = weights[l]\n",
        "        #     b = biases[l]\n",
        "        #     # H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
        "        #     H =  H*tf.sigmoid(tf.add(tf.matmul(H, W), b))\n",
        "        # W = weights[-1]\n",
        "        # b = biases[-1]\n",
        "        # H = tf.add(tf.matmul(H, W), b)\n",
        "        # H = (tf.concat(inputs, 1) - self.X_mean)/self.X_std\n",
        "        num_layers = len(layers)\n",
        "        for l in range(0,num_layers-1):\n",
        "            W = weights[l]\n",
        "            b = biases[l]\n",
        "            V = W/tf.norm(W, axis = 0, keepdims=True)\n",
        "            H = tf.matmul(H, V)\n",
        "            H = H + b\n",
        "            if l < num_layers-2:\n",
        "                    if(self.activFun == 'xsig'):\n",
        "                        H = H*tf.sigmoid(H)\n",
        "                    elif self.activFun == 'hard_swish':\n",
        "                        H = H * tf.nn.relu6(H+3) * 0.16666667\n",
        "                    else:\n",
        "                        H = tf.tanh(H)\n",
        "                \n",
        "        Y = tf.split(H, num_or_size_splits=H.shape[1], axis=1)\n",
        "        return H\n",
        "################################################################################################\n",
        "    # Forward pass for u\n",
        "    def net_u(self, t, x):\n",
        "        u = self.forward_pass(tf.concat([t, x], 1),  self.layers, self.weights, self.biases)\n",
        "        return u\n",
        "\n",
        "    # Forward pass for du/dt\n",
        "    def net_u_t(self, t, x):\n",
        "        u_t = tf.gradients(self.net_u(t, x), t)[0] / self.sigma_t\n",
        "        return u_t\n",
        "\n",
        "    # Forward pass for the residual\n",
        "    def net_r(self, t, x):\n",
        "        u = self.net_u(t, x)\n",
        "        residual = self.operator(u, t, x, self.c, self.sigma_t,  self.sigma_x)\n",
        "        return residual\n",
        "    \n",
        "    \n",
        "\n",
        "    def fetch_minibatch(self, sampler, N):\n",
        "        X, Y = sampler.sample(N)\n",
        "        X = (X - self.mu_X) / self.sigma_X\n",
        "        return X, Y\n",
        "\n",
        "        # Trains the model by minimizing the MSE loss\n",
        "\n",
        "    def trainmb(self, nIter=10000, batch_size=128, log_NTK=False, update_lam=False):\n",
        "\n",
        "        start_time = timeit.default_timer()\n",
        "        for it in range(1 , nIter):\n",
        "            # Fetch boundary mini-batches\n",
        "            X_ics_batch, u_ics_batch = self.fetch_minibatch(self.ics_sampler, batch_size // 3)\n",
        "            X_bc1_batch, _ = self.fetch_minibatch(self.bcs_sampler[0], batch_size // 3)\n",
        "            X_bc2_batch, _ = self.fetch_minibatch(self.bcs_sampler[1], batch_size // 3)\n",
        "            \n",
        "            # Fetch residual mini-batch\n",
        "            X_res_batch, _ = self.fetch_minibatch(self.res_sampler, batch_size)\n",
        "            # Define a dictionary for associating placeholders with data\n",
        "            tf_dict = {self.t_ics_tf: X_ics_batch[:, 0:1], self.x_ics_tf: X_ics_batch[:, 1:2],\n",
        "                       self.u_ics_tf: u_ics_batch,\n",
        "                       self.t_bc1_tf: X_bc1_batch[:, 0:1], self.x_bc1_tf: X_bc1_batch[:, 1:2],\n",
        "                       self.t_bc2_tf: X_bc2_batch[:, 0:1], self.x_bc2_tf: X_bc2_batch[:, 1:2],\n",
        "                       self.t_r_tf: X_res_batch[:, 0:1], self.x_r_tf: X_res_batch[:, 1:2],\n",
        "                       self.lam_u_tf: self.lam_u_val,\n",
        "                       self.lam_bc_tf: self.lam_bc1_val,\n",
        "                    self.lam_res_tf: self.lam_res_val,\n",
        "                       }\n",
        "\n",
        "            # Run the Tensorflow session to minimize the loss\n",
        "            self.sess.run(self.train_op, tf_dict)\n",
        "\n",
        "            # Print\n",
        "            if it % 100 == 0:\n",
        "                elapsed = timeit.default_timer() - start_time\n",
        "\n",
        "                loss = self.sess.run(self.loss, tf_dict)\n",
        "                loss_bc1 = self.sess.run(self.loss_bc1, tf_dict)\n",
        "                # loss_bc2 = self.sess.run(self.loss_bc2, tf_dict)\n",
        "                loss_ics_u = self.sess.run(self.loss_ics_u, tf_dict)\n",
        "                loss_res = self.sess.run(self.loss_res, tf_dict)\n",
        "                \n",
        "                if it % 100 == 0:\n",
        "                    elapsed = timeit.default_timer() - start_time\n",
        "\n",
        "                    loss , loss_bc1 , loss_bc2 , loss_ics_u , loss_ics_ut , loss_res = self.sess.run( [self.loss  , self.loss_bc1 ,self.loss_bc2 , self.loss_ics_u, self.loss_ics_ut, self.loss_res ] , tf_dict)\n",
        "\n",
        "                    print('It: %d, Loss: %.3e,  loss_bc1: %.3e,  loss_bc2: %.3e, loss_ics_u: %.3e, loss_ics_ut: %.3e,  Loss_res: %.3e , Time: %.2f' %(it, loss, loss_bc1 , loss_bc2 , loss_ics_u, loss_ics_ut , loss_res , elapsed))\n",
        "                    \n",
        "    \n",
        "                    # start_time = timeit.default_timer()\n",
        "\n",
        "                    # self.loss_bc_avg += (loss_bc1 + loss_bc2 ) /self.count\n",
        "                    # self.loss_ics_u_avg += (loss_ics_u + loss_ics_ut )  /self.count\n",
        "                    # self.loss_res_avg += loss_res  /self.count\n",
        "                    # self.count +=1\n",
        "            \n",
        "                    if it % 100== 0: \n",
        "                            alpha   = 10000\n",
        "                            self.lam_bc_val = alpha *  1.0/(loss_bc1 + loss_bc2 )\n",
        "                            # self.lam_bc2_val = alpha * loss_bc2\n",
        "                            self.lam_u_val = alpha * 1.0/(loss_ics_u + loss_ics_ut )\n",
        "                            self.lam_res_val = 100 *1.0/loss_res\n",
        "                            \n",
        "                            print('loss_bc1: {:.3e}'.format(self.lam_bc_val))\n",
        "                            # print('loss_bc2: {:.3e}'.format(self.lam_bc2_val))\n",
        "                            print('loss_ics_u: {:.3e}'.format(self.lam_u_val))\n",
        "                            print('loss_res_val: {:.3e}'.format(self.lam_res_val))\n",
        "\n",
        "                sys.stdout.flush()\n",
        "\n",
        "\n",
        "    def train(self, nIter , bcbatch_size , ubatch_size):\n",
        "\n",
        "        start_time = timeit.default_timer()\n",
        "\n",
        "        # Fetch boundary mini-batches\n",
        "        X_ics_batch, u_ics_batch = self.fetch_minibatch(self.ics_sampler, bcbatch_size)\n",
        "        X_bc1_batch, _ = self.fetch_minibatch(self.bcs_sampler[0], bcbatch_size )\n",
        "        X_bc2_batch, _ = self.fetch_minibatch(self.bcs_sampler[1], bcbatch_size )\n",
        "        \n",
        "        # Fetch residual mini-batch\n",
        "        X_res_batch, _ = self.fetch_minibatch(self.res_sampler, ubatch_size)\n",
        "        # print(\"inside trainmb: \" , X_res_batch.shape)\n",
        "        # Define a dictionary for associating placeholders with data\n",
        "        tf_dict = {self.t_ics_tf: X_ics_batch[:, 0:1], self.x_ics_tf: X_ics_batch[:, 1:2],\n",
        "                    self.u_ics_tf: u_ics_batch,\n",
        "                    self.t_bc1_tf: X_bc1_batch[:, 0:1], self.x_bc1_tf: X_bc1_batch[:, 1:2],\n",
        "                    self.t_bc2_tf: X_bc2_batch[:, 0:1], self.x_bc2_tf: X_bc2_batch[:, 1:2],\n",
        "                    self.t_r_tf: X_res_batch[:, 0:1], self.x_r_tf: X_res_batch[:, 1:2],\n",
        "                    self.lam_u_tf: self.lam_u_val,\n",
        "                       self.lam_bc_tf: self.lam_bc1_val,\n",
        "                    self.lam_res_tf: self.lam_res_val,\n",
        "                    }\n",
        "        \n",
        "   \n",
        "  \n",
        "        for it in range(nIter):\n",
        "\n",
        "            # Run the Tensorflow session to minimize the loss\n",
        "            self.sess.run(self.train_op, tf_dict)\n",
        "\n",
        "          \n",
        "\n",
        "            if it % 100 == 0:\n",
        "                elapsed = timeit.default_timer() - start_time\n",
        "\n",
        "                loss , loss_bc1 , loss_bc2 , loss_ics_u , loss_ics_ut , loss_res = self.sess.run( [self.loss  , self.loss_bc1 ,self.loss_bc2 , self.loss_ics_u, self.loss_ics_ut, self.loss_res ] , tf_dict)\n",
        "\n",
        "                print('It: %d, Loss: %.3e,  loss_bc1: %.3e,  loss_bc2: %.3e, loss_ics_u: %.3e, loss_ics_ut: %.3e,  Loss_res: %.3e , Time: %.2f' %(it, loss, loss_bc1 , loss_bc2 , loss_ics_u, loss_ics_ut , loss_res , elapsed))\n",
        "                \n",
        "\n",
        "                # start_time = timeit.default_timer()\n",
        "\n",
        "                # self.loss_bc_avg += (loss_bc1 + loss_bc2 ) /self.count\n",
        "                # self.loss_ics_u_avg += (loss_ics_u + loss_ics_ut )  /self.count\n",
        "                # self.loss_res_avg += loss_res  /self.count\n",
        "                # self.count +=1\n",
        "        \n",
        "                if it % 100== 0: \n",
        "                        alpha   = 10000\n",
        "                        self.lam_bc_val = alpha *  (loss_bc1 + loss_bc2 )\n",
        "                        # self.lam_bc2_val = alpha * loss_bc2\n",
        "                        self.lam_u_val = alpha * (loss_ics_u + loss_ics_ut )\n",
        "                        self.lam_res_val = 100 *loss_res\n",
        "                        \n",
        "                        print('loss_bc1: {:.3e}'.format(self.lam_bc_val))\n",
        "                        # print('loss_bc2: {:.3e}'.format(self.lam_bc2_val))\n",
        "                        print('loss_ics_u: {:.3e}'.format(self.lam_u_val))\n",
        "                        print('loss_res_val: {:.3e}'.format(self.lam_res_val))\n",
        "\n",
        "            sys.stdout.flush()\n",
        "\n",
        "\n",
        "    # Evaluates predictions at test points\n",
        "    def predict_u(self, X_star):\n",
        "        X_star = (X_star - self.mu_X) / self.sigma_X\n",
        "        tf_dict = {self.t_u_tf: X_star[:, 0:1], self.x_u_tf: X_star[:, 1:2]}\n",
        "        u_star = self.sess.run(self.u_pred, tf_dict)\n",
        "        return u_star\n",
        "\n",
        "        # Evaluates predictions at test points\n",
        "\n",
        "    def predict_r(self, X_star):\n",
        "        X_star = (X_star - self.mu_X) / self.sigma_X\n",
        "        tf_dict = {self.t_r_tf: X_star[:, 0:1], self.x_r_tf: X_star[:, 1:2]}\n",
        "        r_star = self.sess.run(self.r_pred, tf_dict)\n",
        "        return r_star\n",
        "    \n",
        "   ###############################################################################################################################################\n",
        "   # \n",
        "   # ###############################################################################################################################################\n",
        "   # \n",
        "   # ###############################################################################################################################################\n",
        "   # \n",
        "   #  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#test_method(mtd , layers,  X_u, Y_u, X_r, Y_r ,  X_star , u_star , r_star  , nIter ,batch_size , bcbatch_size , ubatch_size)\n",
        "def test_method(method , layers,  ics_sampler, bcs_sampler, res_sampler, c ,kernel_size , X_star , u_star , r_star , nIter ,mbbatch_size , bcbatch_size , ubatch_size ):\n",
        "\n",
        "    tf.reset_default_graph()\n",
        "    gpu_options = tf.GPUOptions(visible_device_list=\"0\")\n",
        "    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options,allow_soft_placement=False, log_device_placement=False)) as sess:\n",
        "        # sess.run(init)\n",
        "\n",
        "        model = PINN(layers, operator, ics_sampler, bcs_sampler, res_sampler, c, kernel_size , sess)\n",
        "        # Train model\n",
        "        start_time = time.time()\n",
        "\n",
        "        if method ==\"full_batch\":\n",
        "            print(\"full_batch method is used\")\n",
        "            model.train(nIter  , bcbatch_size , ubatch_size  )\n",
        "        elif method ==\"mini_batch\":\n",
        "            print(\"mini_batch method is used\")\n",
        "            model.trainmb(nIter, mbbatch_size)\n",
        "        else:\n",
        "            print(\"unknown method!\")\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        # Predictions\n",
        "        u_pred = model.predict_u(X_star)\n",
        "        r_pred = model.predict_u(X_star)\n",
        "        # Predictions\n",
        "\n",
        "        sess.close()   \n",
        "\n",
        "    error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
        "    error_r = np.linalg.norm(r_star - r_pred, 2) #/ np.linalg.norm(u_star, 2)\n",
        "\n",
        "    print('elapsed: {:.2e}'.format(elapsed))\n",
        "\n",
        "    print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
        "    print('Relative L2 error_r: {:.2e}'.format(error_r))\n",
        "\n",
        "\n",
        "    return [elapsed, error_u , error_r , model]\n",
        "\n",
        "###############################################################################################################################################\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Method:  mini_batch\n",
            "Epoch:  1\n",
            "WARNING:tensorflow:From /tmp/ipykernel_10497/2211598682.py:4: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_10497/2211598682.py:5: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_10497/2211598682.py:6: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_10497/2211598682.py:6: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_10497/258566634.py:38: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-27 15:49:49.914352: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
            "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-27 15:49:49.941085: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz\n",
            "2023-11-27 15:49:49.941989: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e884a2e9a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2023-11-27 15:49:49.942035: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2023-11-27 15:49:49.950470: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tmp/ipykernel_10497/258566634.py:88: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_10497/258566634.py:90: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_10497/258566634.py:93: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "mini_batch method is used\n",
            "It: 100, Loss: 6.047e-01,  loss_bc1: 5.691e-02,  loss_bc2: 1.501e-02, loss_ics_u: 2.248e-01, loss_ics_ut: 5.957e-04,  Loss_res: 9.964e-03 , Time: 27.27\n",
            "loss_bc1: 1.390e+05\n",
            "loss_ics_u: 4.436e+04\n",
            "loss_res_val: 1.004e+04\n",
            "It: 200, Loss: 8.270e+03,  loss_bc1: 2.099e-01,  loss_bc2: 4.170e-02, loss_ics_u: 1.837e-01, loss_ics_ut: 7.842e-04,  Loss_res: 8.758e-03 , Time: 43.65\n",
            "loss_bc1: 3.975e+04\n",
            "loss_ics_u: 5.422e+04\n",
            "loss_res_val: 1.142e+04\n",
            "It: 300, Loss: 8.224e+03,  loss_bc1: 1.764e-01,  loss_bc2: 2.545e-02, loss_ics_u: 1.496e-01, loss_ics_ut: 6.755e-04,  Loss_res: 6.446e-03 , Time: 57.84\n",
            "loss_bc1: 4.953e+04\n",
            "loss_ics_u: 6.653e+04\n",
            "loss_res_val: 1.551e+04\n",
            "It: 400, Loss: 1.004e+04,  loss_bc1: 1.341e-01,  loss_bc2: 2.638e-02, loss_ics_u: 1.488e-01, loss_ics_ut: 9.776e-04,  Loss_res: 5.176e-03 , Time: 71.96\n",
            "loss_bc1: 6.231e+04\n",
            "loss_ics_u: 6.677e+04\n",
            "loss_res_val: 1.932e+04\n",
            "It: 500, Loss: 1.097e+04,  loss_bc1: 1.352e-01,  loss_bc2: 2.247e-02, loss_ics_u: 1.495e-01, loss_ics_ut: 1.102e-03,  Loss_res: 4.742e-02 , Time: 86.30\n",
            "loss_bc1: 6.341e+04\n",
            "loss_ics_u: 6.639e+04\n",
            "loss_res_val: 2.109e+03\n",
            "It: 600, Loss: 7.954e+03,  loss_bc1: 1.620e-01,  loss_bc2: 4.960e-03, loss_ics_u: 1.121e-01, loss_ics_ut: 3.085e-03,  Loss_res: 1.451e-01 , Time: 100.51\n",
            "loss_bc1: 5.991e+04\n",
            "loss_ics_u: 8.680e+04\n",
            "loss_res_val: 6.893e+02\n",
            "It: 700, Loss: 8.893e+03,  loss_bc1: 2.117e-01,  loss_bc2: 1.468e-02, loss_ics_u: 9.707e-02, loss_ics_ut: 3.282e-03,  Loss_res: 2.640e-01 , Time: 114.85\n",
            "loss_bc1: 4.418e+04\n",
            "loss_ics_u: 9.965e+04\n",
            "loss_res_val: 3.788e+02\n",
            "It: 800, Loss: 1.042e+04,  loss_bc1: 3.390e-01,  loss_bc2: 4.424e-02, loss_ics_u: 9.764e-02, loss_ics_ut: 8.439e-04,  Loss_res: 1.598e+00 , Time: 128.95\n",
            "loss_bc1: 2.610e+04\n",
            "loss_ics_u: 1.015e+05\n",
            "loss_res_val: 6.257e+01\n",
            "It: 900, Loss: 9.225e+03,  loss_bc1: 4.671e-01,  loss_bc2: 5.507e-02, loss_ics_u: 8.530e-02, loss_ics_ut: 9.339e-04,  Loss_res: 7.472e+00 , Time: 143.04\n",
            "loss_bc1: 1.915e+04\n",
            "loss_ics_u: 1.160e+05\n",
            "loss_res_val: 1.338e+01\n",
            "It: 1000, Loss: 8.684e+03,  loss_bc1: 6.826e-01,  loss_bc2: 9.437e-02, loss_ics_u: 6.593e-02, loss_ics_ut: 1.633e-03,  Loss_res: 6.337e+01 , Time: 157.59\n",
            "loss_bc1: 1.287e+04\n",
            "loss_ics_u: 1.480e+05\n",
            "loss_res_val: 1.578e+00\n",
            "It: 1100, Loss: 5.729e+03,  loss_bc1: 2.949e-01,  loss_bc2: 6.051e-02, loss_ics_u: 3.139e-02, loss_ics_ut: 6.287e-04,  Loss_res: 6.271e+02 , Time: 171.99\n",
            "loss_bc1: 2.814e+04\n",
            "loss_ics_u: 3.124e+05\n",
            "loss_res_val: 1.595e-01\n",
            "It: 1200, Loss: 2.617e+03,  loss_bc1: 1.284e-01,  loss_bc2: 4.627e-02, loss_ics_u: 2.928e-03, loss_ics_ut: 1.941e-03,  Loss_res: 6.872e+03 , Time: 186.95\n",
            "loss_bc1: 5.727e+04\n",
            "loss_ics_u: 2.054e+06\n",
            "loss_res_val: 1.455e-02\n",
            "It: 1300, Loss: 1.341e+04,  loss_bc1: 7.689e+00,  loss_bc2: 1.523e+02, loss_ics_u: 5.225e-03, loss_ics_ut: 2.945e-04,  Loss_res: 1.208e+05 , Time: 202.94\n",
            "loss_bc1: 6.249e+01\n",
            "loss_ics_u: 1.812e+06\n",
            "loss_res_val: 8.280e-04\n",
            "It: 1400, Loss: 3.898e+03,  loss_bc1: 5.033e+00,  loss_bc2: 1.247e+02, loss_ics_u: 1.839e-03, loss_ics_ut: 1.232e-04,  Loss_res: 9.971e+04 , Time: 217.18\n",
            "loss_bc1: 7.707e+01\n",
            "loss_ics_u: 5.096e+06\n",
            "loss_res_val: 1.003e-03\n",
            "It: 1500, Loss: 2.179e+03,  loss_bc1: 1.153e+00,  loss_bc2: 6.459e+01, loss_ics_u: 3.567e-04, loss_ics_ut: 2.354e-05,  Loss_res: 1.094e+05 , Time: 231.40\n",
            "loss_bc1: 1.521e+02\n",
            "loss_ics_u: 2.630e+07\n",
            "loss_res_val: 9.138e-04\n",
            "It: 1600, Loss: 1.245e+04,  loss_bc1: 1.745e+00,  loss_bc2: 7.952e+00, loss_ics_u: 3.921e-04, loss_ics_ut: 7.699e-05,  Loss_res: 1.053e+05 , Time: 245.62\n",
            "loss_bc1: 1.031e+03\n",
            "loss_ics_u: 2.132e+07\n",
            "loss_res_val: 9.494e-04\n",
            "It: 1700, Loss: 2.674e+03,  loss_bc1: 2.044e+00,  loss_bc2: 5.500e+00, loss_ics_u: 1.086e-04, loss_ics_ut: 1.180e-05,  Loss_res: 9.806e+04 , Time: 259.88\n",
            "loss_bc1: 1.326e+03\n",
            "loss_ics_u: 8.308e+07\n",
            "loss_res_val: 1.020e-03\n",
            "It: 1800, Loss: 5.206e+03,  loss_bc1: 4.320e+00,  loss_bc2: 3.599e+00, loss_ics_u: 5.201e-05, loss_ics_ut: 9.217e-06,  Loss_res: 1.016e+05 , Time: 274.05\n",
            "loss_bc1: 1.263e+03\n",
            "loss_ics_u: 1.633e+08\n",
            "loss_res_val: 9.842e-04\n",
            "It: 1900, Loss: 1.510e+04,  loss_bc1: 5.318e+00,  loss_bc2: 8.328e+00, loss_ics_u: 7.302e-05, loss_ics_ut: 1.840e-05,  Loss_res: 1.394e+05 , Time: 288.18\n",
            "loss_bc1: 7.328e+02\n",
            "loss_ics_u: 1.094e+08\n",
            "loss_res_val: 7.175e-04\n",
            "It: 2000, Loss: 1.534e+03,  loss_bc1: 7.037e+00,  loss_bc2: 3.387e+00, loss_ics_u: 1.063e-05, loss_ics_ut: 2.115e-06,  Loss_res: 1.655e+05 , Time: 302.13\n",
            "loss_bc1: 9.594e+02\n",
            "loss_ics_u: 7.848e+08\n",
            "loss_res_val: 6.042e-04\n",
            "It: 2100, Loss: 9.722e+04,  loss_bc1: 4.989e+00,  loss_bc2: 1.780e+01, loss_ics_u: 7.765e-05, loss_ics_ut: 4.600e-05,  Loss_res: 2.147e+05 , Time: 316.16\n",
            "loss_bc1: 4.388e+02\n",
            "loss_ics_u: 8.087e+07\n",
            "loss_res_val: 4.657e-04\n",
            "It: 2200, Loss: 3.188e+03,  loss_bc1: 4.203e+00,  loss_bc2: 2.038e+01, loss_ics_u: 3.383e-05, loss_ics_ut: 3.699e-06,  Loss_res: 2.230e+05 , Time: 330.33\n",
            "loss_bc1: 4.068e+02\n",
            "loss_ics_u: 2.664e+08\n",
            "loss_res_val: 4.485e-04\n",
            "It: 2300, Loss: 5.149e+03,  loss_bc1: 5.098e+00,  loss_bc2: 9.960e+00, loss_ics_u: 1.678e-05, loss_ics_ut: 2.077e-06,  Loss_res: 2.114e+05 , Time: 344.35\n",
            "loss_bc1: 6.641e+02\n",
            "loss_ics_u: 5.303e+08\n",
            "loss_res_val: 4.730e-04\n",
            "It: 2400, Loss: 7.200e+03,  loss_bc1: 4.174e+00,  loss_bc2: 1.454e+01, loss_ics_u: 1.093e-05, loss_ics_ut: 2.370e-06,  Loss_res: 2.303e+05 , Time: 358.36\n",
            "loss_bc1: 5.344e+02\n",
            "loss_ics_u: 7.518e+08\n",
            "loss_res_val: 4.342e-04\n",
            "It: 2500, Loss: 3.697e+03,  loss_bc1: 2.619e+00,  loss_bc2: 6.552e+00, loss_ics_u: 3.564e-06, loss_ics_ut: 1.193e-06,  Loss_res: 2.348e+05 , Time: 372.58\n",
            "loss_bc1: 1.090e+03\n",
            "loss_ics_u: 2.102e+09\n",
            "loss_res_val: 4.259e-04\n",
            "It: 2600, Loss: 6.200e+04,  loss_bc1: 4.627e+00,  loss_bc2: 8.908e+00, loss_ics_u: 2.840e-05, loss_ics_ut: 1.032e-06,  Loss_res: 2.677e+05 , Time: 386.72\n",
            "loss_bc1: 7.388e+02\n",
            "loss_ics_u: 3.398e+08\n",
            "loss_res_val: 3.735e-04\n",
            "It: 2700, Loss: 2.363e+03,  loss_bc1: 4.877e+00,  loss_bc2: 6.957e+00, loss_ics_u: 6.367e-06, loss_ics_ut: 2.766e-07,  Loss_res: 2.206e+05 , Time: 400.79\n",
            "loss_bc1: 8.450e+02\n",
            "loss_ics_u: 1.505e+09\n",
            "loss_res_val: 4.533e-04\n",
            "It: 2800, Loss: 5.772e+03,  loss_bc1: 2.643e+00,  loss_bc2: 6.817e+00, loss_ics_u: 2.989e-06, loss_ics_ut: 7.621e-07,  Loss_res: 2.357e+05 , Time: 414.91\n",
            "loss_bc1: 1.057e+03\n",
            "loss_ics_u: 2.666e+09\n",
            "loss_res_val: 4.242e-04\n",
            "It: 2900, Loss: 6.851e+03,  loss_bc1: 2.302e+00,  loss_bc2: 3.686e+00, loss_ics_u: 1.966e-06, loss_ics_ut: 5.648e-07,  Loss_res: 2.210e+05 , Time: 429.01\n",
            "loss_bc1: 1.670e+03\n",
            "loss_ics_u: 3.952e+09\n",
            "loss_res_val: 4.525e-04\n",
            "It: 3000, Loss: 6.986e+04,  loss_bc1: 3.326e+00,  loss_bc2: 7.657e+00, loss_ics_u: 9.043e-06, loss_ics_ut: 8.600e-06,  Loss_res: 2.542e+05 , Time: 443.20\n",
            "loss_bc1: 9.105e+02\n",
            "loss_ics_u: 5.668e+08\n",
            "loss_res_val: 3.934e-04\n",
            "It: 3100, Loss: 1.364e+03,  loss_bc1: 3.826e+00,  loss_bc2: 4.088e+00, loss_ics_u: 2.104e-06, loss_ics_ut: 1.119e-07,  Loss_res: 2.343e+05 , Time: 457.29\n",
            "loss_bc1: 1.264e+03\n",
            "loss_ics_u: 4.512e+09\n",
            "loss_res_val: 4.268e-04\n",
            "It: 3200, Loss: 1.845e+04,  loss_bc1: 4.811e+00,  loss_bc2: 5.339e+00, loss_ics_u: 3.401e-06, loss_ics_ut: 6.573e-07,  Loss_res: 2.725e+05 , Time: 471.45\n",
            "loss_bc1: 9.852e+02\n",
            "loss_ics_u: 2.464e+09\n",
            "loss_res_val: 3.669e-04\n",
            "It: 3300, Loss: 3.552e+03,  loss_bc1: 3.867e+00,  loss_bc2: 5.275e+00, loss_ics_u: 1.206e-06, loss_ics_ut: 1.910e-07,  Loss_res: 2.523e+05 , Time: 485.88\n",
            "loss_bc1: 1.094e+03\n",
            "loss_ics_u: 7.160e+09\n",
            "loss_res_val: 3.964e-04\n",
            "It: 3400, Loss: 7.255e+05,  loss_bc1: 7.132e+00,  loss_bc2: 1.556e+01, loss_ics_u: 5.657e-05, loss_ics_ut: 4.472e-05,  Loss_res: 3.358e+05 , Time: 507.76\n",
            "loss_bc1: 4.407e+02\n",
            "loss_ics_u: 9.872e+07\n",
            "loss_res_val: 2.978e-04\n",
            "It: 3500, Loss: 1.061e+03,  loss_bc1: 4.887e+00,  loss_bc2: 1.286e+01, loss_ics_u: 8.617e-06, loss_ics_ut: 6.213e-07,  Loss_res: 3.822e+05 , Time: 523.28\n",
            "loss_bc1: 5.634e+02\n",
            "loss_ics_u: 1.082e+09\n",
            "loss_res_val: 2.616e-04\n",
            "It: 3600, Loss: 5.400e+03,  loss_bc1: 4.335e+00,  loss_bc2: 9.973e+00, loss_ics_u: 4.811e-06, loss_ics_ut: 8.184e-08,  Loss_res: 2.870e+05 , Time: 540.64\n",
            "loss_bc1: 6.989e+02\n",
            "loss_ics_u: 2.044e+09\n",
            "loss_res_val: 3.485e-04\n",
            "It: 3700, Loss: 4.552e+03,  loss_bc1: 5.372e+00,  loss_bc2: 1.111e+01, loss_ics_u: 2.003e-06, loss_ics_ut: 1.583e-07,  Loss_res: 2.956e+05 , Time: 559.64\n",
            "loss_bc1: 6.066e+02\n",
            "loss_ics_u: 4.628e+09\n",
            "loss_res_val: 3.383e-04\n",
            "It: 3800, Loss: 5.083e+03,  loss_bc1: 3.323e+00,  loss_bc2: 7.893e+00, loss_ics_u: 9.946e-07, loss_ics_ut: 7.478e-08,  Loss_res: 3.283e+05 , Time: 574.59\n",
            "loss_bc1: 8.916e+02\n",
            "loss_ics_u: 9.351e+09\n",
            "loss_res_val: 3.046e-04\n",
            "It: 3900, Loss: 7.608e+04,  loss_bc1: 4.183e+00,  loss_bc2: 8.625e+00, loss_ics_u: 3.141e-06, loss_ics_ut: 4.984e-06,  Loss_res: 2.752e+05 , Time: 590.18\n",
            "loss_bc1: 7.807e+02\n",
            "loss_ics_u: 1.231e+09\n",
            "loss_res_val: 3.633e-04\n",
            "It: 4000, Loss: 6.395e+02,  loss_bc1: 3.661e+00,  loss_bc2: 7.681e+00, loss_ics_u: 3.748e-07, loss_ics_ut: 3.640e-08,  Loss_res: 3.046e+05 , Time: 605.36\n",
            "loss_bc1: 8.817e+02\n",
            "loss_ics_u: 2.432e+10\n",
            "loss_res_val: 3.283e-04\n",
            "It: 4100, Loss: 1.536e+06,  loss_bc1: 3.764e+00,  loss_bc2: 5.308e+01, loss_ics_u: 4.280e-05, loss_ics_ut: 2.036e-05,  Loss_res: 2.656e+05 , Time: 620.83\n",
            "loss_bc1: 1.759e+02\n",
            "loss_ics_u: 1.583e+08\n",
            "loss_res_val: 3.765e-04\n",
            "It: 4200, Loss: 1.201e+03,  loss_bc1: 2.367e+00,  loss_bc2: 4.033e+01, loss_ics_u: 4.979e-06, loss_ics_ut: 1.308e-06,  Loss_res: 3.184e+05 , Time: 635.71\n",
            "loss_bc1: 2.342e+02\n",
            "loss_ics_u: 1.591e+09\n",
            "loss_res_val: 3.141e-04\n",
            "It: 4300, Loss: 5.988e+03,  loss_bc1: 4.277e+00,  loss_bc2: 5.206e+01, loss_ics_u: 3.264e-06, loss_ics_ut: 3.660e-07,  Loss_res: 3.264e+05 , Time: 653.71\n",
            "loss_bc1: 1.775e+02\n",
            "loss_ics_u: 2.755e+09\n",
            "loss_res_val: 3.064e-04\n",
            "It: 4400, Loss: 1.145e+04,  loss_bc1: 3.555e+00,  loss_bc2: 4.593e+01, loss_ics_u: 3.763e-06, loss_ics_ut: 3.222e-07,  Loss_res: 3.103e+05 , Time: 670.26\n",
            "loss_bc1: 2.021e+02\n",
            "loss_ics_u: 2.448e+09\n",
            "loss_res_val: 3.222e-04\n",
            "It: 4500, Loss: 8.527e+03,  loss_bc1: 4.207e+00,  loss_bc2: 4.699e+01, loss_ics_u: 3.119e-06, loss_ics_ut: 2.860e-07,  Loss_res: 2.782e+05 , Time: 685.76\n",
            "loss_bc1: 1.953e+02\n",
            "loss_ics_u: 2.937e+09\n",
            "loss_res_val: 3.595e-04\n",
            "It: 4600, Loss: 8.001e+03,  loss_bc1: 4.827e+00,  loss_bc2: 4.590e+01, loss_ics_u: 2.383e-06, loss_ics_ut: 2.727e-07,  Loss_res: 2.841e+05 , Time: 704.21\n",
            "loss_bc1: 1.971e+02\n",
            "loss_ics_u: 3.766e+09\n",
            "loss_res_val: 3.520e-04\n",
            "It: 4700, Loss: 9.157e+03,  loss_bc1: 3.783e+00,  loss_bc2: 3.470e+01, loss_ics_u: 2.148e-06, loss_ics_ut: 2.305e-07,  Loss_res: 3.452e+05 , Time: 719.35\n",
            "loss_bc1: 2.599e+02\n",
            "loss_ics_u: 4.204e+09\n",
            "loss_res_val: 2.897e-04\n",
            "It: 4800, Loss: 8.125e+03,  loss_bc1: 2.291e+00,  loss_bc2: 4.850e+01, loss_ics_u: 1.696e-06, loss_ics_ut: 1.926e-07,  Loss_res: 2.863e+05 , Time: 734.56\n",
            "loss_bc1: 1.969e+02\n",
            "loss_ics_u: 5.294e+09\n",
            "loss_res_val: 3.493e-04\n",
            "It: 4900, Loss: 6.719e+03,  loss_bc1: 3.474e+00,  loss_bc2: 3.294e+01, loss_ics_u: 1.070e-06, loss_ics_ut: 1.674e-07,  Loss_res: 2.708e+05 , Time: 749.62\n",
            "loss_bc1: 2.747e+02\n",
            "loss_ics_u: 8.081e+09\n",
            "loss_res_val: 3.693e-04\n",
            "It: 5000, Loss: 6.282e+03,  loss_bc1: 4.390e+00,  loss_bc2: 3.012e+01, loss_ics_u: 6.381e-07, loss_ics_ut: 1.172e-07,  Loss_res: 2.975e+05 , Time: 764.79\n",
            "loss_bc1: 2.898e+02\n",
            "loss_ics_u: 1.324e+10\n",
            "loss_res_val: 3.362e-04\n",
            "It: 5100, Loss: 1.562e+04,  loss_bc1: 4.315e+00,  loss_bc2: 4.132e+01, loss_ics_u: 9.661e-07, loss_ics_ut: 1.994e-07,  Loss_res: 2.785e+05 , Time: 780.49\n",
            "loss_bc1: 2.192e+02\n",
            "loss_ics_u: 8.580e+09\n",
            "loss_res_val: 3.590e-04\n",
            "It: 5200, Loss: 5.636e+03,  loss_bc1: 3.251e+00,  loss_bc2: 3.466e+01, loss_ics_u: 5.322e-07, loss_ics_ut: 1.049e-07,  Loss_res: 2.614e+05 , Time: 796.86\n",
            "loss_bc1: 2.638e+02\n",
            "loss_ics_u: 1.570e+10\n",
            "loss_res_val: 3.826e-04\n",
            "It: 5300, Loss: 9.496e+03,  loss_bc1: 5.119e+00,  loss_bc2: 4.205e+01, loss_ics_u: 4.659e-07, loss_ics_ut: 1.265e-07,  Loss_res: 2.687e+05 , Time: 812.86\n",
            "loss_bc1: 2.120e+02\n",
            "loss_ics_u: 1.688e+10\n",
            "loss_res_val: 3.721e-04\n",
            "It: 5400, Loss: 5.833e+03,  loss_bc1: 2.295e+00,  loss_bc2: 4.402e+01, loss_ics_u: 2.659e-07, loss_ics_ut: 6.864e-08,  Loss_res: 2.524e+05 , Time: 827.83\n",
            "loss_bc1: 2.159e+02\n",
            "loss_ics_u: 2.989e+10\n",
            "loss_res_val: 3.962e-04\n",
            "It: 5500, Loss: 1.611e+04,  loss_bc1: 3.285e+00,  loss_bc2: 3.774e+01, loss_ics_u: 3.402e-07, loss_ics_ut: 1.932e-07,  Loss_res: 2.160e+05 , Time: 842.82\n",
            "loss_bc1: 2.438e+02\n",
            "loss_ics_u: 1.875e+10\n",
            "loss_res_val: 4.630e-04\n",
            "It: 5600, Loss: 7.460e+03,  loss_bc1: 4.156e+00,  loss_bc2: 2.699e+01, loss_ics_u: 3.016e-07, loss_ics_ut: 8.642e-08,  Loss_res: 2.690e+05 , Time: 858.60\n",
            "loss_bc1: 3.210e+02\n",
            "loss_ics_u: 2.577e+10\n",
            "loss_res_val: 3.717e-04\n",
            "It: 5700, Loss: 1.551e+04,  loss_bc1: 5.704e+00,  loss_bc2: 2.930e+01, loss_ics_u: 3.143e-07, loss_ics_ut: 2.805e-07,  Loss_res: 3.010e+05 , Time: 875.01\n",
            "loss_bc1: 2.857e+02\n",
            "loss_ics_u: 1.681e+10\n",
            "loss_res_val: 3.323e-04\n",
            "It: 5800, Loss: 4.368e+03,  loss_bc1: 4.715e+00,  loss_bc2: 3.805e+01, loss_ics_u: 2.188e-07, loss_ics_ut: 3.134e-08,  Loss_res: 2.325e+05 , Time: 890.10\n",
            "loss_bc1: 2.338e+02\n",
            "loss_ics_u: 3.998e+10\n",
            "loss_res_val: 4.300e-04\n",
            "It: 5900, Loss: 2.357e+06,  loss_bc1: 3.377e+00,  loss_bc2: 2.677e+01, loss_ics_u: 1.798e-05, loss_ics_ut: 4.098e-05,  Loss_res: 2.636e+05 , Time: 904.92\n",
            "loss_bc1: 3.317e+02\n",
            "loss_ics_u: 1.696e+08\n",
            "loss_res_val: 3.793e-04\n",
            "It: 6000, Loss: 3.230e+03,  loss_bc1: 3.970e+00,  loss_bc2: 3.109e+01, loss_ics_u: 1.395e-05, loss_ics_ut: 4.106e-06,  Loss_res: 2.547e+05 , Time: 920.60\n",
            "loss_bc1: 2.852e+02\n",
            "loss_ics_u: 5.538e+08\n",
            "loss_res_val: 3.927e-04\n",
            "It: 6100, Loss: 8.964e+02,  loss_bc1: 4.851e+00,  loss_bc2: 2.787e+01, loss_ics_u: 1.179e-06, loss_ics_ut: 1.377e-07,  Loss_res: 2.586e+05 , Time: 936.92\n",
            "loss_bc1: 3.056e+02\n",
            "loss_ics_u: 7.592e+09\n",
            "loss_res_val: 3.867e-04\n",
            "It: 6200, Loss: 4.093e+03,  loss_bc1: 4.858e+00,  loss_bc2: 2.744e+01, loss_ics_u: 4.633e-07, loss_ics_ut: 5.258e-08,  Loss_res: 2.886e+05 , Time: 952.42\n",
            "loss_bc1: 3.096e+02\n",
            "loss_ics_u: 1.938e+10\n",
            "loss_res_val: 3.464e-04\n",
            "It: 6300, Loss: 7.478e+03,  loss_bc1: 4.195e+00,  loss_bc2: 3.061e+01, loss_ics_u: 3.223e-07, loss_ics_ut: 5.507e-08,  Loss_res: 2.654e+05 , Time: 969.64\n",
            "loss_bc1: 2.873e+02\n",
            "loss_ics_u: 2.650e+10\n",
            "loss_res_val: 3.768e-04\n",
            "It: 6400, Loss: 6.670e+03,  loss_bc1: 3.578e+00,  loss_bc2: 2.084e+01, loss_ics_u: 2.144e-07, loss_ics_ut: 3.176e-08,  Loss_res: 2.631e+05 , Time: 984.63\n",
            "loss_bc1: 4.096e+02\n",
            "loss_ics_u: 4.063e+10\n",
            "loss_res_val: 3.801e-04\n",
            "It: 6500, Loss: 1.768e+06,  loss_bc1: 3.412e+00,  loss_bc2: 1.996e+01, loss_ics_u: 3.832e-05, loss_ics_ut: 5.190e-06,  Loss_res: 2.964e+05 , Time: 1000.11\n",
            "loss_bc1: 4.279e+02\n",
            "loss_ics_u: 2.298e+08\n",
            "loss_res_val: 3.374e-04\n",
            "It: 6600, Loss: 3.060e+03,  loss_bc1: 4.900e+00,  loss_bc2: 1.997e+01, loss_ics_u: 1.084e-05, loss_ics_ut: 1.774e-06,  Loss_res: 3.273e+05 , Time: 1015.29\n",
            "loss_bc1: 4.022e+02\n",
            "loss_ics_u: 7.925e+08\n",
            "loss_res_val: 3.055e-04\n",
            "It: 6700, Loss: 9.237e+02,  loss_bc1: 6.447e+00,  loss_bc2: 1.758e+01, loss_ics_u: 9.383e-07, loss_ics_ut: 6.084e-08,  Loss_res: 2.743e+05 , Time: 1032.62\n",
            "loss_bc1: 4.162e+02\n",
            "loss_ics_u: 1.001e+10\n",
            "loss_res_val: 3.645e-04\n",
            "It: 6800, Loss: 2.933e+03,  loss_bc1: 4.498e+00,  loss_bc2: 2.010e+01, loss_ics_u: 2.539e-07, loss_ics_ut: 2.487e-08,  Loss_res: 2.586e+05 , Time: 1047.79\n",
            "loss_bc1: 4.065e+02\n",
            "loss_ics_u: 3.587e+10\n",
            "loss_res_val: 3.867e-04\n",
            "It: 6900, Loss: 4.447e+04,  loss_bc1: 6.379e+00,  loss_bc2: 1.793e+01, loss_ics_u: 9.406e-07, loss_ics_ut: 2.943e-07,  Loss_res: 3.180e+05 , Time: 1064.19\n",
            "loss_bc1: 4.114e+02\n",
            "loss_ics_u: 8.098e+09\n",
            "loss_res_val: 3.144e-04\n",
            "It: 7000, Loss: 1.485e+03,  loss_bc1: 4.974e+00,  loss_bc2: 2.277e+01, loss_ics_u: 1.386e-07, loss_ics_ut: 2.709e-08,  Loss_res: 2.787e+05 , Time: 1083.05\n",
            "loss_bc1: 3.605e+02\n",
            "loss_ics_u: 6.036e+10\n",
            "loss_res_val: 3.588e-04\n",
            "It: 7100, Loss: 4.412e+05,  loss_bc1: 1.259e+01,  loss_bc2: 3.009e+01, loss_ics_u: 5.602e-06, loss_ics_ut: 1.703e-06,  Loss_res: 4.473e+05 , Time: 1098.30\n",
            "loss_bc1: 2.343e+02\n",
            "loss_ics_u: 1.369e+09\n",
            "loss_res_val: 2.236e-04\n",
            "It: 7200, Loss: 1.728e+03,  loss_bc1: 8.116e+00,  loss_bc2: 3.706e+01, loss_ics_u: 9.222e-07, loss_ics_ut: 1.976e-07,  Loss_res: 4.697e+05 , Time: 1119.60\n",
            "loss_bc1: 2.213e+02\n",
            "loss_ics_u: 8.930e+09\n",
            "loss_res_val: 2.129e-04\n",
            "It: 7300, Loss: 5.873e+03,  loss_bc1: 1.081e+01,  loss_bc2: 2.761e+01, loss_ics_u: 5.597e-07, loss_ics_ut: 8.046e-08,  Loss_res: 3.750e+05 , Time: 1139.41\n",
            "loss_bc1: 2.603e+02\n",
            "loss_ics_u: 1.562e+10\n",
            "loss_res_val: 2.667e-04\n",
            "It: 7400, Loss: 1.286e+04,  loss_bc1: 9.002e+00,  loss_bc2: 3.343e+01, loss_ics_u: 7.407e-07, loss_ics_ut: 7.011e-08,  Loss_res: 4.017e+05 , Time: 1160.56\n",
            "loss_bc1: 2.357e+02\n",
            "loss_ics_u: 1.233e+10\n",
            "loss_res_val: 2.489e-04\n",
            "It: 7500, Loss: 5.503e+03,  loss_bc1: 1.034e+01,  loss_bc2: 3.927e+01, loss_ics_u: 3.884e-07, loss_ics_ut: 4.267e-08,  Loss_res: 3.517e+05 , Time: 1181.19\n",
            "loss_bc1: 2.016e+02\n",
            "loss_ics_u: 2.320e+10\n",
            "loss_res_val: 2.843e-04\n",
            "It: 7600, Loss: 8.353e+03,  loss_bc1: 6.395e+00,  loss_bc2: 3.003e+01, loss_ics_u: 2.978e-07, loss_ics_ut: 5.300e-08,  Loss_res: 4.939e+05 , Time: 1195.99\n",
            "loss_bc1: 2.745e+02\n",
            "loss_ics_u: 2.850e+10\n",
            "loss_res_val: 2.025e-04\n",
            "It: 7700, Loss: 8.602e+03,  loss_bc1: 4.687e+00,  loss_bc2: 2.776e+01, loss_ics_u: 2.259e-07, loss_ics_ut: 7.111e-08,  Loss_res: 3.471e+05 , Time: 1213.40\n",
            "loss_bc1: 3.082e+02\n",
            "loss_ics_u: 3.367e+10\n",
            "loss_res_val: 2.881e-04\n",
            "It: 7800, Loss: 8.608e+03,  loss_bc1: 7.978e+00,  loss_bc2: 3.578e+01, loss_ics_u: 2.184e-07, loss_ics_ut: 3.189e-08,  Loss_res: 3.256e+05 , Time: 1229.21\n",
            "loss_bc1: 2.285e+02\n",
            "loss_ics_u: 3.995e+10\n",
            "loss_res_val: 3.071e-04\n",
            "It: 7900, Loss: 1.156e+04,  loss_bc1: 6.796e+00,  loss_bc2: 3.020e+01, loss_ics_u: 2.096e-07, loss_ics_ut: 7.468e-08,  Loss_res: 4.226e+05 , Time: 1245.49\n",
            "loss_bc1: 2.703e+02\n",
            "loss_ics_u: 3.518e+10\n",
            "loss_res_val: 2.366e-04\n",
            "It: 8000, Loss: 6.972e+03,  loss_bc1: 8.302e+00,  loss_bc2: 2.924e+01, loss_ics_u: 1.519e-07, loss_ics_ut: 4.140e-08,  Loss_res: 4.078e+05 , Time: 1261.46\n",
            "loss_bc1: 2.663e+02\n",
            "loss_ics_u: 5.173e+10\n",
            "loss_res_val: 2.452e-04\n",
            "It: 8100, Loss: 1.157e+04,  loss_bc1: 8.966e+00,  loss_bc2: 1.971e+01, loss_ics_u: 1.738e-07, loss_ics_ut: 4.647e-08,  Loss_res: 4.716e+05 , Time: 1277.23\n",
            "loss_bc1: 3.487e+02\n",
            "loss_ics_u: 4.539e+10\n",
            "loss_res_val: 2.120e-04\n",
            "It: 8200, Loss: 1.957e+04,  loss_bc1: 6.940e+00,  loss_bc2: 2.380e+01, loss_ics_u: 2.287e-07, loss_ics_ut: 1.992e-07,  Loss_res: 4.188e+05 , Time: 1292.54\n",
            "loss_bc1: 3.253e+02\n",
            "loss_ics_u: 2.337e+10\n",
            "loss_res_val: 2.388e-04\n",
            "It: 8300, Loss: 4.262e+03,  loss_bc1: 7.227e+00,  loss_bc2: 1.891e+01, loss_ics_u: 1.420e-07, loss_ics_ut: 3.435e-08,  Loss_res: 3.679e+05 , Time: 1307.51\n",
            "loss_bc1: 3.826e+02\n",
            "loss_ics_u: 5.670e+10\n",
            "loss_res_val: 2.718e-04\n",
            "It: 8400, Loss: 6.919e+04,  loss_bc1: 8.877e+00,  loss_bc2: 2.180e+01, loss_ics_u: 1.005e-06, loss_ics_ut: 2.118e-07,  Loss_res: 3.854e+05 , Time: 1322.15\n",
            "loss_bc1: 3.259e+02\n",
            "loss_ics_u: 8.215e+09\n",
            "loss_res_val: 2.595e-04\n",
            "It: 8500, Loss: 1.532e+03,  loss_bc1: 8.010e+00,  loss_bc2: 2.344e+01, loss_ics_u: 1.357e-07, loss_ics_ut: 3.082e-08,  Loss_res: 3.896e+05 , Time: 1337.92\n",
            "loss_bc1: 3.180e+02\n",
            "loss_ics_u: 6.007e+10\n",
            "loss_res_val: 2.567e-04\n",
            "It: 8600, Loss: 3.046e+05,  loss_bc1: 6.243e+00,  loss_bc2: 2.090e+01, loss_ics_u: 2.682e-06, loss_ics_ut: 2.386e-06,  Loss_res: 4.152e+05 , Time: 1353.30\n",
            "loss_bc1: 3.684e+02\n",
            "loss_ics_u: 1.973e+09\n",
            "loss_res_val: 2.408e-04\n",
            "It: 8700, Loss: 4.255e+02,  loss_bc1: 9.022e+00,  loss_bc2: 1.854e+01, loss_ics_u: 1.262e-07, loss_ics_ut: 2.663e-08,  Loss_res: 2.860e+05 , Time: 1368.39\n",
            "loss_bc1: 3.628e+02\n",
            "loss_ics_u: 6.544e+10\n",
            "loss_res_val: 3.497e-04\n",
            "It: 8800, Loss: 3.042e+05,  loss_bc1: 7.233e+00,  loss_bc2: 1.845e+01, loss_ics_u: 1.898e-06, loss_ics_ut: 2.749e-06,  Loss_res: 3.575e+05 , Time: 1383.31\n",
            "loss_bc1: 3.893e+02\n",
            "loss_ics_u: 2.152e+09\n",
            "loss_res_val: 2.797e-04\n",
            "It: 8900, Loss: 5.071e+02,  loss_bc1: 9.119e+00,  loss_bc2: 2.180e+01, loss_ics_u: 1.349e-07, loss_ics_ut: 2.237e-08,  Loss_res: 3.818e+05 , Time: 1398.27\n",
            "loss_bc1: 3.234e+02\n",
            "loss_ics_u: 6.359e+10\n",
            "loss_res_val: 2.619e-04\n",
            "It: 9000, Loss: 9.820e+05,  loss_bc1: 9.916e+00,  loss_bc2: 1.766e+01, loss_ics_u: 1.410e-05, loss_ics_ut: 1.339e-06,  Loss_res: 3.783e+05 , Time: 1413.40\n",
            "loss_bc1: 3.626e+02\n",
            "loss_ics_u: 6.476e+08\n",
            "loss_res_val: 2.643e-04\n",
            "It: 9100, Loss: 3.652e+02,  loss_bc1: 5.978e+00,  loss_bc2: 2.385e+01, loss_ics_u: 1.395e-07, loss_ics_ut: 1.787e-07,  Loss_res: 3.763e+05 , Time: 1428.47\n",
            "loss_bc1: 3.353e+02\n",
            "loss_ics_u: 3.143e+10\n",
            "loss_res_val: 2.657e-04\n",
            "It: 9200, Loss: 5.004e+03,  loss_bc1: 6.570e+00,  loss_bc2: 1.679e+01, loss_ics_u: 1.393e-07, loss_ics_ut: 1.551e-08,  Loss_res: 3.398e+05 , Time: 1443.16\n",
            "loss_bc1: 4.281e+02\n",
            "loss_ics_u: 6.458e+10\n",
            "loss_res_val: 2.943e-04\n",
            "It: 9300, Loss: 1.375e+05,  loss_bc1: 8.395e+00,  loss_bc2: 1.635e+01, loss_ics_u: 1.868e-06, loss_ics_ut: 2.583e-07,  Loss_res: 3.886e+05 , Time: 1470.78\n",
            "loss_bc1: 4.041e+02\n",
            "loss_ics_u: 4.704e+09\n",
            "loss_res_val: 2.574e-04\n",
            "It: 9400, Loss: 7.578e+02,  loss_bc1: 6.874e+00,  loss_bc2: 1.782e+01, loss_ics_u: 1.152e-07, loss_ics_ut: 1.626e-08,  Loss_res: 3.505e+05 , Time: 1540.31\n",
            "loss_bc1: 4.049e+02\n",
            "loss_ics_u: 7.609e+10\n",
            "loss_res_val: 2.853e-04\n",
            "It: 9500, Loss: 1.543e+06,  loss_bc1: 8.429e+00,  loss_bc2: 1.357e+01, loss_ics_u: 1.447e-05, loss_ics_ut: 5.811e-06,  Loss_res: 4.807e+05 , Time: 1556.79\n",
            "loss_bc1: 4.547e+02\n",
            "loss_ics_u: 4.930e+08\n",
            "loss_res_val: 2.080e-04\n",
            "It: 9600, Loss: 1.172e+03,  loss_bc1: 1.316e+01,  loss_bc2: 1.090e+01, loss_ics_u: 1.869e-06, loss_ics_ut: 2.268e-07,  Loss_res: 4.342e+05 , Time: 1580.83\n",
            "loss_bc1: 4.155e+02\n",
            "loss_ics_u: 4.771e+09\n",
            "loss_res_val: 2.303e-04\n",
            "It: 9700, Loss: 1.437e+03,  loss_bc1: 1.229e+01,  loss_bc2: 2.335e+01, loss_ics_u: 2.344e-07, loss_ics_ut: 3.261e-08,  Loss_res: 3.985e+05 , Time: 1599.21\n",
            "loss_bc1: 2.806e+02\n",
            "loss_ics_u: 3.745e+10\n",
            "loss_res_val: 2.510e-04\n",
            "It: 9800, Loss: 6.569e+03,  loss_bc1: 1.008e+01,  loss_bc2: 1.153e+01, loss_ics_u: 1.509e-07, loss_ics_ut: 2.068e-08,  Loss_res: 3.905e+05 , Time: 1614.88\n",
            "loss_bc1: 4.627e+02\n",
            "loss_ics_u: 5.827e+10\n",
            "loss_res_val: 2.561e-04\n",
            "It: 9900, Loss: 1.414e+04,  loss_bc1: 1.336e+01,  loss_bc2: 1.366e+01, loss_ics_u: 1.942e-07, loss_ics_ut: 4.581e-08,  Loss_res: 4.099e+05 , Time: 1631.75\n",
            "loss_bc1: 3.700e+02\n",
            "loss_ics_u: 4.167e+10\n",
            "loss_res_val: 2.440e-04\n",
            "It: 10000, Loss: 4.285e+03,  loss_bc1: 1.593e+01,  loss_bc2: 1.061e+01, loss_ics_u: 8.054e-08, loss_ics_ut: 1.840e-08,  Loss_res: 4.467e+05 , Time: 1656.80\n",
            "loss_bc1: 3.767e+02\n",
            "loss_ics_u: 1.011e+11\n",
            "loss_res_val: 2.239e-04\n",
            "It: 10100, Loss: 1.475e+07,  loss_bc1: 1.375e+01,  loss_bc2: 1.781e+01, loss_ics_u: 1.210e-04, loss_ics_ut: 2.486e-05,  Loss_res: 3.979e+05 , Time: 1672.42\n",
            "loss_bc1: 3.169e+02\n",
            "loss_ics_u: 6.854e+07\n",
            "loss_res_val: 2.513e-04\n",
            "It: 10200, Loss: 6.310e+04,  loss_bc1: 1.249e+01,  loss_bc2: 1.850e+01, loss_ics_u: 8.020e-04, loss_ics_ut: 1.163e-04,  Loss_res: 4.000e+05 , Time: 1686.86\n",
            "loss_bc1: 3.227e+02\n",
            "loss_ics_u: 1.089e+07\n",
            "loss_res_val: 2.500e-04\n",
            "It: 10300, Loss: 3.993e+03,  loss_bc1: 1.182e+01,  loss_bc2: 2.183e+01, loss_ics_u: 2.703e-04, loss_ics_ut: 8.079e-05,  Loss_res: 4.085e+05 , Time: 1701.09\n",
            "loss_bc1: 2.972e+02\n",
            "loss_ics_u: 2.848e+07\n",
            "loss_res_val: 2.448e-04\n",
            "It: 10400, Loss: 3.397e+03,  loss_bc1: 1.266e+01,  loss_bc2: 1.821e+01, loss_ics_u: 8.281e-05, loss_ics_ut: 3.089e-05,  Loss_res: 3.959e+05 , Time: 1715.25\n",
            "loss_bc1: 3.240e+02\n",
            "loss_ics_u: 8.796e+07\n",
            "loss_res_val: 2.526e-04\n",
            "It: 10500, Loss: 2.433e+03,  loss_bc1: 1.716e+01,  loss_bc2: 1.448e+01, loss_ics_u: 1.572e-05, loss_ics_ut: 1.004e-05,  Loss_res: 4.088e+05 , Time: 1729.54\n",
            "loss_bc1: 3.161e+02\n",
            "loss_ics_u: 3.881e+08\n",
            "loss_res_val: 2.446e-04\n",
            "It: 10600, Loss: 6.934e+02,  loss_bc1: 1.125e+01,  loss_bc2: 1.554e+01, loss_ics_u: 8.270e-07, loss_ics_ut: 5.208e-07,  Loss_res: 4.771e+05 , Time: 1743.79\n",
            "loss_bc1: 3.732e+02\n",
            "loss_ics_u: 7.419e+09\n",
            "loss_res_val: 2.096e-04\n",
            "It: 10700, Loss: 1.491e+03,  loss_bc1: 1.177e+01,  loss_bc2: 1.276e+01, loss_ics_u: 1.318e-07, loss_ics_ut: 5.021e-08,  Loss_res: 4.388e+05 , Time: 1757.88\n",
            "loss_bc1: 4.078e+02\n",
            "loss_ics_u: 5.494e+10\n",
            "loss_res_val: 2.279e-04\n",
            "It: 10800, Loss: 9.924e+03,  loss_bc1: 9.640e+00,  loss_bc2: 1.780e+01, loss_ics_u: 1.547e-07, loss_ics_ut: 2.312e-08,  Loss_res: 4.255e+05 , Time: 1771.99\n",
            "loss_bc1: 3.644e+02\n",
            "loss_ics_u: 5.622e+10\n",
            "loss_res_val: 2.350e-04\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_10497/823296758.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Create residual sampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0melapsed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_u\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0merror_r\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmtd\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mics_sampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbcs_sampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_sampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mX_star\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mu_star\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mr_star\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnIter\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mmbbatch_size\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbcbatch_size\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mubatch_size\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_10497/2211598682.py\u001b[0m in \u001b[0;36mtest_method\u001b[0;34m(method, layers, ics_sampler, bcs_sampler, res_sampler, c, kernel_size, X_star, u_star, r_star, nIter, mbbatch_size, bcbatch_size, ubatch_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m\"mini_batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mini_batch method is used\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainmb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnIter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmbbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown method!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_10497/258566634.py\u001b[0m in \u001b[0;36mtrainmb\u001b[0;34m(self, nIter, batch_size, log_NTK, update_lam)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;31m# Run the Tensorflow session to minimize the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;31m# Print\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/twoPhase/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/twoPhase/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/twoPhase/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/twoPhase/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/twoPhase/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/twoPhase/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Define PINN model\n",
        "a = 0.5\n",
        "c = 2\n",
        "\n",
        "kernel_size = 300\n",
        "\n",
        "# Domain boundaries\n",
        "ics_coords = np.array([[0.0, 0.0],  [0.0, 1.0]])\n",
        "bc1_coords = np.array([[0.0, 0.0],  [1.0, 0.0]])\n",
        "bc2_coords = np.array([[0.0, 1.0],  [1.0, 1.0]])\n",
        "dom_coords = np.array([[0.0, 0.0],  [1.0, 1.0]])\n",
        "\n",
        "# Create initial conditions samplers\n",
        "ics_sampler = Sampler(2, ics_coords, lambda x: u(x, a, c), name='Initial Condition 1')\n",
        "\n",
        "# Create boundary conditions samplers\n",
        "bc1 = Sampler(2, bc1_coords, lambda x: u(x, a, c), name='Dirichlet BC1')\n",
        "bc2 = Sampler(2, bc2_coords, lambda x: u(x, a, c), name='Dirichlet BC2')\n",
        "bcs_sampler = [bc1, bc2]\n",
        "\n",
        "# Create residual sampler\n",
        "res_sampler = Sampler(2, dom_coords, lambda x: r(x, a, c), name='Forcing')\n",
        "\n",
        "\n",
        "\n",
        "nIter =40000\n",
        "bcbatch_size = 500\n",
        "ubatch_size = 5000\n",
        "mbbatch_size = 300\n",
        "\n",
        "\n",
        "\n",
        "# Define model\n",
        "mode = 'M4'\n",
        "layers = [2, 500, 500, 500, 1]\n",
        "\n",
        "\n",
        "nn = 200\n",
        "t = np.linspace(dom_coords[0, 0], dom_coords[1, 0], nn)[:, None]\n",
        "x = np.linspace(dom_coords[0, 1], dom_coords[1, 1], nn)[:, None]\n",
        "t, x = np.meshgrid(t, x)\n",
        "X_star = np.hstack((t.flatten()[:, None], x.flatten()[:, None]))\n",
        "\n",
        "u_star = u(X_star, a,c)\n",
        "r_star = r(X_star, a, c)\n",
        "\n",
        "iterations = 1\n",
        "methods = [  \"mini_batch\"]\n",
        "\n",
        "result_dict =  dict((mtd, []) for mtd in methods)\n",
        "\n",
        "for mtd in methods:\n",
        "    print(\"Method: \", mtd)\n",
        "    time_list = []\n",
        "    error_u_list = []\n",
        "    \n",
        "    for index in range(iterations):\n",
        "\n",
        "        print(\"Epoch: \", str(index+1))\n",
        "\n",
        "        # Create residual sampler\n",
        "\n",
        "\n",
        "        tf.reset_default_graph()\n",
        "        gpu_options = tf.GPUOptions(visible_device_list=\"0\")\n",
        "        with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options,allow_soft_placement=False, log_device_placement=False)) as sess:\n",
        "            # sess.run(init)\n",
        "\n",
        "            model = PINN(layers, operator, ics_sampler, bcs_sampler, res_sampler, c, kernel_size , sess)\n",
        "            # Train model\n",
        "            start_time = time.time()\n",
        "\n",
        "            if mtd ==\"full_batch\":\n",
        "                print(\"full_batch method is used\")\n",
        "                model.train(nIter  , bcbatch_size , ubatch_size  )\n",
        "            elif mtd ==\"mini_batch\":\n",
        "                print(\"mini_batch method is used\")\n",
        "                model.trainmb(nIter, mbbatch_size)\n",
        "            else:\n",
        "                print(\"unknown method!\")\n",
        "            elapsed = time.time() - start_time\n",
        "\n",
        "            # Predictions\n",
        "            u_pred = model.predict_u(X_star)\n",
        "            r_pred = model.predict_u(X_star)\n",
        "            # Predictions\n",
        "\n",
        "            sess.close()   \n",
        "\n",
        "        error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
        "        error_r = np.linalg.norm(r_star - r_pred, 2) #/ np.linalg.norm(u_star, 2)\n",
        "\n",
        "        print('elapsed: {:.2e}'.format(elapsed))\n",
        "\n",
        "        print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
        "        print('Relative L2 error_r: {:.2e}'.format(error_r))\n",
        "\n",
        "\n",
        "\n",
        "        print('elapsed: {:.2e}'.format(elapsed))\n",
        "        print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
        "\n",
        "        time_list.append(elapsed)\n",
        "        error_u_list.append(error_u)\n",
        "\n",
        "    print(\"\\n\\nMethod: \", mtd)\n",
        "    print(\"\\naverage of time_list:\" , sum(time_list) / len(time_list) )\n",
        "    print(\"average of error_u_list:\" , sum(error_u_list) / len(error_u_list) )\n",
        "    # print(\"average of error_r_list:\" , sum(error_r_list) / len(error_r_list) )\n",
        "\n",
        "    result_dict[mtd] = [time_list ,error_u_list]\n",
        "    # scipy.io.savemat(\"M2_result_\"+str(iterations)+\"_\"+mtd+\".mat\" , {'time_list':np.array(time_list),'error_u_list':np.array(error_u_list),'error_f_list':np.array(error_f_list)})\n",
        "\n",
        "    scipy.io.savemat(\"./1DWave_database/\"+mtd+\"_1Dwave_\"+mode+\"_result_mb\"+str(mbbatch_size)+\"_fb\"+str(ubatch_size)+\"_bc\"+str(mbbatch_size)+\"_\"+str(iterations)+\".mat\" , result_dict)\n",
        "\n",
        "###############################################################################################################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_10497/2458753082.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mu_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_u\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_star\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mr_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_r\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_star\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "# Predictions\n",
        "u_pred = model.predict_u(X_star)\n",
        "r_pred = model.predict_r(X_star)\n",
        "\n",
        "# Predictions\n",
        "\n",
        "error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
        "\n",
        "print('elapsed: {:.2e}'.format(elapsed))\n",
        "\n",
        "print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
        "\n",
        "U_star = griddata(X_star, u_star.flatten(), (t, x), method='cubic')\n",
        "r_star = griddata(X_star, r_star.flatten(), (t, x), method='cubic')\n",
        "U_pred = griddata(X_star, u_pred.flatten(), (t, x), method='cubic')\n",
        "# R_pred = griddata(X_star, r_pred.flatten(), (t, x), method='cubic')\n",
        "\n",
        "\n",
        "plt.figure(figsize=(18, 9))\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.pcolor(t, x, U_star, cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.title('Exact u(t, x)')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.pcolor(t, x, U_pred, cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$t$')\n",
        "plt.ylabel('$x$')\n",
        "plt.title('Predicted u(t, x)')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.pcolor(t, x, np.abs(U_star - U_pred), cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$t$')\n",
        "plt.ylabel('$x$')\n",
        "plt.title('Absolute error')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(2, 3, 4)\n",
        "plt.pcolor(t, x, r_star, cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$t$')\n",
        "plt.ylabel('$x$')\n",
        "plt.title('Exact r(t, x)')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(2, 3, 5)\n",
        "plt.pcolor(t, x, r_pred, cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$t$')\n",
        "plt.ylabel('$x$')\n",
        "plt.title('Predicted r(t, x)')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(2, 3, 6)\n",
        "plt.pcolor(t, x, np.abs(r_star - r_pred), cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$t$')\n",
        "plt.ylabel('$x$')\n",
        "plt.title('Absolute error')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YGFobW0EatXj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Method:  mini_batch\n",
            "Epoch:  1\n",
            "mini_batch method is used\n",
            "It: 100, Loss: 9.238e-01,  loss_bc1: 6.848e-02, loss_ics_u: 3.931e-01,  Loss_res: 6.576e-04 , Time: 4.89\n",
            "It: 200, Loss: 6.458e-01,  loss_bc1: 7.923e-02, loss_ics_u: 2.403e-01,  Loss_res: 6.826e-03 , Time: 3.53\n",
            "It: 300, Loss: 6.600e-01,  loss_bc1: 8.652e-02, loss_ics_u: 2.341e-01,  Loss_res: 1.875e-02 , Time: 3.44\n",
            "It: 400, Loss: 5.494e-01,  loss_bc1: 6.093e-02, loss_ics_u: 2.009e-01,  Loss_res: 2.586e-02 , Time: 3.43\n",
            "It: 500, Loss: 5.235e-01,  loss_bc1: 4.314e-02, loss_ics_u: 2.099e-01,  Loss_res: 1.742e-02 , Time: 3.35\n",
            "It: 600, Loss: 4.532e-01,  loss_bc1: 4.553e-02, loss_ics_u: 1.763e-01,  Loss_res: 9.461e-03 , Time: 3.27\n",
            "It: 700, Loss: 4.660e-01,  loss_bc1: 4.488e-02, loss_ics_u: 1.662e-01,  Loss_res: 4.375e-02 , Time: 3.38\n",
            "It: 800, Loss: 4.010e-01,  loss_bc1: 5.502e-02, loss_ics_u: 1.294e-01,  Loss_res: 3.213e-02 , Time: 3.22\n",
            "It: 900, Loss: 3.889e-01,  loss_bc1: 4.886e-02, loss_ics_u: 1.423e-01,  Loss_res: 6.523e-03 , Time: 3.26\n",
            "It: 1000, Loss: 4.760e-01,  loss_bc1: 3.239e-02, loss_ics_u: 1.614e-01,  Loss_res: 8.841e-02 , Time: 3.23\n",
            "loss_bc1: 3.239e+00\n",
            "loss_ics_u: 1.614e+01\n",
            "It: 1100, Loss: 4.028e+00,  loss_bc1: 2.087e-01, loss_ics_u: 2.050e-01,  Loss_res: 4.341e-02 , Time: 3.24\n",
            "It: 1200, Loss: 4.036e+00,  loss_bc1: 2.012e-01, loss_ics_u: 2.079e-01,  Loss_res: 2.821e-02 , Time: 3.24\n",
            "It: 1300, Loss: 3.089e+00,  loss_bc1: 1.975e-01, loss_ics_u: 1.486e-01,  Loss_res: 5.050e-02 , Time: 3.29\n",
            "It: 1400, Loss: 3.631e+00,  loss_bc1: 9.093e-02, loss_ics_u: 2.015e-01,  Loss_res: 8.446e-02 , Time: 3.25\n",
            "It: 1500, Loss: 3.205e+00,  loss_bc1: 1.203e-01, loss_ics_u: 1.708e-01,  Loss_res: 5.864e-02 , Time: 3.28\n",
            "It: 1600, Loss: 2.442e+00,  loss_bc1: 6.459e-02, loss_ics_u: 1.321e-01,  Loss_res: 1.004e-01 , Time: 3.25\n",
            "It: 1700, Loss: 1.988e+00,  loss_bc1: 5.784e-02, loss_ics_u: 1.060e-01,  Loss_res: 9.038e-02 , Time: 3.28\n",
            "It: 1800, Loss: 2.086e+00,  loss_bc1: 6.114e-02, loss_ics_u: 1.096e-01,  Loss_res: 1.187e-01 , Time: 3.30\n",
            "It: 1900, Loss: 1.798e+00,  loss_bc1: 5.601e-02, loss_ics_u: 9.710e-02,  Loss_res: 4.957e-02 , Time: 3.27\n",
            "It: 2000, Loss: 2.066e+00,  loss_bc1: 5.252e-02, loss_ics_u: 1.144e-01,  Loss_res: 4.957e-02 , Time: 3.29\n",
            "loss_bc1: 5.252e+00\n",
            "loss_ics_u: 1.144e+01\n",
            "It: 2100, Loss: 1.550e+00,  loss_bc1: 4.679e-02, loss_ics_u: 1.096e-01,  Loss_res: 5.031e-02 , Time: 3.31\n",
            "It: 2200, Loss: 1.371e+00,  loss_bc1: 4.520e-02, loss_ics_u: 9.635e-02,  Loss_res: 3.133e-02 , Time: 3.24\n",
            "It: 2300, Loss: 1.521e+00,  loss_bc1: 4.606e-02, loss_ics_u: 1.102e-01,  Loss_res: 1.778e-02 , Time: 3.20\n",
            "It: 2400, Loss: 1.439e+00,  loss_bc1: 4.217e-02, loss_ics_u: 1.018e-01,  Loss_res: 5.311e-02 , Time: 3.22\n",
            "It: 2500, Loss: 1.371e+00,  loss_bc1: 4.292e-02, loss_ics_u: 9.668e-02,  Loss_res: 3.920e-02 , Time: 3.22\n",
            "It: 2600, Loss: 1.398e+00,  loss_bc1: 4.434e-02, loss_ics_u: 1.003e-01,  Loss_res: 1.732e-02 , Time: 3.33\n",
            "It: 2700, Loss: 1.422e+00,  loss_bc1: 5.076e-02, loss_ics_u: 9.485e-02,  Loss_res: 6.997e-02 , Time: 3.22\n",
            "It: 2800, Loss: 1.420e+00,  loss_bc1: 4.226e-02, loss_ics_u: 1.026e-01,  Loss_res: 2.447e-02 , Time: 3.22\n",
            "It: 2900, Loss: 1.382e+00,  loss_bc1: 4.252e-02, loss_ics_u: 9.909e-02,  Loss_res: 2.485e-02 , Time: 3.21\n",
            "It: 3000, Loss: 1.566e+00,  loss_bc1: 3.510e-02, loss_ics_u: 1.161e-01,  Loss_res: 5.379e-02 , Time: 3.23\n",
            "loss_bc1: 3.510e+00\n",
            "loss_ics_u: 1.161e+01\n",
            "It: 3100, Loss: 1.250e+00,  loss_bc1: 4.534e-02, loss_ics_u: 9.202e-02,  Loss_res: 2.217e-02 , Time: 3.25\n",
            "It: 3200, Loss: 1.463e+00,  loss_bc1: 4.408e-02, loss_ics_u: 1.112e-01,  Loss_res: 1.781e-02 , Time: 3.22\n",
            "It: 3300, Loss: 1.234e+00,  loss_bc1: 4.673e-02, loss_ics_u: 9.008e-02,  Loss_res: 2.384e-02 , Time: 3.23\n",
            "It: 3400, Loss: 1.296e+00,  loss_bc1: 4.818e-02, loss_ics_u: 9.465e-02,  Loss_res: 2.827e-02 , Time: 3.19\n",
            "It: 3500, Loss: 1.202e+00,  loss_bc1: 4.031e-02, loss_ics_u: 8.907e-02,  Loss_res: 2.603e-02 , Time: 3.22\n",
            "It: 3600, Loss: 1.318e+00,  loss_bc1: 3.901e-02, loss_ics_u: 9.679e-02,  Loss_res: 5.757e-02 , Time: 3.22\n",
            "It: 3700, Loss: 1.339e+00,  loss_bc1: 4.521e-02, loss_ics_u: 9.347e-02,  Loss_res: 9.490e-02 , Time: 3.23\n",
            "It: 3800, Loss: 1.117e+00,  loss_bc1: 3.642e-02, loss_ics_u: 8.242e-02,  Loss_res: 3.266e-02 , Time: 3.23\n",
            "It: 3900, Loss: 1.193e+00,  loss_bc1: 3.797e-02, loss_ics_u: 8.865e-02,  Loss_res: 3.007e-02 , Time: 3.21\n",
            "It: 4000, Loss: 1.234e+00,  loss_bc1: 4.410e-02, loss_ics_u: 8.808e-02,  Loss_res: 5.626e-02 , Time: 3.26\n",
            "loss_bc1: 4.410e+00\n",
            "loss_ics_u: 8.808e+00\n",
            "It: 4100, Loss: 9.802e-01,  loss_bc1: 4.087e-02, loss_ics_u: 8.796e-02,  Loss_res: 2.525e-02 , Time: 3.23\n",
            "It: 4200, Loss: 7.871e-01,  loss_bc1: 3.142e-02, loss_ics_u: 7.091e-02,  Loss_res: 2.396e-02 , Time: 3.22\n",
            "It: 4300, Loss: 9.718e-01,  loss_bc1: 3.682e-02, loss_ics_u: 8.874e-02,  Loss_res: 2.785e-02 , Time: 3.20\n",
            "It: 4400, Loss: 9.642e-01,  loss_bc1: 3.058e-02, loss_ics_u: 9.060e-02,  Loss_res: 3.125e-02 , Time: 3.26\n",
            "It: 4500, Loss: 8.799e-01,  loss_bc1: 2.439e-02, loss_ics_u: 8.445e-02,  Loss_res: 2.850e-02 , Time: 3.32\n",
            "It: 4600, Loss: 9.538e-01,  loss_bc1: 2.985e-02, loss_ics_u: 9.104e-02,  Loss_res: 2.028e-02 , Time: 3.49\n",
            "It: 4700, Loss: 9.735e-01,  loss_bc1: 2.568e-02, loss_ics_u: 8.460e-02,  Loss_res: 1.151e-01 , Time: 3.21\n",
            "It: 4800, Loss: 1.139e+00,  loss_bc1: 3.047e-02, loss_ics_u: 8.349e-02,  Loss_res: 2.688e-01 , Time: 3.23\n",
            "It: 4900, Loss: 8.897e-01,  loss_bc1: 2.511e-02, loss_ics_u: 8.457e-02,  Loss_res: 3.410e-02 , Time: 3.27\n",
            "It: 5000, Loss: 8.940e-01,  loss_bc1: 2.638e-02, loss_ics_u: 8.533e-02,  Loss_res: 2.602e-02 , Time: 3.57\n",
            "loss_bc1: 2.638e+00\n",
            "loss_ics_u: 8.533e+00\n",
            "It: 5100, Loss: 7.650e-01,  loss_bc1: 2.841e-02, loss_ics_u: 7.593e-02,  Loss_res: 4.203e-02 , Time: 3.42\n",
            "It: 5200, Loss: 7.556e-01,  loss_bc1: 2.848e-02, loss_ics_u: 7.732e-02,  Loss_res: 2.066e-02 , Time: 3.46\n",
            "It: 5300, Loss: 8.372e-01,  loss_bc1: 2.470e-02, loss_ics_u: 8.721e-02,  Loss_res: 2.776e-02 , Time: 3.27\n",
            "It: 5400, Loss: 8.250e-01,  loss_bc1: 3.508e-02, loss_ics_u: 7.640e-02,  Loss_res: 8.048e-02 , Time: 3.37\n",
            "It: 5500, Loss: 7.433e-01,  loss_bc1: 3.176e-02, loss_ics_u: 7.389e-02,  Loss_res: 2.904e-02 , Time: 3.84\n",
            "It: 5600, Loss: 8.500e-01,  loss_bc1: 2.148e-02, loss_ics_u: 8.489e-02,  Loss_res: 6.889e-02 , Time: 3.76\n",
            "It: 5700, Loss: 8.856e-01,  loss_bc1: 2.965e-02, loss_ics_u: 8.233e-02,  Loss_res: 1.047e-01 , Time: 3.84\n",
            "It: 5800, Loss: 7.934e-01,  loss_bc1: 3.199e-02, loss_ics_u: 8.170e-02,  Loss_res: 1.185e-02 , Time: 4.21\n",
            "It: 5900, Loss: 6.295e-01,  loss_bc1: 2.616e-02, loss_ics_u: 6.469e-02,  Loss_res: 8.447e-03 , Time: 3.81\n",
            "It: 6000, Loss: 7.770e-01,  loss_bc1: 2.826e-02, loss_ics_u: 7.285e-02,  Loss_res: 8.075e-02 , Time: 3.30\n",
            "loss_bc1: 2.826e+00\n",
            "loss_ics_u: 7.285e+00\n",
            "It: 6100, Loss: 7.395e-01,  loss_bc1: 2.725e-02, loss_ics_u: 8.498e-02,  Loss_res: 4.339e-02 , Time: 3.26\n",
            "It: 6200, Loss: 6.320e-01,  loss_bc1: 2.240e-02, loss_ics_u: 7.337e-02,  Loss_res: 3.422e-02 , Time: 3.26\n",
            "It: 6300, Loss: 7.214e-01,  loss_bc1: 2.809e-02, loss_ics_u: 7.978e-02,  Loss_res: 6.084e-02 , Time: 3.37\n",
            "It: 6400, Loss: 6.903e-01,  loss_bc1: 2.062e-02, loss_ics_u: 8.453e-02,  Loss_res: 1.630e-02 , Time: 3.31\n",
            "It: 6500, Loss: 5.729e-01,  loss_bc1: 2.227e-02, loss_ics_u: 6.528e-02,  Loss_res: 3.439e-02 , Time: 3.25\n",
            "It: 6600, Loss: 6.427e-01,  loss_bc1: 2.084e-02, loss_ics_u: 7.847e-02,  Loss_res: 1.215e-02 , Time: 3.28\n",
            "It: 6700, Loss: 6.382e-01,  loss_bc1: 2.782e-02, loss_ics_u: 6.780e-02,  Loss_res: 6.566e-02 , Time: 3.34\n",
            "It: 6800, Loss: 7.090e-01,  loss_bc1: 3.071e-02, loss_ics_u: 8.264e-02,  Loss_res: 2.019e-02 , Time: 3.31\n",
            "It: 6900, Loss: 6.630e-01,  loss_bc1: 3.743e-02, loss_ics_u: 7.378e-02,  Loss_res: 1.977e-02 , Time: 3.27\n",
            "It: 7000, Loss: 5.993e-01,  loss_bc1: 2.533e-02, loss_ics_u: 7.067e-02,  Loss_res: 1.288e-02 , Time: 3.26\n",
            "loss_bc1: 2.533e+00\n",
            "loss_ics_u: 7.067e+00\n",
            "It: 7100, Loss: 5.544e-01,  loss_bc1: 1.875e-02, loss_ics_u: 7.023e-02,  Loss_res: 1.061e-02 , Time: 3.27\n",
            "It: 7200, Loss: 5.860e-01,  loss_bc1: 2.289e-02, loss_ics_u: 7.186e-02,  Loss_res: 2.016e-02 , Time: 3.29\n",
            "It: 7300, Loss: 5.804e-01,  loss_bc1: 2.950e-02, loss_ics_u: 6.364e-02,  Loss_res: 5.588e-02 , Time: 3.28\n",
            "It: 7400, Loss: 5.462e-01,  loss_bc1: 2.331e-02, loss_ics_u: 6.764e-02,  Loss_res: 9.172e-03 , Time: 3.27\n",
            "It: 7500, Loss: 8.304e-01,  loss_bc1: 3.285e-02, loss_ics_u: 7.115e-02,  Loss_res: 2.443e-01 , Time: 3.27\n",
            "It: 7600, Loss: 6.820e-01,  loss_bc1: 2.153e-02, loss_ics_u: 7.428e-02,  Loss_res: 1.026e-01 , Time: 3.29\n",
            "It: 7700, Loss: 7.606e-01,  loss_bc1: 4.626e-02, loss_ics_u: 7.817e-02,  Loss_res: 9.092e-02 , Time: 3.27\n",
            "It: 7800, Loss: 5.466e-01,  loss_bc1: 2.056e-02, loss_ics_u: 6.840e-02,  Loss_res: 1.107e-02 , Time: 3.27\n",
            "It: 7900, Loss: 5.074e-01,  loss_bc1: 2.721e-02, loss_ics_u: 6.056e-02,  Loss_res: 1.047e-02 , Time: 3.27\n",
            "It: 8000, Loss: 5.273e-01,  loss_bc1: 2.016e-02, loss_ics_u: 6.464e-02,  Loss_res: 1.944e-02 , Time: 3.29\n",
            "loss_bc1: 2.016e+00\n",
            "loss_ics_u: 6.464e+00\n",
            "It: 8100, Loss: 5.165e-01,  loss_bc1: 2.897e-02, loss_ics_u: 6.732e-02,  Loss_res: 2.294e-02 , Time: 3.25\n",
            "It: 8200, Loss: 5.093e-01,  loss_bc1: 2.612e-02, loss_ics_u: 6.808e-02,  Loss_res: 1.660e-02 , Time: 3.39\n",
            "It: 8300, Loss: 4.938e-01,  loss_bc1: 2.461e-02, loss_ics_u: 6.506e-02,  Loss_res: 2.366e-02 , Time: 3.26\n",
            "It: 8400, Loss: 4.566e-01,  loss_bc1: 2.211e-02, loss_ics_u: 6.029e-02,  Loss_res: 2.233e-02 , Time: 3.28\n",
            "It: 8500, Loss: 5.714e-01,  loss_bc1: 2.626e-02, loss_ics_u: 7.673e-02,  Loss_res: 2.248e-02 , Time: 3.28\n",
            "It: 8600, Loss: 5.056e-01,  loss_bc1: 1.853e-02, loss_ics_u: 7.116e-02,  Loss_res: 8.203e-03 , Time: 3.30\n",
            "It: 8700, Loss: 4.594e-01,  loss_bc1: 2.381e-02, loss_ics_u: 6.117e-02,  Loss_res: 1.599e-02 , Time: 3.26\n",
            "It: 8800, Loss: 5.830e-01,  loss_bc1: 3.105e-02, loss_ics_u: 6.247e-02,  Loss_res: 1.166e-01 , Time: 3.31\n",
            "It: 8900, Loss: 4.775e-01,  loss_bc1: 2.004e-02, loss_ics_u: 6.605e-02,  Loss_res: 1.014e-02 , Time: 3.55\n"
          ]
        }
      ],
      "source": [
        "# Define PINN model\n",
        "a = 0.5\n",
        "c = 2\n",
        "\n",
        "kernel_size = 300\n",
        "\n",
        "# Domain boundaries\n",
        "ics_coords = np.array([[0.0, 0.0],  [0.0, 1.0]])\n",
        "bc1_coords = np.array([[0.0, 0.0],  [1.0, 0.0]])\n",
        "bc2_coords = np.array([[0.0, 1.0],  [1.0, 1.0]])\n",
        "dom_coords = np.array([[0.0, 0.0],  [1.0, 1.0]])\n",
        "\n",
        "# Create initial conditions samplers\n",
        "ics_sampler = Sampler(2, ics_coords, lambda x: u(x, a, c), name='Initial Condition 1')\n",
        "\n",
        "# Create boundary conditions samplers\n",
        "bc1 = Sampler(2, bc1_coords, lambda x: u(x, a, c), name='Dirichlet BC1')\n",
        "bc2 = Sampler(2, bc2_coords, lambda x: u(x, a, c), name='Dirichlet BC2')\n",
        "bcs_sampler = [bc1, bc2]\n",
        "\n",
        "# Create residual sampler\n",
        "res_sampler = Sampler(2, dom_coords, lambda x: r(x, a, c), name='Forcing')\n",
        "\n",
        "\n",
        "\n",
        "nIter =40000\n",
        "bcbatch_size = 500\n",
        "ubatch_size = 5000\n",
        "mbbatch_size = 300\n",
        "\n",
        "\n",
        "\n",
        "# Define model\n",
        "mode = 'M4'\n",
        "layers = [2, 500, 500, 500, 1]\n",
        "\n",
        "\n",
        "nn = 200\n",
        "t = np.linspace(dom_coords[0, 0], dom_coords[1, 0], nn)[:, None]\n",
        "x = np.linspace(dom_coords[0, 1], dom_coords[1, 1], nn)[:, None]\n",
        "t, x = np.meshgrid(t, x)\n",
        "X_star = np.hstack((t.flatten()[:, None], x.flatten()[:, None]))\n",
        "\n",
        "u_star = u(X_star, a,c)\n",
        "r_star = r(X_star, a, c)\n",
        "\n",
        "iterations = 1\n",
        "methods = [  \"mini_batch\"]\n",
        "\n",
        "result_dict =  dict((mtd, []) for mtd in methods)\n",
        "\n",
        "for mtd in methods:\n",
        "    print(\"Method: \", mtd)\n",
        "    time_list = []\n",
        "    error_u_list = []\n",
        "    \n",
        "    for index in range(iterations):\n",
        "\n",
        "        print(\"Epoch: \", str(index+1))\n",
        "\n",
        "        # Create residual sampler\n",
        "\n",
        "        [elapsed, error_u] = test_method(mtd , layers,  ics_sampler, bcs_sampler, res_sampler, c ,kernel_size , X_star , u_star , r_star , nIter ,mbbatch_size , bcbatch_size , ubatch_size )\n",
        "\n",
        "\n",
        "        print('elapsed: {:.2e}'.format(elapsed))\n",
        "        print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
        "\n",
        "        time_list.append(elapsed)\n",
        "        error_u_list.append(error_u)\n",
        "\n",
        "    print(\"\\n\\nMethod: \", mtd)\n",
        "    print(\"\\naverage of time_list:\" , sum(time_list) / len(time_list) )\n",
        "    print(\"average of error_u_list:\" , sum(error_u_list) / len(error_u_list) )\n",
        "    # print(\"average of error_r_list:\" , sum(error_r_list) / len(error_r_list) )\n",
        "\n",
        "    result_dict[mtd] = [time_list ,error_u_list]\n",
        "    # scipy.io.savemat(\"M2_result_\"+str(iterations)+\"_\"+mtd+\".mat\" , {'time_list':np.array(time_list),'error_u_list':np.array(error_u_list),'error_f_list':np.array(error_f_list)})\n",
        "\n",
        "    scipy.io.savemat(\"./1DWave_database/\"+mtd+\"_1Dwave_\"+mode+\"_result_mb\"+str(mbbatch_size)+\"_fb\"+str(ubatch_size)+\"_bc\"+str(mbbatch_size)+\"_\"+str(iterations)+\".mat\" , result_dict)\n",
        "\n",
        "###############################################################################################################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define PINN model\n",
        "a = 0.5\n",
        "c = 2\n",
        "\n",
        "kernel_size = 300\n",
        "\n",
        "# Domain boundaries\n",
        "ics_coords = np.array([[0.0, 0.0],  [0.0, 1.0]])\n",
        "bc1_coords = np.array([[0.0, 0.0],  [1.0, 0.0]])\n",
        "bc2_coords = np.array([[0.0, 1.0],  [1.0, 1.0]])\n",
        "dom_coords = np.array([[0.0, 0.0],  [1.0, 1.0]])\n",
        "\n",
        "# Create initial conditions samplers\n",
        "ics_sampler = Sampler(2, ics_coords, lambda x: u(x, a, c), name='Initial Condition 1')\n",
        "\n",
        "# Create boundary conditions samplers\n",
        "bc1 = Sampler(2, bc1_coords, lambda x: u(x, a, c), name='Dirichlet BC1')\n",
        "bc2 = Sampler(2, bc2_coords, lambda x: u(x, a, c), name='Dirichlet BC2')\n",
        "bcs_sampler = [bc1, bc2]\n",
        "\n",
        "# Create residual sampler\n",
        "res_sampler = Sampler(2, dom_coords, lambda x: r(x, a, c), name='Forcing')\n",
        "\n",
        "\n",
        "\n",
        "nIter =40000\n",
        "bcbatch_size = 500\n",
        "ubatch_size = 5000\n",
        "mbbatch_size = 300\n",
        "\n",
        "\n",
        "\n",
        "# Define model\n",
        "mode = 'M4'\n",
        "layers = [2, 500, 500, 500, 1]\n",
        "\n",
        "\n",
        "nn = 200\n",
        "t = np.linspace(dom_coords[0, 0], dom_coords[1, 0], nn)[:, None]\n",
        "x = np.linspace(dom_coords[0, 1], dom_coords[1, 1], nn)[:, None]\n",
        "t, x = np.meshgrid(t, x)\n",
        "X_star = np.hstack((t.flatten()[:, None], x.flatten()[:, None]))\n",
        "\n",
        "u_star = u(X_star, a,c)\n",
        "r_star = r(X_star, a, c)\n",
        "\n",
        "iterations = 1\n",
        "methods = [  \"mini_batch\"]\n",
        "\n",
        "result_dict =  dict((mtd, []) for mtd in methods)\n",
        "\n",
        "for mtd in methods:\n",
        "    print(\"Method: \", mtd)\n",
        "    time_list = []\n",
        "    error_u_list = []\n",
        "    \n",
        "    for index in range(iterations):\n",
        "\n",
        "        print(\"Epoch: \", str(index+1))\n",
        "\n",
        "        # Create residual sampler\n",
        "\n",
        "        [elapsed, error_u] = test_method(mtd , layers,  ics_sampler, bcs_sampler, res_sampler, c ,kernel_size , X_star , u_star , r_star , nIter ,mbbatch_size , bcbatch_size , ubatch_size )\n",
        "\n",
        "\n",
        "        print('elapsed: {:.2e}'.format(elapsed))\n",
        "        print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
        "\n",
        "        time_list.append(elapsed)\n",
        "        error_u_list.append(error_u)\n",
        "\n",
        "    print(\"\\n\\nMethod: \", mtd)\n",
        "    print(\"\\naverage of time_list:\" , sum(time_list) / len(time_list) )\n",
        "    print(\"average of error_u_list:\" , sum(error_u_list) / len(error_u_list) )\n",
        "    # print(\"average of error_r_list:\" , sum(error_r_list) / len(error_r_list) )\n",
        "\n",
        "    result_dict[mtd] = [time_list ,error_u_list]\n",
        "    # scipy.io.savemat(\"M2_result_\"+str(iterations)+\"_\"+mtd+\".mat\" , {'time_list':np.array(time_list),'error_u_list':np.array(error_u_list),'error_f_list':np.array(error_f_list)})\n",
        "\n",
        "    scipy.io.savemat(\"./1DWave_database/\"+mtd+\"_1Dwave_\"+mode+\"_result_mb\"+str(mbbatch_size)+\"_fb\"+str(ubatch_size)+\"_bc\"+str(mbbatch_size)+\"_\"+str(iterations)+\".mat\" , result_dict)\n",
        "\n",
        "###############################################################################################################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZtWEM9-brXF",
        "outputId": "371feba5-fed5-41cb-9e3e-5c8497c4fbe6"
      },
      "outputs": [],
      "source": [
        "\n",
        "import scipy.io\n",
        "\n",
        "mode = 'M4'\n",
        "mbbatch_size = 128\n",
        "ubatch_size = 5000\n",
        "bcbatch_size = 500\n",
        "iterations = 40000\n",
        "\n",
        "time_list = []\n",
        "error_u_list = []\n",
        "error_v_list = []\n",
        "error_p_list = []\n",
        "    \n",
        "methods = [\"mini_batch\" , \"full_batch\"]\n",
        "result_dict =  dict((mtd, []) for mtd in methods)\n",
        "\n",
        "##Mini Batch\n",
        "time_list = []\n",
        "error_u_list = [ ]\n",
        "\n",
        "\n",
        "result_dict[\"mini_batch\"] = [time_list ,error_u_list]\n",
        "\n",
        "print(\"\\n\\nMethod: \", mtd)\n",
        "print(\"\\naverage of time_list:\" , sum(time_list) / len(time_list) )\n",
        "print(\"average of error_u_list:\" , sum(error_u_list) / len(error_u_list) )\n",
        "\n",
        "##Full Batch\n",
        "time_list = []\n",
        "error_u_list = [ ]\n",
        "error_v_list = []\n",
        "error_p_list = []\n",
        "\n",
        "result_dict[\"full_batch\"] = [time_list ,error_u_list ,error_v_list ,  error_p_list]\n",
        "\n",
        "print(\"\\n\\nMethod: \", mtd)\n",
        "print(\"\\naverage of time_list:\" , sum(time_list) / len(time_list) )\n",
        "print(\"average of error_u_list:\" , sum(error_u_list) / len(error_u_list) )\n",
        "print(\"average of error_v_list:\" , sum(error_v_list) / len(error_v_list) )\n",
        "print(\"average of error_p_list:\" , sum(error_p_list) / len(error_p_list) )\n",
        "\n",
        "\n",
        "scipy.io.savemat(\"./dataset/1DWave_database_\"+mode+\"_result_mb\"+str(mbbatch_size)+\"_fb\"+str(ubatch_size)+\"_\"+str(bcbatch_size)+\"_\"+str(iterations)+\".mat\" , result_dict)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vF1hwPUobyPE"
      },
      "outputs": [],
      "source": [
        "# Train model\n",
        "itertaions = 80001\n",
        "log_NTK = True # Compute and store NTK matrix during training\n",
        "update_lam = True # Compute and update the loss weights using the NTK \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiyikOwBjRoZ"
      },
      "source": [
        "**Training Loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "Fw807UNzhu5z",
        "outputId": "f4551313-ffbc-49b5-8fd3-1296fc1641fe"
      },
      "outputs": [],
      "source": [
        "loss_res = model.loss_res_log\n",
        "loss_bcs = model.loss_bcs_log\n",
        "loss_u_t_ics = model.loss_ut_ics_log\n",
        "\n",
        "fig = plt.figure(figsize=(6, 5))\n",
        "plt.plot(loss_res, label='$\\mathcal{L}_{r}$')\n",
        "plt.plot(loss_bcs, label='$\\mathcal{L}_{u}$')\n",
        "plt.plot(loss_u_t_ics, label='$\\mathcal{L}_{u_t}$')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFLIBq5xjZ3v"
      },
      "source": [
        "**Model Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "To0PDN17cc0v",
        "outputId": "1f47f288-322a-46b5-f173-45485191a68d"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Predictions\n",
        "u_pred = model.predict_u(X_star)\n",
        "r_pred = model.predict_r(X_star)\n",
        "error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
        "\n",
        "print('Relative L2 error_u: %e' % (error_u))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "id": "K428lOuXhdc8",
        "outputId": "015f591b-d8a4-4e47-8020-84fcf219d7ca"
      },
      "outputs": [],
      "source": [
        "U_star = griddata(X_star, u_star.flatten(), (t, x), method='cubic')\n",
        "r_star = griddata(X_star, r_star.flatten(), (t, x), method='cubic')\n",
        "U_pred = griddata(X_star, u_pred.flatten(), (t, x), method='cubic')\n",
        "R_pred = griddata(X_star, r_pred.flatten(), (t, x), method='cubic')\n",
        "\n",
        "\n",
        "plt.figure(figsize=(18, 9))\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.pcolor(t, x, U_star, cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.title('Exact u(t, x)')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.pcolor(t, x, U_pred, cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$t$')\n",
        "plt.ylabel('$x$')\n",
        "plt.title('Predicted u(t, x)')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.pcolor(t, x, np.abs(U_star - U_pred), cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$t$')\n",
        "plt.ylabel('$x$')\n",
        "plt.title('Absolute error')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(2, 3, 4)\n",
        "plt.pcolor(t, x, r_star, cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$t$')\n",
        "plt.ylabel('$x$')\n",
        "plt.title('Exact r(t, x)')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(2, 3, 5)\n",
        "plt.pcolor(t, x, R_pred, cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$t$')\n",
        "plt.ylabel('$x$')\n",
        "plt.title('Predicted r(t, x)')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(2, 3, 6)\n",
        "plt.pcolor(t, x, np.abs(r_star - R_pred), cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$t$')\n",
        "plt.ylabel('$x$')\n",
        "plt.title('Absolute error')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EYdfKGLj6h0"
      },
      "source": [
        "**NTK Eigenvalues**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3dByeQjhBYj"
      },
      "outputs": [],
      "source": [
        "# Create empty lists for storing the eigenvalues of NTK\n",
        "lam_K_u_log = []\n",
        "lam_K_ut_log = []\n",
        "lam_K_r_log = []\n",
        "\n",
        "# Restore the NTK\n",
        "K_u_list = model.K_u_log\n",
        "K_ut_list = model.K_ut_log\n",
        "K_r_list = model.K_r_log\n",
        "\n",
        "K_list = []\n",
        "    \n",
        "for k in range(len(K_u_list)):\n",
        "    K_u = K_u_list[k]\n",
        "    K_ut = K_ut_list[k]\n",
        "    K_r = K_r_list[k]\n",
        "    \n",
        "    # Compute eigenvalues\n",
        "    lam_K_u, _ = np.linalg.eig(K_u)\n",
        "    lam_K_ut, _ = np.linalg.eig(K_ut)\n",
        "    lam_K_r, _ = np.linalg.eig(K_r)\n",
        "    # Sort in descresing order\n",
        "    lam_K_u = np.sort(np.real(lam_K_u))[::-1]\n",
        "    lam_K_ut = np.sort(np.real(lam_K_ut))[::-1]\n",
        "    lam_K_r = np.sort(np.real(lam_K_r))[::-1]\n",
        "    \n",
        "    # Store eigenvalues\n",
        "    lam_K_u_log.append(lam_K_u)\n",
        "    lam_K_ut_log.append(lam_K_ut)\n",
        "    lam_K_r_log.append(lam_K_r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "vSn3Q_1IhisN",
        "outputId": "886908b3-c316-48d6-933f-81b1180ff954"
      },
      "outputs": [],
      "source": [
        "#  Eigenvalues of NTK\n",
        "fig = plt.figure(figsize=(18, 5))\n",
        "plt.subplot(1,3,1)\n",
        "\n",
        "plt.plot(lam_K_u_log[0], label = '$n=0$')\n",
        "plt.plot(lam_K_u_log[1], '--', label = '$n=10,000$')\n",
        "plt.plot(lam_K_u_log[4], '--', label = '$n=40,000$')\n",
        "plt.plot(lam_K_u_log[-1], '--', label = '$n=80,000$')\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "\n",
        "plt.title(r'Eigenvalues of ${K}_u$')\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.plot(lam_K_ut_log[0], label = '$n=0$')\n",
        "plt.plot(lam_K_ut_log[1], '--',label = '$n=10,000$')\n",
        "plt.plot(lam_K_ut_log[4], '--', label = '$n=40,000$')\n",
        "plt.plot(lam_K_ut_log[-1], '--', label = '$n=80,000$')\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.title(r'Eigenvalues of ${K}_{u_t}$')\n",
        "\n",
        "ax =plt.subplot(1,3,3)\n",
        "plt.plot(lam_K_r_log[0], label = '$n=0$')\n",
        "plt.plot(lam_K_r_log[1], '--', label = '$n=10,000$')\n",
        "plt.plot(lam_K_r_log[4], '--', label = '$n=40,000$')\n",
        "plt.plot(lam_K_r_log[-1], '--', label = '$n=80,000$')\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.title(r'Eigenvalues of ${K}_{r}$')\n",
        "handles, labels = ax.get_legend_handles_labels()\n",
        "fig.legend(handles, labels, loc=\"upper left\", bbox_to_anchor=(0.35, -0.02),\n",
        "            borderaxespad=0, bbox_transform=fig.transFigure, ncol=4)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbUn_fcowojl"
      },
      "source": [
        "**Evolution of NTK Weights**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYbzkhfMjJ8k"
      },
      "outputs": [],
      "source": [
        "if update_lam == True:\n",
        "\n",
        "  lam_u_log = model.lam_u_log\n",
        "  lam_ut_log = model.lam_ut_log\n",
        "  lam_r_log = model.lam_r_log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "xzFzPCA2w1ML",
        "outputId": "71452cf9-3ebb-4aeb-9708-c7664b88e65d"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(6, 5))\n",
        "plt.plot(lam_u_log, label='$\\lambda_u$')\n",
        "plt.plot(lam_ut_log, label='$\\lambda_{u_t}$')\n",
        "plt.plot(lam_r_log, label='$\\lambda_{r}$')\n",
        "plt.xlabel('iterations')\n",
        "plt.ylabel('$\\lambda$')\n",
        "plt.yscale('log')\n",
        "plt.legend( )\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mimIv2Z5xlip"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PINNsNTK_Wave.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
