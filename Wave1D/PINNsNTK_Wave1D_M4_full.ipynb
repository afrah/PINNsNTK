{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7WkCgnRiYQSY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from Compute_Jacobian import jacobian # Please download 'Compute_Jacobian.py' in the repository \n",
        "import numpy as np\n",
        "import timeit\n",
        "from scipy.interpolate import griddata\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "os.environ[\"KMP_WARNINGS\"] = \"FALSE\" \n",
        "import timeit\n",
        "\n",
        "import sys\n",
        "\n",
        "import scipy\n",
        "import scipy.io\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-y7cHTcJfBTR"
      },
      "outputs": [],
      "source": [
        "class Sampler:\n",
        "    # Initialize the class\n",
        "    def __init__(self, dim, coords, func, name = None):\n",
        "        self.dim = dim\n",
        "        self.coords = coords\n",
        "        self.func = func\n",
        "        self.name = name\n",
        "    def sample(self, N):\n",
        "        x = self.coords[0:1,:] + (self.coords[1:2,:]-self.coords[0:1,:])*np.random.rand(N, self.dim)\n",
        "        y = self.func(x)\n",
        "        return x, y\n",
        "\n",
        "# Define the exact solution and its derivatives\n",
        "def u(x, a, c):\n",
        "    \"\"\"\n",
        "    :param x: x = (t, x)\n",
        "    \"\"\"\n",
        "    t = x[:,0:1]\n",
        "    x = x[:,1:2]\n",
        "    return np.sin(np.pi * x) * np.cos(c * np.pi * t) + a * np.sin(2 * c * np.pi* x) * np.cos(4 * c  * np.pi * t)\n",
        "\n",
        "def u_t(x,a, c):\n",
        "    t = x[:,0:1]\n",
        "    x = x[:,1:2]\n",
        "    u_t = -  c * np.pi * np.sin(np.pi * x) * np.sin(c * np.pi * t) -  a * 4 * c * np.pi * np.sin(2 * c * np.pi* x) * np.sin(4 * c * np.pi * t)\n",
        "    return u_t\n",
        "\n",
        "def u_tt(x, a, c):\n",
        "    t = x[:,0:1]\n",
        "    x = x[:,1:2]\n",
        "    u_tt = -(c * np.pi)**2 * np.sin( np.pi * x) * np.cos(c * np.pi * t) - a * (4 * c * np.pi)**2 *  np.sin(2 * c * np.pi* x) * np.cos(4 * c * np.pi * t)\n",
        "    return u_tt\n",
        "\n",
        "def u_xx(x, a, c):\n",
        "    t = x[:,0:1]\n",
        "    x = x[:,1:2]\n",
        "    u_xx = - np.pi**2 * np.sin( np.pi * x) * np.cos(c * np.pi * t) -  a * (2 * c * np.pi)** 2 * np.sin(2 * c * np.pi* x) * np.cos(4 * c * np.pi * t)\n",
        "    return  u_xx\n",
        "\n",
        "\n",
        "def r(x, a, c):\n",
        "    return u_tt(x, a, c) - c**2 * u_xx(x, a, c)\n",
        "\n",
        "def operator(u, t, x, c, sigma_t=1.0, sigma_x=1.0):\n",
        "    u_t = tf.gradients(u, t)[0] / sigma_t\n",
        "    u_x = tf.gradients(u, x)[0] / sigma_x\n",
        "    u_tt = tf.gradients(u_t, t)[0] / sigma_t\n",
        "    u_xx = tf.gradients(u_x, x)[0] / sigma_x\n",
        "    residual = u_tt - c**2 * u_xx\n",
        "    return residual\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SDqDWN3nfSAg"
      },
      "outputs": [],
      "source": [
        "class PINN:\n",
        "    # Initialize the class\n",
        "    def __init__(self, layers, operator, ics_sampler, bcs_sampler, res_sampler, c, kernel_size , sess):\n",
        "        # Normalization \n",
        "        X, _ = res_sampler.sample(np.int32(1e5))\n",
        "        self.mu_X, self.sigma_X = X.mean(0), X.std(0)\n",
        "        self.mu_t, self.sigma_t = self.mu_X[0], self.sigma_X[0]\n",
        "        self.mu_x, self.sigma_x = self.mu_X[1], self.sigma_X[1]\n",
        "\n",
        "\n",
        "        # Samplers\n",
        "        self.operator = operator\n",
        "        self.ics_sampler = ics_sampler\n",
        "        self.bcs_sampler = bcs_sampler\n",
        "        self.res_sampler = res_sampler\n",
        "\n",
        "        self.sess = sess\n",
        "        # Initialize network weights and biases\n",
        "        self.layers = layers\n",
        "        self.weights, self.biases = self.initialize_NN(layers)\n",
        "        \n",
        "        # weights\n",
        "        self.lam_u_val = np.array(100.0)\n",
        "        self.lam_ut_val = np.array(100.0)\n",
        "        self.lam_r_val = np.array(1.0)\n",
        "        self.lam_bc1_val = np.array(100.0)\n",
        "        self.lam_bc2_val = np.array(100.0)\n",
        "      \n",
        "        # Wave constant\n",
        "        self.c = tf.constant(c, dtype=tf.float32)\n",
        "        \n",
        "        self.kernel_size = kernel_size # Size of the NTK matrix\n",
        "\n",
        "        # Define Tensorflow session\n",
        "        self.sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
        "\n",
        "        # Define placeholders and computational graph\n",
        "        self.t_u_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.x_u_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "\n",
        "        self.t_ics_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.x_ics_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.u_ics_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "\n",
        "        self.t_bc1_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.x_bc1_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "\n",
        "        self.t_bc2_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.x_bc2_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "\n",
        "        self.t_r_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        self.x_r_tf = tf.placeholder(tf.float32, shape=(None, 1))\n",
        "        \n",
        "        self.lam_u_tf = tf.placeholder(tf.float32, shape=self.lam_u_val.shape)\n",
        "        self.lam_ut_tf = tf.placeholder(tf.float32, shape=self.lam_u_val.shape)\n",
        "        self.lam_r_tf = tf.placeholder(tf.float32, shape=self.lam_u_val.shape)\n",
        "        self.lam_bc1_tf = tf.placeholder(tf.float32, shape=self.lam_bc1_val.shape)\n",
        "        self.lam_bc2_tf = tf.placeholder(tf.float32, shape=self.lam_bc2_val.shape)\n",
        "        \n",
        "\n",
        "        self.u_pred = self.net_u(self.t_u_tf, self.x_u_tf)\n",
        "\n",
        "\n",
        "        # Evaluate predictions\n",
        "        self.u_ics_pred = self.net_u(self.t_ics_tf, self.x_ics_tf)\n",
        "        self.u_t_ics_pred = self.net_u_t(self.t_ics_tf, self.x_ics_tf)\n",
        "        self.u_bc1_pred = self.net_u(self.t_bc1_tf, self.x_bc1_tf)\n",
        "        self.u_bc2_pred = self.net_u(self.t_bc2_tf, self.x_bc2_tf)\n",
        "\n",
        "        self.r_pred = self.net_r(self.t_r_tf, self.x_r_tf)\n",
        "        \n",
        "        \n",
        "        # Boundary loss and Initial loss\n",
        "        self.loss_ics_u = tf.reduce_mean(tf.square(self.u_ics_tf - self.u_ics_pred)  +  tf.square( tf.gradients(self.u_ics_pred, self.t_ics_tf)[0] / self.sigma_t) )\n",
        "        self.loss_ics_u_t = tf.reduce_mean(tf.square(self.u_t_ics_pred))\n",
        "        self.loss_bc1 = tf.reduce_mean(tf.square(self.u_bc1_pred))\n",
        "        self.loss_bc2 = tf.reduce_mean(tf.square(self.u_bc2_pred))\n",
        "\n",
        "        self.loss_bcs = self.loss_ics_u + self.loss_bc1 + self.loss_bc2\n",
        "\n",
        "        # Residual loss\n",
        "        self.loss_res = tf.reduce_mean(tf.square(self.r_pred))\n",
        "\n",
        "        # Total loss\n",
        "        self.loss = self.lam_r_tf * self.loss_res + self.lam_bc1_tf * self.loss_bc1 + self.lam_bc2_tf * self.loss_bc2 + self.lam_u_tf * self.loss_ics_u # + self.lam_ut_tf * self.loss_ics_u_t \n",
        "\n",
        "        # Define optimizer with learning rate schedule\n",
        "        self.global_step = tf.Variable(0, trainable=False)\n",
        "        starter_learning_rate = 1e-3\n",
        "        self.learning_rate = tf.train.exponential_decay(starter_learning_rate, self.global_step,  1000, 0.9, staircase=False)\n",
        "        # Passing global_step to minimize() will increment it at each step.\n",
        "        self.train_op = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss, global_step=self.global_step)\n",
        "        \n",
        "         # Initialize Tensorflow variables\n",
        "        init = tf.global_variables_initializer()\n",
        "        self.sess.run(init)\n",
        "\n",
        "    # Initialize network weights and biases using Xavier initialization\n",
        "    def initialize_NN(self, layers):\n",
        "        # Xavier initialization\n",
        "        def xavier_init(size):\n",
        "            in_dim = size[0]\n",
        "            out_dim = size[1]\n",
        "            xavier_stddev = 1. / np.sqrt((in_dim + out_dim) / 2.)\n",
        "            return tf.Variable(tf.random.normal([in_dim, out_dim], dtype=tf.float32) * xavier_stddev,  dtype=tf.float32)\n",
        "\n",
        "        weights = []\n",
        "        biases = []\n",
        "        num_layers = len(layers)\n",
        "        for l in range(0, num_layers - 1):\n",
        "            W = xavier_init(size=[layers[l], layers[l + 1]])\n",
        "            b = tf.Variable(tf.zeros([1, layers[l + 1]], dtype=tf.float32), dtype=tf.float32)\n",
        "            weights.append(W)\n",
        "            biases.append(b)\n",
        "        return weights, biases\n",
        "\n",
        "    # Evaluates the forward pass\n",
        "    def forward_pass(self, H, layers, weights, biases):\n",
        "        num_layers = len(layers)\n",
        "        for l in range(0, num_layers - 2):\n",
        "            W = weights[l]\n",
        "            b = biases[l]\n",
        "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
        "        W = weights[-1]\n",
        "        b = biases[-1]\n",
        "        H = tf.add(tf.matmul(H, W), b)\n",
        "        return H\n",
        "\n",
        "    # Forward pass for u\n",
        "    def net_u(self, t, x):\n",
        "        u = self.forward_pass(tf.concat([t, x], 1),  self.layers, self.weights, self.biases)\n",
        "        return u\n",
        "\n",
        "    # Forward pass for du/dt\n",
        "    def net_u_t(self, t, x):\n",
        "        u_t = tf.gradients(self.net_u(t, x), t)[0] / self.sigma_t\n",
        "        return u_t\n",
        "\n",
        "    # Forward pass for the residual\n",
        "    def net_r(self, t, x):\n",
        "        u = self.net_u(t, x)\n",
        "        residual = self.operator(u, t, x, self.c, self.sigma_t,  self.sigma_x)\n",
        "        return residual\n",
        "    \n",
        "    \n",
        "\n",
        "    def fetch_minibatch(self, sampler, N):\n",
        "        X, Y = sampler.sample(N)\n",
        "        X = (X - self.mu_X) / self.sigma_X\n",
        "        return X, Y\n",
        "\n",
        "        # Trains the model by minimizing the MSE loss\n",
        "\n",
        "    def trainmb(self, nIter=10000, batch_size=128, log_NTK=False, update_lam=False):\n",
        "\n",
        "        start_time = timeit.default_timer()\n",
        "        for it in range(1 , nIter):\n",
        "            # Fetch boundary mini-batches\n",
        "            X_ics_batch, u_ics_batch = self.fetch_minibatch(self.ics_sampler, batch_size // 3)\n",
        "            X_bc1_batch, _ = self.fetch_minibatch(self.bcs_sampler[0], batch_size // 3)\n",
        "            X_bc2_batch, _ = self.fetch_minibatch(self.bcs_sampler[1], batch_size // 3)\n",
        "            \n",
        "            # Fetch residual mini-batch\n",
        "            X_res_batch, _ = self.fetch_minibatch(self.res_sampler, batch_size)\n",
        "            # Define a dictionary for associating placeholders with data\n",
        "            tf_dict = {self.t_ics_tf: X_ics_batch[:, 0:1], self.x_ics_tf: X_ics_batch[:, 1:2],\n",
        "                       self.u_ics_tf: u_ics_batch,\n",
        "                       self.t_bc1_tf: X_bc1_batch[:, 0:1], self.x_bc1_tf: X_bc1_batch[:, 1:2],\n",
        "                       self.t_bc2_tf: X_bc2_batch[:, 0:1], self.x_bc2_tf: X_bc2_batch[:, 1:2],\n",
        "                       self.t_r_tf: X_res_batch[:, 0:1], self.x_r_tf: X_res_batch[:, 1:2],\n",
        "                       self.lam_u_tf: self.lam_u_val,\n",
        "                    #    self.lam_ut_tf: self.lam_ut_val,\n",
        "                       self.lam_r_tf: self.lam_r_val,\n",
        "                       self.lam_bc1_tf: self.lam_bc1_val,\n",
        "                       self.lam_bc2_tf: self.lam_bc2_val,\n",
        "                       }\n",
        "\n",
        "            # Run the Tensorflow session to minimize the loss\n",
        "            self.sess.run(self.train_op, tf_dict)\n",
        "\n",
        "            # Print\n",
        "            if it % 100 == 0:\n",
        "                elapsed = timeit.default_timer() - start_time\n",
        "\n",
        "                loss = self.sess.run(self.loss, tf_dict)\n",
        "                loss_bc1 = self.sess.run(self.loss_bc1, tf_dict)\n",
        "                loss_bc2 = self.sess.run(self.loss_bc2, tf_dict)\n",
        "                loss_ics_u = self.sess.run(self.loss_ics_u, tf_dict)\n",
        "                loss_ics_u_t = self.sess.run(self.loss_ics_u_t, tf_dict)\n",
        "                loss_res = self.sess.run(self.loss_res, tf_dict)\n",
        "\n",
        "                # # Store losses\n",
        "                # self.loss_bcs_log.append(loss_bcs_value)\n",
        "                # self.loss_res_log.append(loss_res_value)\n",
        "                # self.loss_ut_ics_log.append(loss_ics_ut_value)\n",
        "\n",
        "                print('It: %d, Loss: %.3e,  loss_bc1: %.3e,  loss_bc2: %.3e, loss_ics_u: %.3e, loss_ics_u_t: %.3e, Loss_res: %.3e , Time: %.2f' %(it, loss, loss_bc1, loss_bc2 ,loss_ics_u, loss_ics_u_t, loss_res , elapsed))\n",
        "                \n",
        " \n",
        "                start_time = timeit.default_timer()\n",
        "            \n",
        "          \n",
        "                if it % 1000 == 0: \n",
        "\n",
        "                        loss_bc1, loss_bc2 , loss_ics_u, loss_ics_u_t , loss_res =  self.sess.run([self.loss_bc1,self.loss_bc2, self.loss_ics_u, self.loss_ics_u_t, self.loss_res], tf_dict)\n",
        "\n",
        "                        alpha   = 1000\n",
        "                        self.lam_bc1_val = alpha * loss_bc1\n",
        "                        self.lam_bc2_val = alpha * loss_bc2\n",
        "                        self.lam_u_val = alpha * loss_ics_u\n",
        "                        # self.lam_ut_val = alpha * loss_ics_u_t\n",
        "                        self.lam_r_val = alpha * loss_res\n",
        "\n",
        "                        print('loss_bc1: {:.3e}'.format(self.lam_bc1_val))\n",
        "                        print('loss_bc2: {:.3e}'.format(self.lam_bc2_val))\n",
        "                        print('loss_ics_u: {:.3e}'.format(self.lam_u_val))\n",
        "                        # print('lam_ut_val: {:.3e}'.format(self.lam_ut_val))\n",
        "                        print('lam_r_val: {:.3e}'.format(self.lam_r_val))\n",
        "                sys.stdout.flush()\n",
        "\n",
        "    def train(self, nIter , bcbatch_size , ubatch_size):\n",
        "\n",
        "        start_time = timeit.default_timer()\n",
        "\n",
        "        # Fetch boundary mini-batches\n",
        "        X_ics_batch, u_ics_batch = self.fetch_minibatch(self.ics_sampler, bcbatch_size)\n",
        "        X_bc1_batch, _ = self.fetch_minibatch(self.bcs_sampler[0], bcbatch_size )\n",
        "        X_bc2_batch, _ = self.fetch_minibatch(self.bcs_sampler[1], bcbatch_size )\n",
        "        \n",
        "        # Fetch residual mini-batch\n",
        "        X_res_batch, _ = self.fetch_minibatch(self.res_sampler, ubatch_size)\n",
        "        # print(\"inside trainmb: \" , X_res_batch.shape)\n",
        "        # Define a dictionary for associating placeholders with data\n",
        "        tf_dict = {self.t_ics_tf: X_ics_batch[:, 0:1], self.x_ics_tf: X_ics_batch[:, 1:2],\n",
        "                    self.u_ics_tf: u_ics_batch,\n",
        "                    self.t_bc1_tf: X_bc1_batch[:, 0:1], self.x_bc1_tf: X_bc1_batch[:, 1:2],\n",
        "                    self.t_bc2_tf: X_bc2_batch[:, 0:1], self.x_bc2_tf: X_bc2_batch[:, 1:2],\n",
        "                    self.t_r_tf: X_res_batch[:, 0:1], self.x_r_tf: X_res_batch[:, 1:2],\n",
        "                    self.lam_u_tf: self.lam_u_val,\n",
        "                    # self.lam_ut_tf: self.lam_ut_val,\n",
        "                    self.lam_r_tf: self.lam_r_val,\n",
        "                       self.lam_bc1_tf: self.lam_bc1_val,\n",
        "                       self.lam_bc2_tf: self.lam_bc2_val,\n",
        "                       }\n",
        "        \n",
        "   \n",
        "  \n",
        "        for it in range(1,nIter):\n",
        "\n",
        "            # Run the Tensorflow session to minimize the loss\n",
        "            self.sess.run(self.train_op, tf_dict)\n",
        "\n",
        "            # Print\n",
        "            if it % 100 == 0:\n",
        "                elapsed = timeit.default_timer() - start_time\n",
        "\n",
        "                loss = self.sess.run(self.loss, tf_dict)\n",
        "                loss_bc1 = self.sess.run(self.loss_bc1, tf_dict)\n",
        "                loss_bc2 = self.sess.run(self.loss_bc2, tf_dict)\n",
        "                loss_ics_u = self.sess.run(self.loss_ics_u, tf_dict)\n",
        "                loss_ics_u_t = self.sess.run(self.loss_ics_u_t, tf_dict)\n",
        "                loss_res = self.sess.run(self.loss_res, tf_dict)\n",
        "\n",
        "                # # Store losses\n",
        "                # self.loss_bcs_log.append(loss_bcs_value)\n",
        "                # self.loss_res_log.append(loss_res_value)\n",
        "                # self.loss_ut_ics_log.append(loss_ics_ut_value)\n",
        "\n",
        "                print('It: %d, Loss: %.3e,  loss_bc1: %.3e,  loss_bc2: %.3e, loss_ics_u: %.3e, loss_ics_u_t: %.3e, Loss_res: %.3e , Time: %.2f' %(it, loss, loss_bc1, loss_bc2 ,loss_ics_u, loss_ics_u_t, loss_res , elapsed))\n",
        "                \n",
        "                start_time = timeit.default_timer()\n",
        "            \n",
        "          \n",
        "                if it % 100 == 0: \n",
        "                        alpha   = 10000\n",
        "                        self.lam_bc1_val = alpha * loss_bc1\n",
        "                        # self.lam_bc2_val = alpha * loss_bc2\n",
        "                        self.lam_u_val = alpha * loss_ics_u\n",
        "\n",
        "                        print('loss_bc1: {:.3e}'.format(self.lam_bc1_val))\n",
        "                        # print('loss_bc2: {:.3e}'.format(self.lam_bc2_val))\n",
        "                        print('loss_ics_u: {:.3e}'.format(self.lam_u_val))\n",
        "                sys.stdout.flush()\n",
        "\n",
        "    # Evaluates predictions at test points\n",
        "    def predict_u(self, X_star):\n",
        "        X_star = (X_star - self.mu_X) / self.sigma_X\n",
        "        tf_dict = {self.t_u_tf: X_star[:, 0:1], self.x_u_tf: X_star[:, 1:2]}\n",
        "        u_star = self.sess.run(self.u_pred, tf_dict)\n",
        "        return u_star\n",
        "\n",
        "        # Evaluates predictions at test points\n",
        "\n",
        "    def predict_r(self, X_star):\n",
        "        X_star = (X_star - self.mu_X) / self.sigma_X\n",
        "        tf_dict = {self.t_r_tf: X_star[:, 0:1], self.x_r_tf: X_star[:, 1:2]}\n",
        "        r_star = self.sess.run(self.r_pred, tf_dict)\n",
        "        return r_star\n",
        "    \n",
        "   ###############################################################################################################################################\n",
        "   # \n",
        "   # ###############################################################################################################################################\n",
        "   # \n",
        "   # ###############################################################################################################################################\n",
        "   # \n",
        "   #  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "#test_method(mtd , layers,  X_u, Y_u, X_r, Y_r ,  X_star , u_star , r_star  , nIter ,batch_size , bcbatch_size , ubatch_size)\n",
        "def test_method(method , layers,  ics_sampler, bcs_sampler, res_sampler, c ,kernel_size , X_star , u_star , r_star , nIter ,mbbatch_size , bcbatch_size , ubatch_size ):\n",
        "\n",
        "    tf.reset_default_graph()\n",
        "    gpu_options = tf.GPUOptions(visible_device_list=\"0\")\n",
        "    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options,allow_soft_placement=False, log_device_placement=False)) as sess:\n",
        "        # sess.run(init)\n",
        "\n",
        "        model = PINN(layers, operator, ics_sampler, bcs_sampler, res_sampler, c, kernel_size , sess)\n",
        "        # Train model\n",
        "        start_time = time.time()\n",
        "\n",
        "        if method ==\"full_batch\":\n",
        "            print(\"full_batch method is used\")\n",
        "            model.train(nIter  , bcbatch_size , ubatch_size  )\n",
        "        elif method ==\"mini_batch\":\n",
        "            print(\"mini_batch method is used\")\n",
        "            model.trainmb(nIter, mbbatch_size)\n",
        "        else:\n",
        "            print(\"unknown method!\")\n",
        "        elapsed = time.time() - start_time\n",
        "\n",
        "        # Predictions\n",
        "        u_pred = model.predict_u(X_star)\n",
        "        r_pred = model.predict_r(X_star)\n",
        "        # Predictions\n",
        "\n",
        "        sess.close()   \n",
        "\n",
        "    error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
        "\n",
        "    print('elapsed: {:.2e}'.format(elapsed))\n",
        "\n",
        "    print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
        "\n",
        "\n",
        "    return [elapsed, error_u  ]\n",
        "\n",
        "###############################################################################################################################################\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Method:  full_batch\n",
            "Epoch:  1\n",
            "WARNING:tensorflow:From /tmp/ipykernel_31933/187544903.py:4: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_31933/187544903.py:5: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_31933/187544903.py:6: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_31933/187544903.py:6: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_31933/1134770933.py:38: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-26 01:45:25.293637: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
            "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-26 01:45:25.317304: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz\n",
            "2023-11-26 01:45:25.317793: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5597bcd045a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2023-11-26 01:45:25.317806: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2023-11-26 01:45:25.323416: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tmp/ipykernel_31933/1134770933.py:90: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_31933/1134770933.py:92: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_31933/1134770933.py:95: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "full_batch method is used\n",
            "It: 100, Loss: 3.640e+01,  loss_bc1: 4.896e-02,  loss_bc2: 2.658e-02, loss_ics_u: 2.883e-01, loss_ics_u_t: 1.062e-02, Loss_res: 1.581e-02 , Time: 36.77\n",
            "loss_bc1: 4.896e+02\n",
            "loss_bc2: 2.658e+02\n",
            "loss_ics_u: 2.883e+03\n",
            "lam_r_val: 1.581e+00\n",
            "It: 200, Loss: 3.066e+01,  loss_bc1: 4.595e-02,  loss_bc2: 2.955e-02, loss_ics_u: 2.192e-01, loss_ics_u_t: 1.640e-03, Loss_res: 1.190e+00 , Time: 36.06\n",
            "loss_bc1: 4.595e+02\n",
            "loss_bc2: 2.955e+02\n",
            "loss_ics_u: 2.192e+03\n",
            "lam_r_val: 1.190e+02\n",
            "It: 300, Loss: 2.399e+01,  loss_bc1: 3.380e-02,  loss_bc2: 1.122e-02, loss_ics_u: 1.788e-01, loss_ics_u_t: 5.305e-03, Loss_res: 1.611e+00 , Time: 36.64\n",
            "loss_bc1: 3.380e+02\n",
            "loss_bc2: 1.122e+02\n",
            "loss_ics_u: 1.788e+03\n",
            "lam_r_val: 1.611e+02\n",
            "It: 400, Loss: 1.930e+01,  loss_bc1: 2.937e-02,  loss_bc2: 1.088e-02, loss_ics_u: 1.420e-01, loss_ics_u_t: 3.352e-03, Loss_res: 1.070e+00 , Time: 38.74\n",
            "loss_bc1: 2.937e+02\n",
            "loss_bc2: 1.088e+02\n",
            "loss_ics_u: 1.420e+03\n",
            "lam_r_val: 1.070e+02\n",
            "It: 500, Loss: 1.786e+01,  loss_bc1: 2.824e-02,  loss_bc2: 1.117e-02, loss_ics_u: 1.300e-01, loss_ics_u_t: 2.049e-03, Loss_res: 9.168e-01 , Time: 35.44\n",
            "loss_bc1: 2.824e+02\n",
            "loss_bc2: 1.117e+02\n",
            "loss_ics_u: 1.300e+03\n",
            "lam_r_val: 9.168e+01\n",
            "It: 600, Loss: 1.623e+01,  loss_bc1: 2.542e-02,  loss_bc2: 1.121e-02, loss_ics_u: 1.193e-01, loss_ics_u_t: 7.532e-04, Loss_res: 6.361e-01 , Time: 35.26\n",
            "loss_bc1: 2.542e+02\n",
            "loss_bc2: 1.121e+02\n",
            "loss_ics_u: 1.193e+03\n",
            "lam_r_val: 6.361e+01\n",
            "It: 700, Loss: 1.627e+01,  loss_bc1: 2.434e-02,  loss_bc2: 9.349e-03, loss_ics_u: 1.223e-01, loss_ics_u_t: 2.016e-03, Loss_res: 6.674e-01 , Time: 35.29\n",
            "loss_bc1: 2.434e+02\n",
            "loss_bc2: 9.349e+01\n",
            "loss_ics_u: 1.223e+03\n",
            "lam_r_val: 6.674e+01\n",
            "It: 800, Loss: 1.511e+01,  loss_bc1: 2.264e-02,  loss_bc2: 1.045e-02, loss_ics_u: 1.126e-01, loss_ics_u_t: 6.790e-04, Loss_res: 5.344e-01 , Time: 35.20\n",
            "loss_bc1: 2.264e+02\n",
            "loss_bc2: 1.045e+02\n",
            "loss_ics_u: 1.126e+03\n",
            "lam_r_val: 5.344e+01\n",
            "It: 900, Loss: 1.450e+01,  loss_bc1: 2.122e-02,  loss_bc2: 1.036e-02, loss_ics_u: 1.089e-01, loss_ics_u_t: 9.087e-04, Loss_res: 4.489e-01 , Time: 35.27\n",
            "loss_bc1: 2.122e+02\n",
            "loss_bc2: 1.036e+02\n",
            "loss_ics_u: 1.089e+03\n",
            "lam_r_val: 4.489e+01\n",
            "It: 1000, Loss: 1.087e+02,  loss_bc1: 9.289e-02,  loss_bc2: 5.512e-02, loss_ics_u: 9.263e-01, loss_ics_u_t: 8.169e-01, Loss_res: 1.255e+00 , Time: 35.28\n",
            "loss_bc1: 9.289e+02\n",
            "loss_bc2: 5.512e+02\n",
            "loss_ics_u: 9.263e+03\n",
            "lam_r_val: 1.255e+02\n",
            "It: 1100, Loss: 1.435e+01,  loss_bc1: 1.952e-02,  loss_bc2: 1.029e-02, loss_ics_u: 1.084e-01, loss_ics_u_t: 1.499e-03, Loss_res: 5.295e-01 , Time: 35.25\n",
            "loss_bc1: 1.952e+02\n",
            "loss_bc2: 1.029e+02\n",
            "loss_ics_u: 1.084e+03\n",
            "lam_r_val: 5.295e+01\n",
            "It: 1200, Loss: 1.382e+01,  loss_bc1: 1.926e-02,  loss_bc2: 1.052e-02, loss_ics_u: 1.042e-01, loss_ics_u_t: 1.281e-03, Loss_res: 4.173e-01 , Time: 35.25\n",
            "loss_bc1: 1.926e+02\n",
            "loss_bc2: 1.052e+02\n",
            "loss_ics_u: 1.042e+03\n",
            "lam_r_val: 4.173e+01\n",
            "It: 1300, Loss: 1.353e+01,  loss_bc1: 1.884e-02,  loss_bc2: 1.069e-02, loss_ics_u: 1.016e-01, loss_ics_u_t: 1.373e-03, Loss_res: 4.203e-01 , Time: 35.27\n",
            "loss_bc1: 1.884e+02\n",
            "loss_bc2: 1.069e+02\n",
            "loss_ics_u: 1.016e+03\n",
            "lam_r_val: 4.203e+01\n",
            "It: 1400, Loss: 1.328e+01,  loss_bc1: 1.834e-02,  loss_bc2: 1.082e-02, loss_ics_u: 9.933e-02, loss_ics_u_t: 1.269e-03, Loss_res: 4.292e-01 , Time: 35.29\n",
            "loss_bc1: 1.834e+02\n",
            "loss_bc2: 1.082e+02\n",
            "loss_ics_u: 9.933e+02\n",
            "lam_r_val: 4.292e+01\n",
            "It: 1500, Loss: 1.333e+01,  loss_bc1: 1.803e-02,  loss_bc2: 1.103e-02, loss_ics_u: 9.992e-02, loss_ics_u_t: 3.929e-03, Loss_res: 4.291e-01 , Time: 35.24\n",
            "loss_bc1: 1.803e+02\n",
            "loss_bc2: 1.103e+02\n",
            "loss_ics_u: 9.992e+02\n",
            "lam_r_val: 4.291e+01\n",
            "It: 1600, Loss: 1.298e+01,  loss_bc1: 1.713e-02,  loss_bc2: 1.082e-02, loss_ics_u: 9.795e-02, loss_ics_u_t: 1.120e-03, Loss_res: 3.869e-01 , Time: 38.47\n",
            "loss_bc1: 1.713e+02\n",
            "loss_bc2: 1.082e+02\n",
            "loss_ics_u: 9.795e+02\n",
            "lam_r_val: 3.869e+01\n",
            "It: 1700, Loss: 1.261e+01,  loss_bc1: 1.714e-02,  loss_bc2: 1.058e-02, loss_ics_u: 9.454e-02, loss_ics_u_t: 1.051e-03, Loss_res: 3.799e-01 , Time: 36.19\n",
            "loss_bc1: 1.714e+02\n",
            "loss_bc2: 1.058e+02\n",
            "loss_ics_u: 9.454e+02\n",
            "lam_r_val: 3.799e+01\n",
            "It: 1800, Loss: 1.223e+01,  loss_bc1: 1.675e-02,  loss_bc2: 1.045e-02, loss_ics_u: 9.150e-02, loss_ics_u_t: 9.642e-04, Loss_res: 3.644e-01 , Time: 38.22\n",
            "loss_bc1: 1.675e+02\n",
            "loss_bc2: 1.045e+02\n",
            "loss_ics_u: 9.150e+02\n",
            "lam_r_val: 3.644e+01\n",
            "It: 1900, Loss: 1.214e+01,  loss_bc1: 1.596e-02,  loss_bc2: 9.823e-03, loss_ics_u: 9.200e-02, loss_ics_u_t: 9.711e-04, Loss_res: 3.590e-01 , Time: 37.77\n",
            "loss_bc1: 1.596e+02\n",
            "loss_bc2: 9.823e+01\n",
            "loss_ics_u: 9.200e+02\n",
            "lam_r_val: 3.590e+01\n",
            "It: 2000, Loss: 1.166e+01,  loss_bc1: 1.574e-02,  loss_bc2: 9.852e-03, loss_ics_u: 8.756e-02, loss_ics_u_t: 9.734e-04, Loss_res: 3.467e-01 , Time: 38.09\n",
            "loss_bc1: 1.574e+02\n",
            "loss_bc2: 9.852e+01\n",
            "loss_ics_u: 8.756e+02\n",
            "lam_r_val: 3.467e+01\n",
            "It: 2100, Loss: 1.147e+01,  loss_bc1: 1.505e-02,  loss_bc2: 9.351e-03, loss_ics_u: 8.704e-02, loss_ics_u_t: 1.513e-03, Loss_res: 3.275e-01 , Time: 36.36\n",
            "loss_bc1: 1.505e+02\n",
            "loss_bc2: 9.351e+01\n",
            "loss_ics_u: 8.704e+02\n",
            "lam_r_val: 3.275e+01\n",
            "It: 2200, Loss: 1.126e+01,  loss_bc1: 1.390e-02,  loss_bc2: 9.050e-03, loss_ics_u: 8.641e-02, loss_ics_u_t: 2.859e-03, Loss_res: 3.282e-01 , Time: 39.60\n",
            "loss_bc1: 1.390e+02\n",
            "loss_bc2: 9.050e+01\n",
            "loss_ics_u: 8.641e+02\n",
            "lam_r_val: 3.282e+01\n",
            "It: 2300, Loss: 1.056e+01,  loss_bc1: 1.290e-02,  loss_bc2: 9.005e-03, loss_ics_u: 8.063e-02, loss_ics_u_t: 1.340e-03, Loss_res: 3.077e-01 , Time: 37.52\n",
            "loss_bc1: 1.290e+02\n",
            "loss_bc2: 9.005e+01\n",
            "loss_ics_u: 8.063e+02\n",
            "lam_r_val: 3.077e+01\n",
            "It: 2400, Loss: 1.037e+01,  loss_bc1: 1.158e-02,  loss_bc2: 8.516e-03, loss_ics_u: 8.035e-02, loss_ics_u_t: 3.603e-03, Loss_res: 3.206e-01 , Time: 37.88\n",
            "loss_bc1: 1.158e+02\n",
            "loss_bc2: 8.516e+01\n",
            "loss_ics_u: 8.035e+02\n",
            "lam_r_val: 3.206e+01\n",
            "It: 2500, Loss: 1.005e+01,  loss_bc1: 1.028e-02,  loss_bc2: 7.711e-03, loss_ics_u: 7.880e-02, loss_ics_u_t: 4.397e-03, Loss_res: 3.701e-01 , Time: 36.94\n",
            "loss_bc1: 1.028e+02\n",
            "loss_bc2: 7.711e+01\n",
            "loss_ics_u: 7.880e+02\n",
            "lam_r_val: 3.701e+01\n",
            "It: 2600, Loss: 9.642e+00,  loss_bc1: 9.333e-03,  loss_bc2: 7.129e-03, loss_ics_u: 7.602e-02, loss_ics_u_t: 3.561e-03, Loss_res: 3.942e-01 , Time: 35.10\n",
            "loss_bc1: 9.333e+01\n",
            "loss_bc2: 7.129e+01\n",
            "loss_ics_u: 7.602e+02\n",
            "lam_r_val: 3.942e+01\n",
            "It: 2700, Loss: 8.849e+00,  loss_bc1: 8.323e-03,  loss_bc2: 6.734e-03, loss_ics_u: 7.101e-02, loss_ics_u_t: 1.330e-03, Loss_res: 2.426e-01 , Time: 38.01\n",
            "loss_bc1: 8.323e+01\n",
            "loss_bc2: 6.734e+01\n",
            "loss_ics_u: 7.101e+02\n",
            "lam_r_val: 2.426e+01\n",
            "It: 2800, Loss: 1.374e+01,  loss_bc1: 9.098e-03,  loss_bc2: 6.578e-03, loss_ics_u: 1.158e-01, loss_ics_u_t: 4.768e-02, Loss_res: 5.911e-01 , Time: 35.12\n",
            "loss_bc1: 9.098e+01\n",
            "loss_bc2: 6.578e+01\n",
            "loss_ics_u: 1.158e+03\n",
            "lam_r_val: 5.911e+01\n",
            "It: 2900, Loss: 8.325e+00,  loss_bc1: 7.051e-03,  loss_bc2: 5.128e-03, loss_ics_u: 6.799e-02, loss_ics_u_t: 2.071e-03, Loss_res: 3.076e-01 , Time: 34.92\n",
            "loss_bc1: 7.051e+01\n",
            "loss_bc2: 5.128e+01\n",
            "loss_ics_u: 6.799e+02\n",
            "lam_r_val: 3.076e+01\n",
            "It: 3000, Loss: 7.818e+00,  loss_bc1: 5.856e-03,  loss_bc2: 4.875e-03, loss_ics_u: 6.501e-02, loss_ics_u_t: 1.623e-03, Loss_res: 2.441e-01 , Time: 35.30\n",
            "loss_bc1: 5.856e+01\n",
            "loss_bc2: 4.875e+01\n",
            "loss_ics_u: 6.501e+02\n",
            "lam_r_val: 2.441e+01\n",
            "It: 3100, Loss: 7.440e+00,  loss_bc1: 5.473e-03,  loss_bc2: 4.892e-03, loss_ics_u: 6.203e-02, loss_ics_u_t: 1.017e-03, Loss_res: 2.009e-01 , Time: 35.72\n",
            "loss_bc1: 5.473e+01\n",
            "loss_bc2: 4.892e+01\n",
            "loss_ics_u: 6.203e+02\n",
            "lam_r_val: 2.009e+01\n",
            "It: 3200, Loss: 7.252e+00,  loss_bc1: 5.274e-03,  loss_bc2: 4.581e-03, loss_ics_u: 6.069e-02, loss_ics_u_t: 8.772e-04, Loss_res: 1.974e-01 , Time: 35.38\n",
            "loss_bc1: 5.274e+01\n",
            "loss_bc2: 4.581e+01\n",
            "loss_ics_u: 6.069e+02\n",
            "lam_r_val: 1.974e+01\n",
            "It: 3300, Loss: 7.087e+00,  loss_bc1: 5.124e-03,  loss_bc2: 4.464e-03, loss_ics_u: 5.915e-02, loss_ics_u_t: 1.308e-03, Loss_res: 2.137e-01 , Time: 36.33\n",
            "loss_bc1: 5.124e+01\n",
            "loss_bc2: 4.464e+01\n",
            "loss_ics_u: 5.915e+02\n",
            "lam_r_val: 2.137e+01\n",
            "It: 3400, Loss: 6.817e+00,  loss_bc1: 4.741e-03,  loss_bc2: 4.306e-03, loss_ics_u: 5.691e-02, loss_ics_u_t: 1.003e-03, Loss_res: 2.205e-01 , Time: 48.38\n",
            "loss_bc1: 4.741e+01\n",
            "loss_bc2: 4.306e+01\n",
            "loss_ics_u: 5.691e+02\n",
            "lam_r_val: 2.205e+01\n",
            "It: 3500, Loss: 6.851e+00,  loss_bc1: 4.494e-03,  loss_bc2: 4.206e-03, loss_ics_u: 5.737e-02, loss_ics_u_t: 3.215e-03, Loss_res: 2.447e-01 , Time: 54.07\n",
            "loss_bc1: 4.494e+01\n",
            "loss_bc2: 4.206e+01\n",
            "loss_ics_u: 5.737e+02\n",
            "lam_r_val: 2.447e+01\n",
            "It: 3600, Loss: 6.507e+00,  loss_bc1: 4.600e-03,  loss_bc2: 4.187e-03, loss_ics_u: 5.391e-02, loss_ics_u_t: 1.113e-03, Loss_res: 2.373e-01 , Time: 36.76\n",
            "loss_bc1: 4.600e+01\n",
            "loss_bc2: 4.187e+01\n",
            "loss_ics_u: 5.391e+02\n",
            "lam_r_val: 2.373e+01\n",
            "It: 3700, Loss: 6.401e+00,  loss_bc1: 4.536e-03,  loss_bc2: 4.113e-03, loss_ics_u: 5.305e-02, loss_ics_u_t: 1.142e-03, Loss_res: 2.306e-01 , Time: 63.85\n",
            "loss_bc1: 4.536e+01\n",
            "loss_bc2: 4.113e+01\n",
            "loss_ics_u: 5.305e+02\n",
            "lam_r_val: 2.306e+01\n",
            "It: 3800, Loss: 6.295e+00,  loss_bc1: 4.614e-03,  loss_bc2: 4.024e-03, loss_ics_u: 5.210e-02, loss_ics_u_t: 1.215e-03, Loss_res: 2.213e-01 , Time: 90.19\n",
            "loss_bc1: 4.614e+01\n",
            "loss_bc2: 4.024e+01\n",
            "loss_ics_u: 5.210e+02\n",
            "lam_r_val: 2.213e+01\n",
            "It: 3900, Loss: 6.170e+00,  loss_bc1: 4.606e-03,  loss_bc2: 4.026e-03, loss_ics_u: 5.090e-02, loss_ics_u_t: 1.212e-03, Loss_res: 2.170e-01 , Time: 89.53\n",
            "loss_bc1: 4.606e+01\n",
            "loss_bc2: 4.026e+01\n",
            "loss_ics_u: 5.090e+02\n",
            "lam_r_val: 2.170e+01\n",
            "It: 4000, Loss: 6.064e+00,  loss_bc1: 4.755e-03,  loss_bc2: 3.948e-03, loss_ics_u: 4.986e-02, loss_ics_u_t: 1.248e-03, Loss_res: 2.078e-01 , Time: 90.56\n",
            "loss_bc1: 4.755e+01\n",
            "loss_bc2: 3.948e+01\n",
            "loss_ics_u: 4.986e+02\n",
            "lam_r_val: 2.078e+01\n",
            "It: 4100, Loss: 5.991e+00,  loss_bc1: 4.597e-03,  loss_bc2: 4.044e-03, loss_ics_u: 4.916e-02, loss_ics_u_t: 1.555e-03, Loss_res: 2.104e-01 , Time: 112.05\n",
            "loss_bc1: 4.597e+01\n",
            "loss_bc2: 4.044e+01\n",
            "loss_ics_u: 4.916e+02\n",
            "lam_r_val: 2.104e+01\n",
            "It: 4200, Loss: 5.849e+00,  loss_bc1: 4.798e-03,  loss_bc2: 4.053e-03, loss_ics_u: 4.755e-02, loss_ics_u_t: 1.723e-03, Loss_res: 2.088e-01 , Time: 108.02\n",
            "loss_bc1: 4.798e+01\n",
            "loss_bc2: 4.053e+01\n",
            "loss_ics_u: 4.755e+02\n",
            "lam_r_val: 2.088e+01\n",
            "It: 4300, Loss: 6.387e+00,  loss_bc1: 4.927e-03,  loss_bc2: 4.222e-03, loss_ics_u: 5.238e-02, loss_ics_u_t: 8.107e-03, Loss_res: 2.342e-01 , Time: 109.63\n",
            "loss_bc1: 4.927e+01\n",
            "loss_bc2: 4.222e+01\n",
            "loss_ics_u: 5.238e+02\n",
            "lam_r_val: 2.342e+01\n",
            "It: 4400, Loss: 7.918e+00,  loss_bc1: 6.686e-03,  loss_bc2: 4.539e-03, loss_ics_u: 6.248e-02, loss_ics_u_t: 1.812e-02, Loss_res: 5.479e-01 , Time: 107.63\n",
            "loss_bc1: 6.686e+01\n",
            "loss_bc2: 4.539e+01\n",
            "loss_ics_u: 6.248e+02\n",
            "lam_r_val: 5.479e+01\n",
            "It: 4500, Loss: 5.429e+00,  loss_bc1: 4.649e-03,  loss_bc2: 4.208e-03, loss_ics_u: 4.333e-02, loss_ics_u_t: 1.483e-03, Loss_res: 2.108e-01 , Time: 109.68\n",
            "loss_bc1: 4.649e+01\n",
            "loss_bc2: 4.208e+01\n",
            "loss_ics_u: 4.333e+02\n",
            "lam_r_val: 2.108e+01\n",
            "It: 4600, Loss: 5.452e+00,  loss_bc1: 4.653e-03,  loss_bc2: 4.068e-03, loss_ics_u: 4.403e-02, loss_ics_u_t: 1.012e-03, Loss_res: 1.764e-01 , Time: 112.91\n",
            "loss_bc1: 4.653e+01\n",
            "loss_bc2: 4.068e+01\n",
            "loss_ics_u: 4.403e+02\n",
            "lam_r_val: 1.764e+01\n",
            "It: 4700, Loss: 5.274e+00,  loss_bc1: 4.540e-03,  loss_bc2: 4.183e-03, loss_ics_u: 4.197e-02, loss_ics_u_t: 1.752e-03, Loss_res: 2.048e-01 , Time: 109.19\n",
            "loss_bc1: 4.540e+01\n",
            "loss_bc2: 4.183e+01\n",
            "loss_ics_u: 4.197e+02\n",
            "lam_r_val: 2.048e+01\n",
            "It: 4800, Loss: 5.175e+00,  loss_bc1: 4.729e-03,  loss_bc2: 4.045e-03, loss_ics_u: 4.116e-02, loss_ics_u_t: 1.110e-03, Loss_res: 1.816e-01 , Time: 111.37\n",
            "loss_bc1: 4.729e+01\n",
            "loss_bc2: 4.045e+01\n",
            "loss_ics_u: 4.116e+02\n",
            "lam_r_val: 1.816e+01\n",
            "It: 4900, Loss: 5.197e+00,  loss_bc1: 4.699e-03,  loss_bc2: 4.076e-03, loss_ics_u: 4.136e-02, loss_ics_u_t: 1.513e-03, Loss_res: 1.839e-01 , Time: 107.28\n",
            "loss_bc1: 4.699e+01\n",
            "loss_bc2: 4.076e+01\n",
            "loss_ics_u: 4.136e+02\n",
            "lam_r_val: 1.839e+01\n",
            "It: 5000, Loss: 1.252e+01,  loss_bc1: 1.028e-02,  loss_bc2: 6.707e-03, loss_ics_u: 1.013e-01, loss_ics_u_t: 6.376e-02, Loss_res: 6.938e-01 , Time: 110.29\n",
            "loss_bc1: 1.028e+02\n",
            "loss_bc2: 6.707e+01\n",
            "loss_ics_u: 1.013e+03\n",
            "lam_r_val: 6.938e+01\n",
            "It: 5100, Loss: 4.819e+00,  loss_bc1: 4.707e-03,  loss_bc2: 4.008e-03, loss_ics_u: 3.768e-02, loss_ics_u_t: 1.071e-03, Loss_res: 1.804e-01 , Time: 107.46\n",
            "loss_bc1: 4.707e+01\n",
            "loss_bc2: 4.008e+01\n",
            "loss_ics_u: 3.768e+02\n",
            "lam_r_val: 1.804e+01\n",
            "It: 5200, Loss: 4.713e+00,  loss_bc1: 4.658e-03,  loss_bc2: 4.026e-03, loss_ics_u: 3.668e-02, loss_ics_u_t: 9.902e-04, Loss_res: 1.767e-01 , Time: 108.92\n",
            "loss_bc1: 4.658e+01\n",
            "loss_bc2: 4.026e+01\n",
            "loss_ics_u: 3.668e+02\n",
            "lam_r_val: 1.767e+01\n",
            "It: 5300, Loss: 4.624e+00,  loss_bc1: 4.683e-03,  loss_bc2: 3.935e-03, loss_ics_u: 3.591e-02, loss_ics_u_t: 9.131e-04, Loss_res: 1.709e-01 , Time: 110.87\n",
            "loss_bc1: 4.683e+01\n",
            "loss_bc2: 3.935e+01\n",
            "loss_ics_u: 3.591e+02\n",
            "lam_r_val: 1.709e+01\n",
            "It: 5400, Loss: 4.620e+00,  loss_bc1: 4.581e-03,  loss_bc2: 3.958e-03, loss_ics_u: 3.576e-02, loss_ics_u_t: 1.565e-03, Loss_res: 1.901e-01 , Time: 108.15\n",
            "loss_bc1: 4.581e+01\n",
            "loss_bc2: 3.958e+01\n",
            "loss_ics_u: 3.576e+02\n",
            "lam_r_val: 1.901e+01\n",
            "It: 5500, Loss: 5.152e+00,  loss_bc1: 5.365e-03,  loss_bc2: 3.891e-03, loss_ics_u: 4.035e-02, loss_ics_u_t: 7.386e-03, Loss_res: 1.917e-01 , Time: 109.07\n",
            "loss_bc1: 5.365e+01\n",
            "loss_bc2: 3.891e+01\n",
            "loss_ics_u: 4.035e+02\n",
            "lam_r_val: 1.917e+01\n",
            "It: 5600, Loss: 4.348e+00,  loss_bc1: 4.777e-03,  loss_bc2: 3.828e-03, loss_ics_u: 3.320e-02, loss_ics_u_t: 9.457e-04, Loss_res: 1.676e-01 , Time: 107.95\n",
            "loss_bc1: 4.777e+01\n",
            "loss_bc2: 3.828e+01\n",
            "loss_ics_u: 3.320e+02\n",
            "lam_r_val: 1.676e+01\n",
            "It: 5700, Loss: 4.235e+00,  loss_bc1: 4.783e-03,  loss_bc2: 3.765e-03, loss_ics_u: 3.212e-02, loss_ics_u_t: 9.666e-04, Loss_res: 1.686e-01 , Time: 110.32\n",
            "loss_bc1: 4.783e+01\n",
            "loss_bc2: 3.765e+01\n",
            "loss_ics_u: 3.212e+02\n",
            "lam_r_val: 1.686e+01\n",
            "It: 5800, Loss: 1.385e+01,  loss_bc1: 6.585e-03,  loss_bc2: 4.941e-03, loss_ics_u: 1.185e-01, loss_ics_u_t: 8.753e-02, Loss_res: 8.397e-01 , Time: 107.88\n",
            "loss_bc1: 6.585e+01\n",
            "loss_bc2: 4.941e+01\n",
            "loss_ics_u: 1.185e+03\n",
            "lam_r_val: 8.397e+01\n",
            "It: 5900, Loss: 4.137e+00,  loss_bc1: 4.910e-03,  loss_bc2: 3.682e-03, loss_ics_u: 3.093e-02, loss_ics_u_t: 1.215e-03, Loss_res: 1.850e-01 , Time: 109.12\n",
            "loss_bc1: 4.910e+01\n",
            "loss_bc2: 3.682e+01\n",
            "loss_ics_u: 3.093e+02\n",
            "lam_r_val: 1.850e+01\n",
            "It: 6000, Loss: 3.984e+00,  loss_bc1: 4.809e-03,  loss_bc2: 3.612e-03, loss_ics_u: 2.982e-02, loss_ics_u_t: 9.698e-04, Loss_res: 1.599e-01 , Time: 109.44\n",
            "loss_bc1: 4.809e+01\n",
            "loss_bc2: 3.612e+01\n",
            "loss_ics_u: 2.982e+02\n",
            "lam_r_val: 1.599e+01\n",
            "It: 6100, Loss: 3.908e+00,  loss_bc1: 4.784e-03,  loss_bc2: 3.652e-03, loss_ics_u: 2.905e-02, loss_ics_u_t: 8.567e-04, Loss_res: 1.590e-01 , Time: 107.54\n",
            "loss_bc1: 4.784e+01\n",
            "loss_bc2: 3.652e+01\n",
            "loss_ics_u: 2.905e+02\n",
            "lam_r_val: 1.590e+01\n",
            "It: 6200, Loss: 4.123e+00,  loss_bc1: 4.824e-03,  loss_bc2: 3.497e-03, loss_ics_u: 3.116e-02, loss_ics_u_t: 3.011e-03, Loss_res: 1.747e-01 , Time: 108.42\n",
            "loss_bc1: 4.824e+01\n",
            "loss_bc2: 3.497e+01\n",
            "loss_ics_u: 3.116e+02\n",
            "lam_r_val: 1.747e+01\n",
            "It: 6300, Loss: 4.473e+00,  loss_bc1: 5.296e-03,  loss_bc2: 3.480e-03, loss_ics_u: 3.301e-02, loss_ics_u_t: 6.027e-03, Loss_res: 2.938e-01 , Time: 107.43\n",
            "loss_bc1: 5.296e+01\n",
            "loss_bc2: 3.480e+01\n",
            "loss_ics_u: 3.301e+02\n",
            "lam_r_val: 2.938e+01\n",
            "It: 6400, Loss: 1.370e+01,  loss_bc1: 6.815e-03,  loss_bc2: 4.153e-03, loss_ics_u: 1.206e-01, loss_ics_u_t: 9.498e-02, Loss_res: 5.440e-01 , Time: 102.78\n",
            "loss_bc1: 6.815e+01\n",
            "loss_bc2: 4.153e+01\n",
            "loss_ics_u: 1.206e+03\n",
            "lam_r_val: 5.440e+01\n",
            "It: 6500, Loss: 3.593e+00,  loss_bc1: 4.916e-03,  loss_bc2: 3.558e-03, loss_ics_u: 2.590e-02, loss_ics_u_t: 8.816e-04, Loss_res: 1.555e-01 , Time: 89.89\n",
            "loss_bc1: 4.916e+01\n",
            "loss_bc2: 3.558e+01\n",
            "loss_ics_u: 2.590e+02\n",
            "lam_r_val: 1.555e+01\n",
            "It: 6600, Loss: 3.575e+00,  loss_bc1: 4.811e-03,  loss_bc2: 3.535e-03, loss_ics_u: 2.599e-02, loss_ics_u_t: 8.424e-04, Loss_res: 1.419e-01 , Time: 89.01\n",
            "loss_bc1: 4.811e+01\n",
            "loss_bc2: 3.535e+01\n",
            "loss_ics_u: 2.599e+02\n",
            "lam_r_val: 1.419e+01\n",
            "It: 6700, Loss: 3.524e+00,  loss_bc1: 5.082e-03,  loss_bc2: 3.427e-03, loss_ics_u: 2.529e-02, loss_ics_u_t: 1.117e-03, Loss_res: 1.444e-01 , Time: 90.60\n",
            "loss_bc1: 5.082e+01\n",
            "loss_bc2: 3.427e+01\n",
            "loss_ics_u: 2.529e+02\n",
            "lam_r_val: 1.444e+01\n",
            "It: 6800, Loss: 3.445e+00,  loss_bc1: 5.028e-03,  loss_bc2: 3.464e-03, loss_ics_u: 2.453e-02, loss_ics_u_t: 1.057e-03, Loss_res: 1.428e-01 , Time: 90.72\n",
            "loss_bc1: 5.028e+01\n",
            "loss_bc2: 3.464e+01\n",
            "loss_ics_u: 2.453e+02\n",
            "lam_r_val: 1.428e+01\n",
            "It: 6900, Loss: 3.488e+00,  loss_bc1: 4.998e-03,  loss_bc2: 3.482e-03, loss_ics_u: 2.495e-02, loss_ics_u_t: 1.800e-03, Loss_res: 1.443e-01 , Time: 88.64\n",
            "loss_bc1: 4.998e+01\n",
            "loss_bc2: 3.482e+01\n",
            "loss_ics_u: 2.495e+02\n",
            "lam_r_val: 1.443e+01\n",
            "It: 7000, Loss: 3.378e+00,  loss_bc1: 5.173e-03,  loss_bc2: 3.396e-03, loss_ics_u: 2.369e-02, loss_ics_u_t: 1.514e-03, Loss_res: 1.518e-01 , Time: 86.61\n",
            "loss_bc1: 5.173e+01\n",
            "loss_bc2: 3.396e+01\n",
            "loss_ics_u: 2.369e+02\n",
            "lam_r_val: 1.518e+01\n",
            "It: 7100, Loss: 8.798e+00,  loss_bc1: 5.136e-03,  loss_bc2: 3.358e-03, loss_ics_u: 7.610e-02, loss_ics_u_t: 5.431e-02, Loss_res: 3.382e-01 , Time: 87.54\n",
            "loss_bc1: 5.136e+01\n",
            "loss_bc2: 3.358e+01\n",
            "loss_ics_u: 7.610e+02\n",
            "lam_r_val: 3.382e+01\n",
            "It: 7200, Loss: 3.412e+00,  loss_bc1: 5.335e-03,  loss_bc2: 3.377e-03, loss_ics_u: 2.374e-02, loss_ics_u_t: 2.556e-03, Loss_res: 1.669e-01 , Time: 87.23\n",
            "loss_bc1: 5.335e+01\n",
            "loss_bc2: 3.377e+01\n",
            "loss_ics_u: 2.374e+02\n",
            "lam_r_val: 1.669e+01\n",
            "It: 7300, Loss: 3.176e+00,  loss_bc1: 5.139e-03,  loss_bc2: 3.350e-03, loss_ics_u: 2.193e-02, loss_ics_u_t: 1.457e-03, Loss_res: 1.342e-01 , Time: 86.20\n",
            "loss_bc1: 5.139e+01\n",
            "loss_bc2: 3.350e+01\n",
            "loss_ics_u: 2.193e+02\n",
            "lam_r_val: 1.342e+01\n",
            "It: 7400, Loss: 5.339e+00,  loss_bc1: 5.860e-03,  loss_bc2: 4.173e-03, loss_ics_u: 3.422e-02, loss_ics_u_t: 1.423e-02, Loss_res: 9.129e-01 , Time: 85.71\n",
            "loss_bc1: 5.860e+01\n",
            "loss_bc2: 4.173e+01\n",
            "loss_ics_u: 3.422e+02\n",
            "lam_r_val: 9.129e+01\n",
            "It: 7500, Loss: 3.054e+00,  loss_bc1: 5.210e-03,  loss_bc2: 3.274e-03, loss_ics_u: 2.082e-02, loss_ics_u_t: 1.064e-03, Loss_res: 1.241e-01 , Time: 89.95\n",
            "loss_bc1: 5.210e+01\n",
            "loss_bc2: 3.274e+01\n",
            "loss_ics_u: 2.082e+02\n",
            "lam_r_val: 1.241e+01\n",
            "It: 7600, Loss: 3.018e+00,  loss_bc1: 5.171e-03,  loss_bc2: 3.287e-03, loss_ics_u: 2.052e-02, loss_ics_u_t: 1.133e-03, Loss_res: 1.204e-01 , Time: 91.37\n",
            "loss_bc1: 5.171e+01\n",
            "loss_bc2: 3.287e+01\n",
            "loss_ics_u: 2.052e+02\n",
            "lam_r_val: 1.204e+01\n",
            "It: 7700, Loss: 3.051e+00,  loss_bc1: 5.324e-03,  loss_bc2: 3.220e-03, loss_ics_u: 2.072e-02, loss_ics_u_t: 2.015e-03, Loss_res: 1.242e-01 , Time: 91.52\n",
            "loss_bc1: 5.324e+01\n",
            "loss_bc2: 3.220e+01\n",
            "loss_ics_u: 2.072e+02\n",
            "lam_r_val: 1.242e+01\n",
            "It: 7800, Loss: 8.315e+00,  loss_bc1: 5.283e-03,  loss_bc2: 3.200e-03, loss_ics_u: 7.155e-02, loss_ics_u_t: 5.325e-02, Loss_res: 3.117e-01 , Time: 92.35\n",
            "loss_bc1: 5.283e+01\n",
            "loss_bc2: 3.200e+01\n",
            "loss_ics_u: 7.155e+02\n",
            "lam_r_val: 3.117e+01\n",
            "It: 7900, Loss: 3.017e+00,  loss_bc1: 5.190e-03,  loss_bc2: 3.260e-03, loss_ics_u: 1.993e-02, loss_ics_u_t: 2.163e-03, Loss_res: 1.783e-01 , Time: 91.97\n",
            "loss_bc1: 5.190e+01\n",
            "loss_bc2: 3.260e+01\n",
            "loss_ics_u: 1.993e+02\n",
            "lam_r_val: 1.783e+01\n",
            "It: 8000, Loss: 2.844e+00,  loss_bc1: 5.292e-03,  loss_bc2: 3.156e-03, loss_ics_u: 1.884e-02, loss_ics_u_t: 1.126e-03, Loss_res: 1.153e-01 , Time: 90.84\n",
            "loss_bc1: 5.292e+01\n",
            "loss_bc2: 3.156e+01\n",
            "loss_ics_u: 1.884e+02\n",
            "lam_r_val: 1.153e+01\n",
            "It: 8100, Loss: 3.006e+00,  loss_bc1: 5.215e-03,  loss_bc2: 3.126e-03, loss_ics_u: 2.003e-02, loss_ics_u_t: 2.585e-03, Loss_res: 1.689e-01 , Time: 91.73\n",
            "loss_bc1: 5.215e+01\n",
            "loss_bc2: 3.126e+01\n",
            "loss_ics_u: 2.003e+02\n",
            "lam_r_val: 1.689e+01\n",
            "It: 8200, Loss: 2.745e+00,  loss_bc1: 5.295e-03,  loss_bc2: 3.120e-03, loss_ics_u: 1.786e-02, loss_ics_u_t: 1.213e-03, Loss_res: 1.166e-01 , Time: 78.13\n",
            "loss_bc1: 5.295e+01\n",
            "loss_bc2: 3.120e+01\n",
            "loss_ics_u: 1.786e+02\n",
            "lam_r_val: 1.166e+01\n",
            "It: 8300, Loss: 2.685e+00,  loss_bc1: 5.172e-03,  loss_bc2: 3.106e-03, loss_ics_u: 1.742e-02, loss_ics_u_t: 1.071e-03, Loss_res: 1.154e-01 , Time: 34.25\n",
            "loss_bc1: 5.172e+01\n",
            "loss_bc2: 3.106e+01\n",
            "loss_ics_u: 1.742e+02\n",
            "lam_r_val: 1.154e+01\n",
            "It: 8400, Loss: 2.732e+00,  loss_bc1: 5.246e-03,  loss_bc2: 3.017e-03, loss_ics_u: 1.795e-02, loss_ics_u_t: 1.629e-03, Loss_res: 1.104e-01 , Time: 35.32\n",
            "loss_bc1: 5.246e+01\n",
            "loss_bc2: 3.017e+01\n",
            "loss_ics_u: 1.795e+02\n",
            "lam_r_val: 1.104e+01\n",
            "It: 8500, Loss: 2.725e+00,  loss_bc1: 5.252e-03,  loss_bc2: 3.107e-03, loss_ics_u: 1.771e-02, loss_ics_u_t: 2.079e-03, Loss_res: 1.174e-01 , Time: 36.86\n",
            "loss_bc1: 5.252e+01\n",
            "loss_bc2: 3.107e+01\n",
            "loss_ics_u: 1.771e+02\n",
            "lam_r_val: 1.174e+01\n",
            "It: 8600, Loss: 2.587e+00,  loss_bc1: 5.117e-03,  loss_bc2: 3.050e-03, loss_ics_u: 1.660e-02, loss_ics_u_t: 1.166e-03, Loss_res: 1.098e-01 , Time: 35.10\n",
            "loss_bc1: 5.117e+01\n",
            "loss_bc2: 3.050e+01\n",
            "loss_ics_u: 1.660e+02\n",
            "lam_r_val: 1.098e+01\n",
            "It: 8700, Loss: 2.839e+00,  loss_bc1: 5.461e-03,  loss_bc2: 2.964e-03, loss_ics_u: 1.871e-02, loss_ics_u_t: 3.559e-03, Loss_res: 1.261e-01 , Time: 34.93\n",
            "loss_bc1: 5.461e+01\n",
            "loss_bc2: 2.964e+01\n",
            "loss_ics_u: 1.871e+02\n",
            "lam_r_val: 1.261e+01\n",
            "It: 8800, Loss: 2.904e+00,  loss_bc1: 5.171e-03,  loss_bc2: 3.161e-03, loss_ics_u: 1.866e-02, loss_ics_u_t: 4.087e-03, Loss_res: 2.050e-01 , Time: 37.62\n",
            "loss_bc1: 5.171e+01\n",
            "loss_bc2: 3.161e+01\n",
            "loss_ics_u: 1.866e+02\n",
            "lam_r_val: 2.050e+01\n",
            "It: 8900, Loss: 2.522e+00,  loss_bc1: 4.978e-03,  loss_bc2: 3.037e-03, loss_ics_u: 1.590e-02, loss_ics_u_t: 1.590e-03, Loss_res: 1.308e-01 , Time: 36.39\n",
            "loss_bc1: 4.978e+01\n",
            "loss_bc2: 3.037e+01\n",
            "loss_ics_u: 1.590e+02\n",
            "lam_r_val: 1.308e+01\n",
            "It: 9000, Loss: 2.385e+00,  loss_bc1: 4.993e-03,  loss_bc2: 2.964e-03, loss_ics_u: 1.482e-02, loss_ics_u_t: 9.710e-04, Loss_res: 1.079e-01 , Time: 36.28\n",
            "loss_bc1: 4.993e+01\n",
            "loss_bc2: 2.964e+01\n",
            "loss_ics_u: 1.482e+02\n",
            "lam_r_val: 1.079e+01\n",
            "It: 9100, Loss: 2.356e+00,  loss_bc1: 4.779e-03,  loss_bc2: 2.974e-03, loss_ics_u: 1.474e-02, loss_ics_u_t: 9.283e-04, Loss_res: 1.071e-01 , Time: 37.77\n",
            "loss_bc1: 4.779e+01\n",
            "loss_bc2: 2.974e+01\n",
            "loss_ics_u: 1.474e+02\n",
            "lam_r_val: 1.071e+01\n",
            "It: 9200, Loss: 2.668e+00,  loss_bc1: 5.072e-03,  loss_bc2: 3.024e-03, loss_ics_u: 1.704e-02, loss_ics_u_t: 3.754e-03, Loss_res: 1.544e-01 , Time: 35.99\n",
            "loss_bc1: 5.072e+01\n",
            "loss_bc2: 3.024e+01\n",
            "loss_ics_u: 1.704e+02\n",
            "lam_r_val: 1.544e+01\n",
            "It: 9300, Loss: 2.765e+00,  loss_bc1: 4.955e-03,  loss_bc2: 2.957e-03, loss_ics_u: 1.781e-02, loss_ics_u_t: 4.854e-03, Loss_res: 1.923e-01 , Time: 37.33\n",
            "loss_bc1: 4.955e+01\n",
            "loss_bc2: 2.957e+01\n",
            "loss_ics_u: 1.781e+02\n",
            "lam_r_val: 1.923e+01\n",
            "It: 9400, Loss: 3.136e+00,  loss_bc1: 5.244e-03,  loss_bc2: 2.899e-03, loss_ics_u: 2.176e-02, loss_ics_u_t: 9.451e-03, Loss_res: 1.461e-01 , Time: 36.57\n",
            "loss_bc1: 5.244e+01\n",
            "loss_bc2: 2.899e+01\n",
            "loss_ics_u: 2.176e+02\n",
            "lam_r_val: 1.461e+01\n",
            "It: 9500, Loss: 2.159e+00,  loss_bc1: 4.563e-03,  loss_bc2: 2.866e-03, loss_ics_u: 1.304e-02, loss_ics_u_t: 1.051e-03, Loss_res: 1.121e-01 , Time: 35.39\n",
            "loss_bc1: 4.563e+01\n",
            "loss_bc2: 2.866e+01\n",
            "loss_ics_u: 1.304e+02\n",
            "lam_r_val: 1.121e+01\n",
            "It: 9600, Loss: 2.112e+00,  loss_bc1: 4.517e-03,  loss_bc2: 2.773e-03, loss_ics_u: 1.272e-02, loss_ics_u_t: 8.594e-04, Loss_res: 1.114e-01 , Time: 34.98\n",
            "loss_bc1: 4.517e+01\n",
            "loss_bc2: 2.773e+01\n",
            "loss_ics_u: 1.272e+02\n",
            "lam_r_val: 1.114e+01\n",
            "It: 9700, Loss: 2.076e+00,  loss_bc1: 4.444e-03,  loss_bc2: 2.819e-03, loss_ics_u: 1.241e-02, loss_ics_u_t: 8.203e-04, Loss_res: 1.087e-01 , Time: 34.62\n",
            "loss_bc1: 4.444e+01\n",
            "loss_bc2: 2.819e+01\n",
            "loss_ics_u: 1.241e+02\n",
            "lam_r_val: 1.087e+01\n",
            "It: 9800, Loss: 2.879e+00,  loss_bc1: 4.369e-03,  loss_bc2: 2.739e-03, loss_ics_u: 2.029e-02, loss_ics_u_t: 9.252e-03, Loss_res: 1.394e-01 , Time: 36.16\n",
            "loss_bc1: 4.369e+01\n",
            "loss_bc2: 2.739e+01\n",
            "loss_ics_u: 2.029e+02\n",
            "lam_r_val: 1.394e+01\n",
            "It: 9900, Loss: 4.282e+00,  loss_bc1: 4.620e-03,  loss_bc2: 2.831e-03, loss_ics_u: 3.143e-02, loss_ics_u_t: 2.052e-02, Loss_res: 3.943e-01 , Time: 36.68\n",
            "loss_bc1: 4.620e+01\n",
            "loss_bc2: 2.831e+01\n",
            "loss_ics_u: 3.143e+02\n",
            "lam_r_val: 3.943e+01\n",
            "elapsed: 6.57e+03\n",
            "Relative L2 error_u: 2.96e-01\n",
            "elapsed: 6.57e+03\n",
            "Relative L2 error_u: 2.96e-01\n",
            "\n",
            "\n",
            "Method:  full_batch\n",
            "\n",
            "average of time_list: 6571.885622262955\n",
            "average of error_u_list: 0.2961059832902447\n"
          ]
        }
      ],
      "source": [
        "# Define PINN model\n",
        "a = 0.5\n",
        "c = 2\n",
        "\n",
        "kernel_size = 300\n",
        "\n",
        "# Domain boundaries\n",
        "ics_coords = np.array([[0.0, 0.0],  [0.0, 1.0]])\n",
        "bc1_coords = np.array([[0.0, 0.0],  [1.0, 0.0]])\n",
        "bc2_coords = np.array([[0.0, 1.0],  [1.0, 1.0]])\n",
        "dom_coords = np.array([[0.0, 0.0],  [1.0, 1.0]])\n",
        "\n",
        "# Create initial conditions samplers\n",
        "ics_sampler = Sampler(2, ics_coords, lambda x: u(x, a, c), name='Initial Condition 1')\n",
        "\n",
        "# Create boundary conditions samplers\n",
        "bc1 = Sampler(2, bc1_coords, lambda x: u(x, a, c), name='Dirichlet BC1')\n",
        "bc2 = Sampler(2, bc2_coords, lambda x: u(x, a, c), name='Dirichlet BC2')\n",
        "bcs_sampler = [bc1, bc2]\n",
        "\n",
        "# Create residual sampler\n",
        "res_sampler = Sampler(2, dom_coords, lambda x: r(x, a, c), name='Forcing')\n",
        "\n",
        "\n",
        "\n",
        "nIter =40000\n",
        "bcbatch_size = 500\n",
        "ubatch_size = 5000\n",
        "mbbatch_size = 300\n",
        "\n",
        "\n",
        "\n",
        "# Define model\n",
        "mode = 'M4'\n",
        "layers = [2, 500, 500, 500, 1]\n",
        "\n",
        "\n",
        "nn = 200\n",
        "t = np.linspace(dom_coords[0, 0], dom_coords[1, 0], nn)[:, None]\n",
        "x = np.linspace(dom_coords[0, 1], dom_coords[1, 1], nn)[:, None]\n",
        "t, x = np.meshgrid(t, x)\n",
        "X_star = np.hstack((t.flatten()[:, None], x.flatten()[:, None]))\n",
        "\n",
        "u_star = u(X_star, a,c)\n",
        "r_star = r(X_star, a, c)\n",
        "\n",
        "iterations = 1\n",
        "methods = [  \"full_batch\"]\n",
        "\n",
        "result_dict =  dict((mtd, []) for mtd in methods)\n",
        "\n",
        "for mtd in methods:\n",
        "    print(\"Method: \", mtd)\n",
        "    time_list = []\n",
        "    error_u_list = []\n",
        "    \n",
        "    for index in range(iterations):\n",
        "\n",
        "        print(\"Epoch: \", str(index+1))\n",
        "\n",
        "        # Create residual sampler\n",
        "\n",
        "        [elapsed, error_u] = test_method(mtd , layers,  ics_sampler, bcs_sampler, res_sampler, c ,kernel_size , X_star , u_star , r_star , nIter ,mbbatch_size , bcbatch_size , ubatch_size )\n",
        "\n",
        "\n",
        "        print('elapsed: {:.2e}'.format(elapsed))\n",
        "        print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
        "\n",
        "        time_list.append(elapsed)\n",
        "        error_u_list.append(error_u)\n",
        "\n",
        "    print(\"\\n\\nMethod: \", mtd)\n",
        "    print(\"\\naverage of time_list:\" , sum(time_list) / len(time_list) )\n",
        "    print(\"average of error_u_list:\" , sum(error_u_list) / len(error_u_list) )\n",
        "    # print(\"average of error_r_list:\" , sum(error_r_list) / len(error_r_list) )\n",
        "\n",
        "    result_dict[mtd] = [time_list ,error_u_list]\n",
        "    # scipy.io.savemat(\"M2_result_\"+str(iterations)+\"_\"+mtd+\".mat\" , {'time_list':np.array(time_list),'error_u_list':np.array(error_u_list),'error_f_list':np.array(error_f_list)})\n",
        "\n",
        "    scipy.io.savemat(\"./1DWave_database/\"+mtd+\"_1Dwave2_\"+mode+\"_result_mb\"+str(mbbatch_size)+\"_fb\"+str(ubatch_size)+\"_bc\"+str(mbbatch_size)+\"_\"+str(iterations)+\".mat\" , result_dict)\n",
        "\n",
        "###############################################################################################################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Method:  full_batch\n",
            "Epoch:  1\n",
            "WARNING:tensorflow:From /tmp/ipykernel_18492/187544903.py:4: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_18492/187544903.py:5: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_18492/187544903.py:6: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_18492/187544903.py:6: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-25 18:58:42.824746: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
            "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-25 18:58:42.845302: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz\n",
            "2023-11-25 18:58:42.846003: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5628562a4d90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2023-11-25 18:58:42.846024: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2023-11-25 18:58:42.860618: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tmp/ipykernel_18492/2540825387.py:38: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_18492/2540825387.py:90: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_18492/2540825387.py:92: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /tmp/ipykernel_18492/2540825387.py:95: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "full_batch method is used\n",
            "It: 0, Loss: 1.959e+02,  loss_bc1: 1.221e+00,  loss_bc2: 1.197e+00, loss_ics_u: 1.716e+01, loss_ics_u_t: 1.145e+01, Loss_res: 1.044e-01 , Time: 5.22\n",
            "loss_bc1: 1.221e+03\n",
            "loss_bc2: 1.197e+03\n",
            "loss_ics_u: 1.716e+04\n",
            "lam_r_val: 1.044e+02\n",
            "It: 100, Loss: 4.278e+00,  loss_bc1: 5.234e-02,  loss_bc2: 2.218e-02, loss_ics_u: 3.518e-01, loss_ics_u_t: 1.981e-02, Loss_res: 1.511e-02 , Time: 74.70\n",
            "It: 200, Loss: 3.398e+00,  loss_bc1: 5.522e-02,  loss_bc2: 3.264e-02, loss_ics_u: 2.473e-01, loss_ics_u_t: 1.344e-03, Loss_res: 4.653e-02 , Time: 74.60\n",
            "It: 300, Loss: 2.763e+00,  loss_bc1: 3.911e-02,  loss_bc2: 1.560e-02, loss_ics_u: 2.145e-01, loss_ics_u_t: 5.867e-03, Loss_res: 7.149e-02 , Time: 71.31\n",
            "It: 400, Loss: 2.013e+00,  loss_bc1: 3.326e-02,  loss_bc2: 1.095e-02, loss_ics_u: 1.513e-01, loss_ics_u_t: 4.831e-03, Loss_res: 5.727e-02 , Time: 77.11\n",
            "It: 500, Loss: 1.789e+00,  loss_bc1: 3.140e-02,  loss_bc2: 1.469e-02, loss_ics_u: 1.305e-01, loss_ics_u_t: 3.799e-03, Loss_res: 2.263e-02 , Time: 76.18\n",
            "It: 600, Loss: 2.656e+00,  loss_bc1: 3.183e-02,  loss_bc2: 1.731e-02, loss_ics_u: 2.109e-01, loss_ics_u_t: 8.041e-02, Loss_res: 5.560e-02 , Time: 79.17\n",
            "It: 700, Loss: 1.558e+00,  loss_bc1: 2.533e-02,  loss_bc2: 1.378e-02, loss_ics_u: 1.144e-01, loss_ics_u_t: 2.885e-03, Loss_res: 2.288e-02 , Time: 77.93\n",
            "It: 800, Loss: 1.530e+00,  loss_bc1: 2.433e-02,  loss_bc2: 1.270e-02, loss_ics_u: 1.139e-01, loss_ics_u_t: 3.312e-03, Loss_res: 2.032e-02 , Time: 74.66\n",
            "It: 900, Loss: 1.494e+00,  loss_bc1: 2.318e-02,  loss_bc2: 1.256e-02, loss_ics_u: 1.118e-01, loss_ics_u_t: 3.852e-03, Loss_res: 1.841e-02 , Time: 72.69\n",
            "It: 1000, Loss: 1.478e+00,  loss_bc1: 2.272e-02,  loss_bc2: 1.214e-02, loss_ics_u: 1.112e-01, loss_ics_u_t: 3.509e-03, Loss_res: 1.800e-02 , Time: 75.71\n",
            "loss_bc1: 2.272e+01\n",
            "loss_bc2: 1.214e+01\n",
            "loss_ics_u: 1.112e+02\n",
            "lam_r_val: 1.800e+01\n",
            "It: 1100, Loss: 1.563e+00,  loss_bc1: 2.233e-02,  loss_bc2: 1.120e-02, loss_ics_u: 1.210e-01, loss_ics_u_t: 1.044e-02, Loss_res: 1.692e-02 , Time: 76.13\n",
            "It: 1200, Loss: 1.445e+00,  loss_bc1: 2.187e-02,  loss_bc2: 1.173e-02, loss_ics_u: 1.093e-01, loss_ics_u_t: 3.215e-03, Loss_res: 1.642e-02 , Time: 76.66\n",
            "It: 1300, Loss: 1.448e+00,  loss_bc1: 2.201e-02,  loss_bc2: 1.131e-02, loss_ics_u: 1.101e-01, loss_ics_u_t: 2.743e-03, Loss_res: 1.368e-02 , Time: 75.52\n",
            "It: 1400, Loss: 1.426e+00,  loss_bc1: 2.124e-02,  loss_bc2: 1.140e-02, loss_ics_u: 1.085e-01, loss_ics_u_t: 2.876e-03, Loss_res: 1.502e-02 , Time: 77.04\n",
            "It: 1500, Loss: 2.823e+00,  loss_bc1: 2.184e-02,  loss_bc2: 1.817e-02, loss_ics_u: 2.211e-01, loss_ics_u_t: 1.023e-01, Loss_res: 2.122e-01 , Time: 76.01\n",
            "It: 1600, Loss: 1.420e+00,  loss_bc1: 2.085e-02,  loss_bc2: 1.100e-02, loss_ics_u: 1.088e-01, loss_ics_u_t: 2.616e-03, Loss_res: 1.363e-02 , Time: 76.97\n",
            "It: 1700, Loss: 1.402e+00,  loss_bc1: 2.036e-02,  loss_bc2: 1.098e-02, loss_ics_u: 1.075e-01, loss_ics_u_t: 2.429e-03, Loss_res: 1.276e-02 , Time: 74.35\n",
            "It: 1800, Loss: 1.386e+00,  loss_bc1: 1.985e-02,  loss_bc2: 1.082e-02, loss_ics_u: 1.068e-01, loss_ics_u_t: 2.077e-03, Loss_res: 1.200e-02 , Time: 77.02\n",
            "It: 1900, Loss: 1.383e+00,  loss_bc1: 1.975e-02,  loss_bc2: 1.024e-02, loss_ics_u: 1.071e-01, loss_ics_u_t: 1.926e-03, Loss_res: 1.199e-02 , Time: 74.61\n",
            "It: 2000, Loss: 2.053e+00,  loss_bc1: 2.239e-02,  loss_bc2: 1.205e-02, loss_ics_u: 1.510e-01, loss_ics_u_t: 4.575e-02, Loss_res: 1.982e-01 , Time: 76.29\n",
            "loss_bc1: 2.239e+01\n",
            "loss_bc2: 1.205e+01\n",
            "loss_ics_u: 1.510e+02\n",
            "lam_r_val: 1.982e+02\n",
            "It: 2100, Loss: 1.361e+00,  loss_bc1: 1.900e-02,  loss_bc2: 1.010e-02, loss_ics_u: 1.059e-01, loss_ics_u_t: 1.691e-03, Loss_res: 1.097e-02 , Time: 74.80\n",
            "It: 2200, Loss: 2.036e+00,  loss_bc1: 2.827e-02,  loss_bc2: 1.270e-02, loss_ics_u: 1.596e-01, loss_ics_u_t: 5.558e-02, Loss_res: 3.098e-02 , Time: 74.25\n",
            "It: 2300, Loss: 1.329e+00,  loss_bc1: 1.797e-02,  loss_bc2: 9.980e-03, loss_ics_u: 1.038e-01, loss_ics_u_t: 1.199e-03, Loss_res: 1.125e-02 , Time: 71.05\n",
            "It: 2400, Loss: 1.336e+00,  loss_bc1: 1.776e-02,  loss_bc2: 9.393e-03, loss_ics_u: 1.051e-01, loss_ics_u_t: 1.376e-03, Loss_res: 1.274e-02 , Time: 72.56\n",
            "It: 2500, Loss: 1.307e+00,  loss_bc1: 1.700e-02,  loss_bc2: 9.713e-03, loss_ics_u: 1.027e-01, loss_ics_u_t: 1.049e-03, Loss_res: 1.277e-02 , Time: 71.39\n",
            "It: 2600, Loss: 1.306e+00,  loss_bc1: 1.688e-02,  loss_bc2: 9.195e-03, loss_ics_u: 1.031e-01, loss_ics_u_t: 1.009e-03, Loss_res: 1.333e-02 , Time: 68.17\n",
            "It: 2700, Loss: 1.377e+00,  loss_bc1: 1.680e-02,  loss_bc2: 9.450e-03, loss_ics_u: 1.098e-01, loss_ics_u_t: 9.069e-03, Loss_res: 1.612e-02 , Time: 53.66\n",
            "It: 2800, Loss: 1.282e+00,  loss_bc1: 1.646e-02,  loss_bc2: 8.102e-03, loss_ics_u: 1.022e-01, loss_ics_u_t: 1.093e-03, Loss_res: 1.430e-02 , Time: 53.67\n",
            "It: 2900, Loss: 1.247e+00,  loss_bc1: 1.447e-02,  loss_bc2: 7.990e-03, loss_ics_u: 1.007e-01, loss_ics_u_t: 1.091e-03, Loss_res: 1.550e-02 , Time: 55.79\n",
            "It: 3000, Loss: 1.244e+00,  loss_bc1: 1.348e-02,  loss_bc2: 6.440e-03, loss_ics_u: 1.017e-01, loss_ics_u_t: 1.257e-03, Loss_res: 2.758e-02 , Time: 53.23\n",
            "loss_bc1: 1.348e+01\n",
            "loss_bc2: 6.440e+00\n",
            "loss_ics_u: 1.017e+02\n",
            "lam_r_val: 2.758e+01\n",
            "It: 3100, Loss: 1.280e+00,  loss_bc1: 1.834e-02,  loss_bc2: 7.124e-03, loss_ics_u: 9.815e-02, loss_ics_u_t: 1.575e-03, Loss_res: 4.400e-02 , Time: 54.08\n",
            "It: 3200, Loss: 1.155e+00,  loss_bc1: 1.055e-02,  loss_bc2: 5.002e-03, loss_ics_u: 9.848e-02, loss_ics_u_t: 1.430e-03, Loss_res: 1.491e-02 , Time: 55.81\n",
            "It: 3300, Loss: 1.127e+00,  loss_bc1: 8.949e-03,  loss_bc2: 4.324e-03, loss_ics_u: 9.800e-02, loss_ics_u_t: 1.517e-03, Loss_res: 1.401e-02 , Time: 53.41\n",
            "It: 3400, Loss: 1.119e+00,  loss_bc1: 9.002e-03,  loss_bc2: 3.823e-03, loss_ics_u: 9.735e-02, loss_ics_u_t: 1.650e-03, Loss_res: 1.703e-02 , Time: 53.21\n",
            "It: 3500, Loss: 1.707e+00,  loss_bc1: 4.054e-03,  loss_bc2: 8.187e-03, loss_ics_u: 1.063e-01, loss_ics_u_t: 1.085e-02, Loss_res: 5.222e-01 , Time: 55.25\n",
            "It: 3600, Loss: 1.076e+00,  loss_bc1: 5.291e-03,  loss_bc2: 3.590e-03, loss_ics_u: 9.464e-02, loss_ics_u_t: 1.673e-03, Loss_res: 4.055e-02 , Time: 53.84\n",
            "It: 3700, Loss: 1.084e+00,  loss_bc1: 5.286e-03,  loss_bc2: 3.456e-03, loss_ics_u: 9.544e-02, loss_ics_u_t: 1.625e-03, Loss_res: 4.222e-02 , Time: 53.51\n",
            "It: 3800, Loss: 1.321e+00,  loss_bc1: 5.841e-03,  loss_bc2: 5.063e-03, loss_ics_u: 9.386e-02, loss_ics_u_t: 3.217e-03, Loss_res: 2.729e-01 , Time: 55.68\n",
            "It: 3900, Loss: 1.009e+00,  loss_bc1: 5.022e-03,  loss_bc2: 3.052e-03, loss_ics_u: 9.180e-02, loss_ics_u_t: 1.050e-03, Loss_res: 1.052e-02 , Time: 53.76\n",
            "It: 4000, Loss: 1.009e+00,  loss_bc1: 5.733e-03,  loss_bc2: 3.166e-03, loss_ics_u: 9.089e-02, loss_ics_u_t: 1.386e-03, Loss_res: 1.076e-02 , Time: 53.71\n",
            "loss_bc1: 5.733e+00\n",
            "loss_bc2: 3.166e+00\n",
            "loss_ics_u: 9.089e+01\n",
            "lam_r_val: 1.076e+01\n",
            "It: 4100, Loss: 9.947e-01,  loss_bc1: 4.978e-03,  loss_bc2: 2.899e-03, loss_ics_u: 9.010e-02, loss_ics_u_t: 1.116e-03, Loss_res: 1.490e-02 , Time: 56.13\n",
            "It: 4200, Loss: 1.042e+00,  loss_bc1: 4.331e-03,  loss_bc2: 4.240e-03, loss_ics_u: 9.379e-02, loss_ics_u_t: 3.547e-03, Loss_res: 1.888e-02 , Time: 53.68\n",
            "It: 4300, Loss: 9.841e-01,  loss_bc1: 5.945e-03,  loss_bc2: 3.038e-03, loss_ics_u: 8.851e-02, loss_ics_u_t: 1.177e-03, Loss_res: 9.114e-03 , Time: 55.58\n",
            "It: 4400, Loss: 9.702e-01,  loss_bc1: 4.523e-03,  loss_bc2: 3.307e-03, loss_ics_u: 8.839e-02, loss_ics_u_t: 1.127e-03, Loss_res: 8.009e-03 , Time: 57.67\n",
            "It: 4500, Loss: 1.791e+00,  loss_bc1: 4.083e-03,  loss_bc2: 7.561e-03, loss_ics_u: 1.331e-01, loss_ics_u_t: 4.267e-02, Loss_res: 3.435e-01 , Time: 57.83\n",
            "It: 4600, Loss: 1.031e+00,  loss_bc1: 3.519e-03,  loss_bc2: 3.482e-03, loss_ics_u: 8.850e-02, loss_ics_u_t: 1.627e-03, Loss_res: 7.633e-02 , Time: 58.89\n",
            "It: 4700, Loss: 1.014e+00,  loss_bc1: 6.263e-03,  loss_bc2: 3.341e-03, loss_ics_u: 8.665e-02, loss_ics_u_t: 1.751e-03, Loss_res: 5.183e-02 , Time: 71.54\n",
            "It: 4800, Loss: 1.170e+00,  loss_bc1: 4.942e-03,  loss_bc2: 5.510e-03, loss_ics_u: 1.035e-01, loss_ics_u_t: 1.868e-02, Loss_res: 3.116e-02 , Time: 76.10\n",
            "It: 4900, Loss: 9.828e-01,  loss_bc1: 4.498e-03,  loss_bc2: 3.446e-03, loss_ics_u: 8.656e-02, loss_ics_u_t: 2.290e-03, Loss_res: 3.784e-02 , Time: 76.38\n",
            "It: 5000, Loss: 9.557e-01,  loss_bc1: 4.098e-03,  loss_bc2: 3.168e-03, loss_ics_u: 8.489e-02, loss_ics_u_t: 1.194e-03, Loss_res: 3.418e-02 , Time: 73.75\n",
            "loss_bc1: 4.098e+00\n",
            "loss_bc2: 3.168e+00\n",
            "loss_ics_u: 8.489e+01\n",
            "lam_r_val: 3.418e+01\n",
            "It: 5100, Loss: 9.687e-01,  loss_bc1: 3.923e-03,  loss_bc2: 3.912e-03, loss_ics_u: 8.709e-02, loss_ics_u_t: 4.294e-03, Loss_res: 1.950e-02 , Time: 73.58\n",
            "It: 5200, Loss: 9.129e-01,  loss_bc1: 4.137e-03,  loss_bc2: 3.438e-03, loss_ics_u: 8.207e-02, loss_ics_u_t: 1.002e-03, Loss_res: 1.642e-02 , Time: 77.51\n",
            "It: 5300, Loss: 1.095e+00,  loss_bc1: 3.550e-03,  loss_bc2: 3.475e-03, loss_ics_u: 8.357e-02, loss_ics_u_t: 3.142e-03, Loss_res: 1.894e-01 , Time: 76.86\n",
            "It: 5400, Loss: 1.796e+00,  loss_bc1: 4.938e-03,  loss_bc2: 7.833e-03, loss_ics_u: 1.210e-01, loss_ics_u_t: 4.199e-02, Loss_res: 4.579e-01 , Time: 77.15\n",
            "It: 5500, Loss: 9.146e-01,  loss_bc1: 4.190e-03,  loss_bc2: 3.457e-03, loss_ics_u: 7.806e-02, loss_ics_u_t: 3.310e-03, Loss_res: 5.760e-02 , Time: 77.69\n",
            "It: 5600, Loss: 8.874e-01,  loss_bc1: 4.741e-03,  loss_bc2: 3.661e-03, loss_ics_u: 7.725e-02, loss_ics_u_t: 4.558e-03, Loss_res: 3.084e-02 , Time: 78.73\n",
            "It: 5700, Loss: 8.156e-01,  loss_bc1: 4.428e-03,  loss_bc2: 2.747e-03, loss_ics_u: 7.299e-02, loss_ics_u_t: 1.868e-03, Loss_res: 1.395e-02 , Time: 78.34\n",
            "It: 5800, Loss: 8.005e-01,  loss_bc1: 4.570e-03,  loss_bc2: 2.621e-03, loss_ics_u: 7.151e-02, loss_ics_u_t: 2.175e-03, Loss_res: 1.347e-02 , Time: 78.12\n",
            "It: 5900, Loss: 7.891e-01,  loss_bc1: 4.464e-03,  loss_bc2: 2.990e-03, loss_ics_u: 7.028e-02, loss_ics_u_t: 2.378e-03, Loss_res: 1.179e-02 , Time: 78.88\n",
            "It: 6000, Loss: 7.830e-01,  loss_bc1: 4.223e-03,  loss_bc2: 2.653e-03, loss_ics_u: 7.053e-02, loss_ics_u_t: 2.020e-03, Loss_res: 9.007e-03 , Time: 76.38\n",
            "loss_bc1: 4.223e+00\n",
            "loss_bc2: 2.653e+00\n",
            "loss_ics_u: 7.053e+01\n",
            "lam_r_val: 9.007e+00\n",
            "It: 6100, Loss: 7.638e-01,  loss_bc1: 4.200e-03,  loss_bc2: 2.658e-03, loss_ics_u: 6.864e-02, loss_ics_u_t: 2.488e-03, Loss_res: 8.811e-03 , Time: 77.93\n",
            "It: 6200, Loss: 7.566e-01,  loss_bc1: 4.102e-03,  loss_bc2: 2.588e-03, loss_ics_u: 6.812e-02, loss_ics_u_t: 2.442e-03, Loss_res: 8.430e-03 , Time: 72.83\n",
            "It: 6300, Loss: 7.596e-01,  loss_bc1: 4.378e-03,  loss_bc2: 2.718e-03, loss_ics_u: 6.748e-02, loss_ics_u_t: 2.810e-03, Loss_res: 1.385e-02 , Time: 77.14\n",
            "It: 6400, Loss: 7.599e-01,  loss_bc1: 4.504e-03,  loss_bc2: 2.360e-03, loss_ics_u: 6.672e-02, loss_ics_u_t: 2.508e-03, Loss_res: 2.407e-02 , Time: 76.98\n",
            "It: 6500, Loss: 1.597e+00,  loss_bc1: 7.307e-03,  loss_bc2: 5.747e-03, loss_ics_u: 1.130e-01, loss_ics_u_t: 5.041e-02, Loss_res: 3.365e-01 , Time: 77.96\n",
            "It: 6600, Loss: 1.162e+00,  loss_bc1: 4.680e-03,  loss_bc2: 3.059e-03, loss_ics_u: 8.589e-02, loss_ics_u_t: 2.404e-02, Loss_res: 2.253e-01 , Time: 76.03\n",
            "It: 6700, Loss: 8.662e-01,  loss_bc1: 4.537e-03,  loss_bc2: 2.896e-03, loss_ics_u: 7.274e-02, loss_ics_u_t: 1.172e-02, Loss_res: 6.444e-02 , Time: 77.89\n",
            "It: 6800, Loss: 7.086e-01,  loss_bc1: 4.110e-03,  loss_bc2: 2.548e-03, loss_ics_u: 6.305e-02, loss_ics_u_t: 2.561e-03, Loss_res: 1.151e-02 , Time: 75.71\n",
            "It: 6900, Loss: 7.576e-01,  loss_bc1: 4.233e-03,  loss_bc2: 2.410e-03, loss_ics_u: 6.361e-02, loss_ics_u_t: 3.653e-03, Loss_res: 5.510e-02 , Time: 76.66\n",
            "It: 7000, Loss: 6.922e-01,  loss_bc1: 3.925e-03,  loss_bc2: 2.624e-03, loss_ics_u: 6.131e-02, loss_ics_u_t: 2.289e-03, Loss_res: 1.368e-02 , Time: 75.46\n",
            "loss_bc1: 3.925e+00\n",
            "loss_bc2: 2.624e+00\n",
            "loss_ics_u: 6.131e+01\n",
            "lam_r_val: 1.368e+01\n",
            "It: 7100, Loss: 6.779e-01,  loss_bc1: 4.193e-03,  loss_bc2: 2.653e-03, loss_ics_u: 5.991e-02, loss_ics_u_t: 2.236e-03, Loss_res: 1.036e-02 , Time: 76.73\n",
            "It: 7200, Loss: 6.656e-01,  loss_bc1: 4.207e-03,  loss_bc2: 2.375e-03, loss_ics_u: 5.888e-02, loss_ics_u_t: 2.019e-03, Loss_res: 1.094e-02 , Time: 76.46\n",
            "It: 7300, Loss: 7.112e-01,  loss_bc1: 5.505e-03,  loss_bc2: 2.506e-03, loss_ics_u: 6.111e-02, loss_ics_u_t: 5.738e-03, Loss_res: 2.004e-02 , Time: 75.83\n",
            "It: 7400, Loss: 6.695e-01,  loss_bc1: 4.297e-03,  loss_bc2: 2.345e-03, loss_ics_u: 5.727e-02, loss_ics_u_t: 2.090e-03, Loss_res: 3.037e-02 , Time: 73.91\n",
            "It: 7500, Loss: 6.750e-01,  loss_bc1: 4.879e-03,  loss_bc2: 2.173e-03, loss_ics_u: 5.688e-02, loss_ics_u_t: 3.309e-03, Loss_res: 3.563e-02 , Time: 76.51\n",
            "It: 7600, Loss: 6.191e-01,  loss_bc1: 4.375e-03,  loss_bc2: 2.572e-03, loss_ics_u: 5.383e-02, loss_ics_u_t: 2.163e-03, Loss_res: 1.130e-02 , Time: 74.93\n",
            "It: 7700, Loss: 6.083e-01,  loss_bc1: 4.465e-03,  loss_bc2: 2.524e-03, loss_ics_u: 5.267e-02, loss_ics_u_t: 2.092e-03, Loss_res: 1.170e-02 , Time: 78.42\n",
            "It: 7800, Loss: 5.997e-01,  loss_bc1: 4.522e-03,  loss_bc2: 2.570e-03, loss_ics_u: 5.168e-02, loss_ics_u_t: 2.216e-03, Loss_res: 1.192e-02 , Time: 75.85\n",
            "It: 7900, Loss: 5.873e-01,  loss_bc1: 4.653e-03,  loss_bc2: 2.612e-03, loss_ics_u: 5.027e-02, loss_ics_u_t: 2.437e-03, Loss_res: 1.198e-02 , Time: 78.72\n",
            "It: 8000, Loss: 5.793e-01,  loss_bc1: 4.758e-03,  loss_bc2: 2.538e-03, loss_ics_u: 4.948e-02, loss_ics_u_t: 2.374e-03, Loss_res: 1.155e-02 , Time: 75.79\n",
            "loss_bc1: 4.758e+00\n",
            "loss_bc2: 2.538e+00\n",
            "loss_ics_u: 4.948e+01\n",
            "lam_r_val: 1.155e+01\n",
            "It: 8100, Loss: 5.715e-01,  loss_bc1: 4.792e-03,  loss_bc2: 2.661e-03, loss_ics_u: 4.852e-02, loss_ics_u_t: 2.465e-03, Loss_res: 1.170e-02 , Time: 78.40\n",
            "It: 8200, Loss: 5.624e-01,  loss_bc1: 4.905e-03,  loss_bc2: 2.607e-03, loss_ics_u: 4.751e-02, loss_ics_u_t: 2.469e-03, Loss_res: 1.220e-02 , Time: 76.64\n",
            "It: 8300, Loss: 5.546e-01,  loss_bc1: 5.044e-03,  loss_bc2: 2.680e-03, loss_ics_u: 4.651e-02, loss_ics_u_t: 2.423e-03, Loss_res: 1.227e-02 , Time: 78.09\n",
            "It: 8400, Loss: 7.931e-01,  loss_bc1: 7.336e-03,  loss_bc2: 4.459e-03, loss_ics_u: 6.173e-02, loss_ics_u_t: 1.856e-02, Loss_res: 5.783e-02 , Time: 79.65\n",
            "It: 8500, Loss: 5.461e-01,  loss_bc1: 5.298e-03,  loss_bc2: 2.662e-03, loss_ics_u: 4.479e-02, loss_ics_u_t: 2.610e-03, Loss_res: 1.866e-02 , Time: 78.92\n",
            "It: 8600, Loss: 5.296e-01,  loss_bc1: 5.323e-03,  loss_bc2: 2.793e-03, loss_ics_u: 4.348e-02, loss_ics_u_t: 2.470e-03, Loss_res: 1.363e-02 , Time: 80.35\n",
            "It: 8700, Loss: 5.200e-01,  loss_bc1: 5.398e-03,  loss_bc2: 2.836e-03, loss_ics_u: 4.225e-02, loss_ics_u_t: 2.291e-03, Loss_res: 1.520e-02 , Time: 75.00\n",
            "It: 8800, Loss: 5.018e-01,  loss_bc1: 5.563e-03,  loss_bc2: 2.955e-03, loss_ics_u: 4.049e-02, loss_ics_u_t: 1.822e-03, Loss_res: 1.170e-02 , Time: 75.30\n",
            "It: 8900, Loss: 4.899e-01,  loss_bc1: 5.763e-03,  loss_bc2: 2.920e-03, loss_ics_u: 3.922e-02, loss_ics_u_t: 1.716e-03, Loss_res: 1.088e-02 , Time: 74.10\n",
            "It: 9000, Loss: 4.783e-01,  loss_bc1: 5.800e-03,  loss_bc2: 3.103e-03, loss_ics_u: 3.789e-02, loss_ics_u_t: 1.665e-03, Loss_res: 1.036e-02 , Time: 76.71\n",
            "loss_bc1: 5.800e+00\n",
            "loss_bc2: 3.103e+00\n",
            "loss_ics_u: 3.789e+01\n",
            "lam_r_val: 1.036e+01\n",
            "It: 9100, Loss: 4.696e-01,  loss_bc1: 5.899e-03,  loss_bc2: 3.051e-03, loss_ics_u: 3.700e-02, loss_ics_u_t: 1.550e-03, Loss_res: 1.010e-02 , Time: 73.19\n",
            "It: 9200, Loss: 4.652e-01,  loss_bc1: 6.146e-03,  loss_bc2: 3.038e-03, loss_ics_u: 3.594e-02, loss_ics_u_t: 1.482e-03, Loss_res: 1.397e-02 , Time: 75.40\n",
            "It: 9300, Loss: 4.547e-01,  loss_bc1: 6.134e-03,  loss_bc2: 3.205e-03, loss_ics_u: 3.499e-02, loss_ics_u_t: 1.734e-03, Loss_res: 1.139e-02 , Time: 75.03\n",
            "It: 9400, Loss: 4.518e-01,  loss_bc1: 6.151e-03,  loss_bc2: 3.293e-03, loss_ics_u: 3.435e-02, loss_ics_u_t: 2.152e-03, Loss_res: 1.387e-02 , Time: 80.33\n",
            "It: 9500, Loss: 4.313e-01,  loss_bc1: 6.281e-03,  loss_bc2: 3.294e-03, loss_ics_u: 3.250e-02, loss_ics_u_t: 1.616e-03, Loss_res: 1.052e-02 , Time: 79.46\n",
            "It: 9600, Loss: 4.204e-01,  loss_bc1: 6.426e-03,  loss_bc2: 3.276e-03, loss_ics_u: 3.131e-02, loss_ics_u_t: 1.641e-03, Loss_res: 1.028e-02 , Time: 81.45\n",
            "It: 9700, Loss: 4.138e-01,  loss_bc1: 6.481e-03,  loss_bc2: 3.325e-03, loss_ics_u: 3.056e-02, loss_ics_u_t: 1.659e-03, Loss_res: 1.022e-02 , Time: 80.12\n",
            "It: 9800, Loss: 4.103e-01,  loss_bc1: 6.642e-03,  loss_bc2: 3.468e-03, loss_ics_u: 2.968e-02, loss_ics_u_t: 2.012e-03, Loss_res: 1.233e-02 , Time: 79.98\n",
            "It: 9900, Loss: 4.034e-01,  loss_bc1: 6.712e-03,  loss_bc2: 3.423e-03, loss_ics_u: 2.913e-02, loss_ics_u_t: 2.334e-03, Loss_res: 1.070e-02 , Time: 78.47\n",
            "It: 10000, Loss: 3.976e-01,  loss_bc1: 6.799e-03,  loss_bc2: 3.336e-03, loss_ics_u: 2.852e-02, loss_ics_u_t: 1.754e-03, Loss_res: 1.107e-02 , Time: 78.65\n",
            "loss_bc1: 6.799e+00\n",
            "loss_bc2: 3.336e+00\n",
            "loss_ics_u: 2.852e+01\n",
            "lam_r_val: 1.107e+01\n",
            "It: 10100, Loss: 4.379e-01,  loss_bc1: 6.949e-03,  loss_bc2: 3.794e-03, loss_ics_u: 2.997e-02, loss_ics_u_t: 3.854e-03, Loss_res: 3.075e-02 , Time: 80.60\n",
            "It: 10200, Loss: 4.973e-01,  loss_bc1: 7.146e-03,  loss_bc2: 3.565e-03, loss_ics_u: 3.371e-02, loss_ics_u_t: 9.230e-03, Loss_res: 5.312e-02 , Time: 79.43\n",
            "It: 10300, Loss: 3.735e-01,  loss_bc1: 6.939e-03,  loss_bc2: 3.519e-03, loss_ics_u: 2.570e-02, loss_ics_u_t: 1.874e-03, Loss_res: 1.196e-02 , Time: 82.03\n",
            "It: 10400, Loss: 3.676e-01,  loss_bc1: 6.937e-03,  loss_bc2: 3.585e-03, loss_ics_u: 2.522e-02, loss_ics_u_t: 1.901e-03, Loss_res: 1.014e-02 , Time: 81.97\n",
            "It: 10500, Loss: 3.610e-01,  loss_bc1: 6.994e-03,  loss_bc2: 3.569e-03, loss_ics_u: 2.450e-02, loss_ics_u_t: 1.887e-03, Loss_res: 1.039e-02 , Time: 80.15\n",
            "It: 10600, Loss: 3.563e-01,  loss_bc1: 7.024e-03,  loss_bc2: 3.580e-03, loss_ics_u: 2.399e-02, loss_ics_u_t: 1.866e-03, Loss_res: 1.041e-02 , Time: 81.05\n",
            "It: 10700, Loss: 7.093e-01,  loss_bc1: 7.472e-03,  loss_bc2: 3.750e-03, loss_ics_u: 4.689e-02, loss_ics_u_t: 2.525e-02, Loss_res: 1.282e-01 , Time: 80.80\n",
            "It: 10800, Loss: 3.901e-01,  loss_bc1: 6.825e-03,  loss_bc2: 3.628e-03, loss_ics_u: 2.553e-02, loss_ics_u_t: 3.978e-03, Loss_res: 3.027e-02 , Time: 67.65\n",
            "It: 10900, Loss: 3.876e-01,  loss_bc1: 7.107e-03,  loss_bc2: 3.798e-03, loss_ics_u: 2.440e-02, loss_ics_u_t: 3.752e-03, Loss_res: 3.462e-02 , Time: 55.05\n",
            "It: 11000, Loss: 3.696e-01,  loss_bc1: 6.840e-03,  loss_bc2: 3.639e-03, loss_ics_u: 2.331e-02, loss_ics_u_t: 2.455e-03, Loss_res: 3.165e-02 , Time: 55.80\n",
            "loss_bc1: 6.840e+00\n",
            "loss_bc2: 3.639e+00\n",
            "loss_ics_u: 2.331e+01\n",
            "lam_r_val: 3.165e+01\n",
            "It: 11100, Loss: 3.351e-01,  loss_bc1: 7.156e-03,  loss_bc2: 3.756e-03, loss_ics_u: 2.146e-02, loss_ics_u_t: 2.248e-03, Loss_res: 1.140e-02 , Time: 55.95\n",
            "It: 11200, Loss: 3.256e-01,  loss_bc1: 7.088e-03,  loss_bc2: 3.790e-03, loss_ics_u: 2.064e-02, loss_ics_u_t: 1.788e-03, Loss_res: 1.042e-02 , Time: 55.19\n",
            "It: 11300, Loss: 3.257e-01,  loss_bc1: 6.994e-03,  loss_bc2: 3.754e-03, loss_ics_u: 2.075e-02, loss_ics_u_t: 1.726e-03, Loss_res: 1.077e-02 , Time: 55.55\n",
            "It: 11400, Loss: 3.261e-01,  loss_bc1: 7.187e-03,  loss_bc2: 4.005e-03, loss_ics_u: 1.964e-02, loss_ics_u_t: 1.777e-03, Loss_res: 1.781e-02 , Time: 55.07\n",
            "It: 11500, Loss: 3.137e-01,  loss_bc1: 7.065e-03,  loss_bc2: 3.844e-03, loss_ics_u: 1.942e-02, loss_ics_u_t: 1.747e-03, Loss_res: 1.044e-02 , Time: 55.36\n",
            "It: 11600, Loss: 3.172e-01,  loss_bc1: 7.002e-03,  loss_bc2: 3.905e-03, loss_ics_u: 1.940e-02, loss_ics_u_t: 1.920e-03, Loss_res: 1.409e-02 , Time: 55.09\n",
            "It: 11700, Loss: 4.367e-01,  loss_bc1: 7.215e-03,  loss_bc2: 3.986e-03, loss_ics_u: 2.801e-02, loss_ics_u_t: 1.070e-02, Loss_res: 4.450e-02 , Time: 55.11\n",
            "It: 11800, Loss: 3.002e-01,  loss_bc1: 7.086e-03,  loss_bc2: 3.992e-03, loss_ics_u: 1.790e-02, loss_ics_u_t: 1.706e-03, Loss_res: 1.035e-02 , Time: 55.04\n",
            "It: 11900, Loss: 2.975e-01,  loss_bc1: 7.008e-03,  loss_bc2: 3.949e-03, loss_ics_u: 1.777e-02, loss_ics_u_t: 1.667e-03, Loss_res: 1.023e-02 , Time: 54.88\n",
            "It: 12000, Loss: 3.348e-01,  loss_bc1: 7.114e-03,  loss_bc2: 4.274e-03, loss_ics_u: 1.774e-02, loss_ics_u_t: 1.767e-03, Loss_res: 4.346e-02 , Time: 54.10\n",
            "loss_bc1: 7.114e+00\n",
            "loss_bc2: 4.274e+00\n",
            "loss_ics_u: 1.774e+01\n",
            "lam_r_val: 4.346e+01\n",
            "It: 12100, Loss: 2.909e-01,  loss_bc1: 7.036e-03,  loss_bc2: 4.099e-03, loss_ics_u: 1.687e-02, loss_ics_u_t: 1.796e-03, Loss_res: 1.087e-02 , Time: 54.01\n",
            "It: 12200, Loss: 2.861e-01,  loss_bc1: 6.959e-03,  loss_bc2: 4.065e-03, loss_ics_u: 1.658e-02, loss_ics_u_t: 1.637e-03, Loss_res: 1.008e-02 , Time: 52.40\n",
            "It: 12300, Loss: 2.978e-01,  loss_bc1: 6.993e-03,  loss_bc2: 4.106e-03, loss_ics_u: 1.677e-02, loss_ics_u_t: 1.975e-03, Loss_res: 1.911e-02 , Time: 52.05\n",
            "It: 12400, Loss: 3.435e-01,  loss_bc1: 7.275e-03,  loss_bc2: 4.433e-03, loss_ics_u: 1.960e-02, loss_ics_u_t: 4.987e-03, Loss_res: 3.041e-02 , Time: 52.95\n",
            "It: 12500, Loss: 2.966e-01,  loss_bc1: 6.911e-03,  loss_bc2: 4.143e-03, loss_ics_u: 1.562e-02, loss_ics_u_t: 1.775e-03, Loss_res: 2.992e-02 , Time: 51.41\n",
            "It: 12600, Loss: 2.788e-01,  loss_bc1: 6.858e-03,  loss_bc2: 4.222e-03, loss_ics_u: 1.559e-02, loss_ics_u_t: 2.015e-03, Loss_res: 1.210e-02 , Time: 52.01\n",
            "It: 12700, Loss: 2.697e-01,  loss_bc1: 6.819e-03,  loss_bc2: 4.166e-03, loss_ics_u: 1.502e-02, loss_ics_u_t: 1.590e-03, Loss_res: 9.694e-03 , Time: 51.66\n",
            "It: 12800, Loss: 2.815e-01,  loss_bc1: 6.719e-03,  loss_bc2: 4.265e-03, loss_ics_u: 1.576e-02, loss_ics_u_t: 2.409e-03, Loss_res: 1.412e-02 , Time: 51.91\n",
            "It: 12900, Loss: 3.047e-01,  loss_bc1: 6.905e-03,  loss_bc2: 4.196e-03, loss_ics_u: 1.699e-02, loss_ics_u_t: 3.855e-03, Loss_res: 2.379e-02 , Time: 51.84\n",
            "It: 13000, Loss: 5.728e-01,  loss_bc1: 6.850e-03,  loss_bc2: 4.509e-03, loss_ics_u: 2.359e-02, loss_ics_u_t: 1.099e-02, Loss_res: 2.233e-01 , Time: 51.48\n",
            "loss_bc1: 6.850e+00\n",
            "loss_bc2: 4.509e+00\n",
            "loss_ics_u: 2.359e+01\n",
            "lam_r_val: 2.233e+02\n",
            "It: 13100, Loss: 2.639e-01,  loss_bc1: 6.741e-03,  loss_bc2: 4.268e-03, loss_ics_u: 1.426e-02, loss_ics_u_t: 2.013e-03, Loss_res: 1.124e-02 , Time: 51.31\n",
            "It: 13200, Loss: 2.547e-01,  loss_bc1: 6.676e-03,  loss_bc2: 4.246e-03, loss_ics_u: 1.362e-02, loss_ics_u_t: 1.528e-03, Loss_res: 9.340e-03 , Time: 50.14\n",
            "It: 13300, Loss: 2.528e-01,  loss_bc1: 6.628e-03,  loss_bc2: 4.314e-03, loss_ics_u: 1.341e-02, loss_ics_u_t: 1.506e-03, Loss_res: 9.358e-03 , Time: 50.62\n",
            "It: 13400, Loss: 2.497e-01,  loss_bc1: 6.603e-03,  loss_bc2: 4.277e-03, loss_ics_u: 1.318e-02, loss_ics_u_t: 1.498e-03, Loss_res: 9.151e-03 , Time: 39.97\n",
            "It: 13500, Loss: 2.498e-01,  loss_bc1: 6.554e-03,  loss_bc2: 4.233e-03, loss_ics_u: 1.325e-02, loss_ics_u_t: 1.601e-03, Loss_res: 9.466e-03 , Time: 35.81\n",
            "It: 13600, Loss: 2.510e-01,  loss_bc1: 6.606e-03,  loss_bc2: 4.409e-03, loss_ics_u: 1.268e-02, loss_ics_u_t: 1.522e-03, Loss_res: 1.409e-02 , Time: 35.96\n",
            "It: 13700, Loss: 2.426e-01,  loss_bc1: 6.522e-03,  loss_bc2: 4.292e-03, loss_ics_u: 1.253e-02, loss_ics_u_t: 1.488e-03, Loss_res: 9.143e-03 , Time: 34.95\n",
            "It: 13800, Loss: 2.411e-01,  loss_bc1: 6.462e-03,  loss_bc2: 4.247e-03, loss_ics_u: 1.246e-02, loss_ics_u_t: 1.437e-03, Loss_res: 9.499e-03 , Time: 35.17\n",
            "It: 13900, Loss: 2.433e-01,  loss_bc1: 6.526e-03,  loss_bc2: 4.361e-03, loss_ics_u: 1.217e-02, loss_ics_u_t: 1.527e-03, Loss_res: 1.282e-02 , Time: 35.58\n",
            "It: 14000, Loss: 2.343e-01,  loss_bc1: 6.421e-03,  loss_bc2: 4.316e-03, loss_ics_u: 1.183e-02, loss_ics_u_t: 1.396e-03, Loss_res: 8.581e-03 , Time: 34.92\n",
            "loss_bc1: 6.421e+00\n",
            "loss_bc2: 4.316e+00\n",
            "loss_ics_u: 1.183e+01\n",
            "lam_r_val: 8.581e+00\n",
            "It: 14100, Loss: 2.318e-01,  loss_bc1: 6.398e-03,  loss_bc2: 4.300e-03, loss_ics_u: 1.164e-02, loss_ics_u_t: 1.373e-03, Loss_res: 8.388e-03 , Time: 35.15\n",
            "It: 14200, Loss: 2.521e-01,  loss_bc1: 6.329e-03,  loss_bc2: 4.280e-03, loss_ics_u: 1.300e-02, loss_ics_u_t: 2.741e-03, Loss_res: 1.601e-02 , Time: 35.24\n",
            "It: 14300, Loss: 2.328e-01,  loss_bc1: 6.356e-03,  loss_bc2: 4.311e-03, loss_ics_u: 1.122e-02, loss_ics_u_t: 1.398e-03, Loss_res: 1.398e-02 , Time: 35.30\n",
            "It: 14400, Loss: 2.267e-01,  loss_bc1: 6.312e-03,  loss_bc2: 4.336e-03, loss_ics_u: 1.113e-02, loss_ics_u_t: 1.466e-03, Loss_res: 8.913e-03 , Time: 35.60\n",
            "It: 14500, Loss: 2.223e-01,  loss_bc1: 6.274e-03,  loss_bc2: 4.301e-03, loss_ics_u: 1.084e-02, loss_ics_u_t: 1.301e-03, Loss_res: 8.136e-03 , Time: 35.03\n",
            "It: 14600, Loss: 3.084e-01,  loss_bc1: 6.341e-03,  loss_bc2: 4.358e-03, loss_ics_u: 1.646e-02, loss_ics_u_t: 7.158e-03, Loss_res: 3.682e-02 , Time: 34.96\n",
            "It: 14700, Loss: 4.644e-01,  loss_bc1: 6.655e-03,  loss_bc2: 4.645e-03, loss_ics_u: 2.385e-02, loss_ics_u_t: 1.449e-02, Loss_res: 1.129e-01 , Time: 36.06\n",
            "It: 14800, Loss: 3.121e-01,  loss_bc1: 6.334e-03,  loss_bc2: 4.312e-03, loss_ics_u: 1.467e-02, loss_ics_u_t: 5.657e-03, Loss_res: 5.886e-02 , Time: 36.83\n",
            "It: 14900, Loss: 2.156e-01,  loss_bc1: 6.146e-03,  loss_bc2: 4.288e-03, loss_ics_u: 1.024e-02, loss_ics_u_t: 1.247e-03, Loss_res: 8.799e-03 , Time: 35.68\n",
            "It: 15000, Loss: 2.594e-01,  loss_bc1: 6.379e-03,  loss_bc2: 4.399e-03, loss_ics_u: 1.247e-02, loss_ics_u_t: 3.547e-03, Loss_res: 2.691e-02 , Time: 36.41\n",
            "loss_bc1: 6.379e+00\n",
            "loss_bc2: 4.399e+00\n",
            "loss_ics_u: 1.247e+01\n",
            "lam_r_val: 2.691e+01\n",
            "It: 15100, Loss: 2.208e-01,  loss_bc1: 6.132e-03,  loss_bc2: 4.327e-03, loss_ics_u: 1.057e-02, loss_ics_u_t: 2.010e-03, Loss_res: 1.053e-02 , Time: 35.36\n",
            "It: 15200, Loss: 2.071e-01,  loss_bc1: 6.055e-03,  loss_bc2: 4.262e-03, loss_ics_u: 9.640e-03, loss_ics_u_t: 1.144e-03, Loss_res: 7.554e-03 , Time: 36.46\n",
            "It: 15300, Loss: 2.054e-01,  loss_bc1: 6.034e-03,  loss_bc2: 4.299e-03, loss_ics_u: 9.426e-03, loss_ics_u_t: 1.121e-03, Loss_res: 7.801e-03 , Time: 34.58\n",
            "It: 15400, Loss: 2.040e-01,  loss_bc1: 5.974e-03,  loss_bc2: 4.228e-03, loss_ics_u: 9.445e-03, loss_ics_u_t: 1.118e-03, Loss_res: 7.496e-03 , Time: 35.74\n",
            "It: 15500, Loss: 2.358e-01,  loss_bc1: 6.044e-03,  loss_bc2: 4.548e-03, loss_ics_u: 9.842e-03, loss_ics_u_t: 1.724e-03, Loss_res: 3.145e-02 , Time: 36.00\n",
            "It: 15600, Loss: 3.832e-01,  loss_bc1: 6.315e-03,  loss_bc2: 4.465e-03, loss_ics_u: 2.033e-02, loss_ics_u_t: 1.227e-02, Loss_res: 7.202e-02 , Time: 36.84\n",
            "It: 15700, Loss: 1.969e-01,  loss_bc1: 5.943e-03,  loss_bc2: 4.208e-03, loss_ics_u: 8.799e-03, loss_ics_u_t: 1.042e-03, Loss_res: 7.407e-03 , Time: 37.22\n",
            "It: 15800, Loss: 1.980e-01,  loss_bc1: 5.915e-03,  loss_bc2: 4.237e-03, loss_ics_u: 8.817e-03, loss_ics_u_t: 1.206e-03, Loss_res: 8.273e-03 , Time: 55.40\n",
            "It: 15900, Loss: 1.934e-01,  loss_bc1: 5.888e-03,  loss_bc2: 4.182e-03, loss_ics_u: 8.510e-03, loss_ics_u_t: 1.001e-03, Loss_res: 7.615e-03 , Time: 57.00\n",
            "It: 16000, Loss: 1.931e-01,  loss_bc1: 5.856e-03,  loss_bc2: 4.196e-03, loss_ics_u: 8.465e-03, loss_ics_u_t: 1.098e-03, Loss_res: 7.888e-03 , Time: 55.20\n",
            "loss_bc1: 5.856e+00\n",
            "loss_bc2: 4.196e+00\n",
            "loss_ics_u: 8.465e+00\n",
            "lam_r_val: 7.888e+00\n",
            "It: 16100, Loss: 1.943e-01,  loss_bc1: 5.845e-03,  loss_bc2: 4.126e-03, loss_ics_u: 8.247e-03, loss_ics_u_t: 9.700e-04, Loss_res: 1.211e-02 , Time: 52.88\n",
            "It: 16200, Loss: 2.194e-01,  loss_bc1: 6.004e-03,  loss_bc2: 4.230e-03, loss_ics_u: 9.791e-03, loss_ics_u_t: 2.537e-03, Loss_res: 1.916e-02 , Time: 52.27\n",
            "It: 16300, Loss: 2.914e-01,  loss_bc1: 5.961e-03,  loss_bc2: 4.334e-03, loss_ics_u: 1.028e-02, loss_ics_u_t: 3.315e-03, Loss_res: 8.564e-02 , Time: 50.05\n",
            "It: 16400, Loss: 1.919e-01,  loss_bc1: 5.798e-03,  loss_bc2: 4.089e-03, loss_ics_u: 8.202e-03, loss_ics_u_t: 1.285e-03, Loss_res: 1.099e-02 , Time: 50.11\n",
            "It: 16500, Loss: 1.841e-01,  loss_bc1: 5.781e-03,  loss_bc2: 4.088e-03, loss_ics_u: 7.706e-03, loss_ics_u_t: 9.052e-04, Loss_res: 8.374e-03 , Time: 49.95\n",
            "It: 16600, Loss: 1.962e-01,  loss_bc1: 5.775e-03,  loss_bc2: 4.056e-03, loss_ics_u: 8.012e-03, loss_ics_u_t: 1.309e-03, Loss_res: 1.773e-02 , Time: 49.94\n",
            "It: 16700, Loss: 1.792e-01,  loss_bc1: 5.729e-03,  loss_bc2: 4.028e-03, loss_ics_u: 7.428e-03, loss_ics_u_t: 8.710e-04, Loss_res: 7.389e-03 , Time: 50.06\n",
            "It: 16800, Loss: 1.811e-01,  loss_bc1: 5.720e-03,  loss_bc2: 3.958e-03, loss_ics_u: 7.549e-03, loss_ics_u_t: 1.070e-03, Loss_res: 8.829e-03 , Time: 49.97\n",
            "It: 16900, Loss: 1.759e-01,  loss_bc1: 5.677e-03,  loss_bc2: 4.010e-03, loss_ics_u: 7.121e-03, loss_ics_u_t: 8.051e-04, Loss_res: 7.825e-03 , Time: 50.10\n",
            "It: 17000, Loss: 1.731e-01,  loss_bc1: 5.654e-03,  loss_bc2: 3.891e-03, loss_ics_u: 7.078e-03, loss_ics_u_t: 7.682e-04, Loss_res: 6.905e-03 , Time: 50.01\n",
            "loss_bc1: 5.654e+00\n",
            "loss_bc2: 3.891e+00\n",
            "loss_ics_u: 7.078e+00\n",
            "lam_r_val: 6.905e+00\n",
            "It: 17100, Loss: 1.967e-01,  loss_bc1: 5.750e-03,  loss_bc2: 3.928e-03, loss_ics_u: 7.879e-03, loss_ics_u_t: 1.770e-03, Loss_res: 2.115e-02 , Time: 50.06\n",
            "It: 17200, Loss: 2.409e-01,  loss_bc1: 5.761e-03,  loss_bc2: 3.861e-03, loss_ics_u: 1.156e-02, loss_ics_u_t: 5.401e-03, Loss_res: 2.911e-02 , Time: 50.16\n",
            "It: 17300, Loss: 1.677e-01,  loss_bc1: 5.604e-03,  loss_bc2: 3.803e-03, loss_ics_u: 6.655e-03, loss_ics_u_t: 7.191e-04, Loss_res: 7.112e-03 , Time: 49.90\n",
            "It: 17400, Loss: 1.660e-01,  loss_bc1: 5.588e-03,  loss_bc2: 3.810e-03, loss_ics_u: 6.512e-03, loss_ics_u_t: 7.049e-04, Loss_res: 6.929e-03 , Time: 50.20\n",
            "It: 17500, Loss: 1.647e-01,  loss_bc1: 5.573e-03,  loss_bc2: 3.724e-03, loss_ics_u: 6.479e-03, loss_ics_u_t: 7.009e-04, Loss_res: 6.980e-03 , Time: 50.06\n",
            "It: 17600, Loss: 1.637e-01,  loss_bc1: 5.549e-03,  loss_bc2: 3.761e-03, loss_ics_u: 6.345e-03, loss_ics_u_t: 7.225e-04, Loss_res: 7.135e-03 , Time: 50.16\n",
            "It: 17700, Loss: 1.617e-01,  loss_bc1: 5.536e-03,  loss_bc2: 3.656e-03, loss_ics_u: 6.259e-03, loss_ics_u_t: 6.798e-04, Loss_res: 7.141e-03 , Time: 49.98\n",
            "It: 17800, Loss: 1.605e-01,  loss_bc1: 5.529e-03,  loss_bc2: 3.687e-03, loss_ics_u: 6.090e-03, loss_ics_u_t: 6.655e-04, Loss_res: 7.423e-03 , Time: 50.39\n",
            "It: 17900, Loss: 1.580e-01,  loss_bc1: 5.493e-03,  loss_bc2: 3.594e-03, loss_ics_u: 5.998e-03, loss_ics_u_t: 6.196e-04, Loss_res: 7.093e-03 , Time: 40.92\n",
            "It: 18000, Loss: 1.574e-01,  loss_bc1: 5.464e-03,  loss_bc2: 3.605e-03, loss_ics_u: 5.928e-03, loss_ics_u_t: 6.397e-04, Loss_res: 7.426e-03 , Time: 35.10\n",
            "loss_bc1: 5.464e+00\n",
            "loss_bc2: 3.605e+00\n",
            "loss_ics_u: 5.928e+00\n",
            "lam_r_val: 7.426e+00\n",
            "It: 18100, Loss: 1.558e-01,  loss_bc1: 5.484e-03,  loss_bc2: 3.491e-03, loss_ics_u: 5.896e-03, loss_ics_u_t: 6.351e-04, Loss_res: 7.074e-03 , Time: 34.86\n",
            "It: 18200, Loss: 1.960e-01,  loss_bc1: 5.470e-03,  loss_bc2: 3.629e-03, loss_ics_u: 6.417e-03, loss_ics_u_t: 1.319e-03, Loss_res: 4.088e-02 , Time: 35.12\n",
            "It: 18300, Loss: 1.515e-01,  loss_bc1: 5.409e-03,  loss_bc2: 3.469e-03, loss_ics_u: 5.578e-03, loss_ics_u_t: 5.848e-04, Loss_res: 6.899e-03 , Time: 34.42\n",
            "It: 18400, Loss: 1.496e-01,  loss_bc1: 5.392e-03,  loss_bc2: 3.391e-03, loss_ics_u: 5.522e-03, loss_ics_u_t: 5.475e-04, Loss_res: 6.577e-03 , Time: 34.84\n",
            "It: 18500, Loss: 1.492e-01,  loss_bc1: 5.352e-03,  loss_bc2: 3.430e-03, loss_ics_u: 5.440e-03, loss_ics_u_t: 5.765e-04, Loss_res: 6.984e-03 , Time: 36.05\n",
            "It: 18600, Loss: 1.469e-01,  loss_bc1: 5.346e-03,  loss_bc2: 3.314e-03, loss_ics_u: 5.367e-03, loss_ics_u_t: 5.212e-04, Loss_res: 6.608e-03 , Time: 38.99\n",
            "It: 18700, Loss: 1.948e-01,  loss_bc1: 5.430e-03,  loss_bc2: 3.422e-03, loss_ics_u: 7.257e-03, loss_ics_u_t: 2.541e-03, Loss_res: 3.371e-02 , Time: 38.32\n",
            "It: 18800, Loss: 2.438e-01,  loss_bc1: 5.454e-03,  loss_bc2: 3.320e-03, loss_ics_u: 1.102e-02, loss_ics_u_t: 6.370e-03, Loss_res: 4.591e-02 , Time: 40.31\n",
            "It: 18900, Loss: 1.980e-01,  loss_bc1: 5.367e-03,  loss_bc2: 3.374e-03, loss_ics_u: 6.615e-03, loss_ics_u_t: 2.087e-03, Loss_res: 4.439e-02 , Time: 39.94\n",
            "It: 19000, Loss: 1.647e-01,  loss_bc1: 5.330e-03,  loss_bc2: 3.174e-03, loss_ics_u: 6.433e-03, loss_ics_u_t: 1.944e-03, Loss_res: 1.534e-02 , Time: 39.14\n",
            "loss_bc1: 5.330e+00\n",
            "loss_bc2: 3.174e+00\n",
            "loss_ics_u: 6.433e+00\n",
            "lam_r_val: 1.534e+01\n",
            "It: 19100, Loss: 1.456e-01,  loss_bc1: 5.335e-03,  loss_bc2: 3.245e-03, loss_ics_u: 5.109e-03, loss_ics_u_t: 7.455e-04, Loss_res: 8.761e-03 , Time: 38.14\n",
            "It: 19200, Loss: 1.401e-01,  loss_bc1: 5.234e-03,  loss_bc2: 3.100e-03, loss_ics_u: 4.825e-03, loss_ics_u_t: 4.697e-04, Loss_res: 8.514e-03 , Time: 37.68\n",
            "It: 19300, Loss: 1.714e-01,  loss_bc1: 5.242e-03,  loss_bc2: 3.175e-03, loss_ics_u: 6.244e-03, loss_ics_u_t: 1.973e-03, Loss_res: 2.482e-02 , Time: 37.88\n",
            "It: 19400, Loss: 1.556e-01,  loss_bc1: 5.215e-03,  loss_bc2: 3.038e-03, loss_ics_u: 5.940e-03, loss_ics_u_t: 1.737e-03, Loss_res: 1.369e-02 , Time: 37.79\n",
            "It: 19500, Loss: 1.469e-01,  loss_bc1: 5.090e-03,  loss_bc2: 3.111e-03, loss_ics_u: 4.721e-03, loss_ics_u_t: 5.199e-04, Loss_res: 1.772e-02 , Time: 37.68\n",
            "It: 19600, Loss: 1.702e-01,  loss_bc1: 5.144e-03,  loss_bc2: 3.030e-03, loss_ics_u: 6.411e-03, loss_ics_u_t: 2.305e-03, Loss_res: 2.433e-02 , Time: 39.07\n",
            "It: 19700, Loss: 1.303e-01,  loss_bc1: 5.068e-03,  loss_bc2: 2.941e-03, loss_ics_u: 4.414e-03, loss_ics_u_t: 4.207e-04, Loss_res: 6.087e-03 , Time: 37.48\n",
            "It: 19800, Loss: 1.293e-01,  loss_bc1: 5.043e-03,  loss_bc2: 2.942e-03, loss_ics_u: 4.341e-03, loss_ics_u_t: 4.246e-04, Loss_res: 6.022e-03 , Time: 37.38\n",
            "It: 19900, Loss: 1.280e-01,  loss_bc1: 5.006e-03,  loss_bc2: 2.882e-03, loss_ics_u: 4.298e-03, loss_ics_u_t: 4.212e-04, Loss_res: 6.130e-03 , Time: 45.33\n",
            "It: 20000, Loss: 1.270e-01,  loss_bc1: 4.964e-03,  loss_bc2: 2.895e-03, loss_ics_u: 4.208e-03, loss_ics_u_t: 4.146e-04, Loss_res: 6.367e-03 , Time: 53.66\n",
            "loss_bc1: 4.964e+00\n",
            "loss_bc2: 2.895e+00\n",
            "loss_ics_u: 4.208e+00\n",
            "lam_r_val: 6.367e+00\n",
            "It: 20100, Loss: 1.301e-01,  loss_bc1: 4.961e-03,  loss_bc2: 2.813e-03, loss_ics_u: 4.507e-03, loss_ics_u_t: 7.075e-04, Loss_res: 7.266e-03 , Time: 54.09\n",
            "It: 20200, Loss: 1.289e-01,  loss_bc1: 4.893e-03,  loss_bc2: 2.873e-03, loss_ics_u: 4.106e-03, loss_ics_u_t: 4.291e-04, Loss_res: 1.016e-02 , Time: 53.92\n",
            "It: 20300, Loss: 1.873e-01,  loss_bc1: 4.933e-03,  loss_bc2: 2.836e-03, loss_ics_u: 5.702e-03, loss_ics_u_t: 2.055e-03, Loss_res: 5.258e-02 , Time: 53.83\n",
            "It: 20400, Loss: 1.210e-01,  loss_bc1: 4.818e-03,  loss_bc2: 2.762e-03, loss_ics_u: 3.939e-03, loss_ics_u_t: 3.913e-04, Loss_res: 5.767e-03 , Time: 53.52\n",
            "It: 20500, Loss: 1.202e-01,  loss_bc1: 4.755e-03,  loss_bc2: 2.762e-03, loss_ics_u: 3.917e-03, loss_ics_u_t: 4.185e-04, Loss_res: 5.828e-03 , Time: 54.16\n",
            "It: 20600, Loss: 1.184e-01,  loss_bc1: 4.734e-03,  loss_bc2: 2.707e-03, loss_ics_u: 3.832e-03, loss_ics_u_t: 3.822e-04, Loss_res: 5.686e-03 , Time: 54.39\n",
            "It: 20700, Loss: 1.179e-01,  loss_bc1: 4.686e-03,  loss_bc2: 2.715e-03, loss_ics_u: 3.809e-03, loss_ics_u_t: 4.265e-04, Loss_res: 5.797e-03 , Time: 53.47\n",
            "It: 20800, Loss: 1.179e-01,  loss_bc1: 4.654e-03,  loss_bc2: 2.646e-03, loss_ics_u: 3.832e-03, loss_ics_u_t: 4.642e-04, Loss_res: 6.567e-03 , Time: 54.08\n",
            "It: 20900, Loss: 1.157e-01,  loss_bc1: 4.585e-03,  loss_bc2: 2.674e-03, loss_ics_u: 3.652e-03, loss_ics_u_t: 3.763e-04, Loss_res: 6.589e-03 , Time: 54.16\n",
            "It: 21000, Loss: 1.137e-01,  loss_bc1: 4.560e-03,  loss_bc2: 2.612e-03, loss_ics_u: 3.631e-03, loss_ics_u_t: 3.856e-04, Loss_res: 5.668e-03 , Time: 54.64\n",
            "loss_bc1: 4.560e+00\n",
            "loss_bc2: 2.612e+00\n",
            "loss_ics_u: 3.631e+00\n",
            "lam_r_val: 5.668e+00\n",
            "It: 21100, Loss: 1.243e-01,  loss_bc1: 4.512e-03,  loss_bc2: 2.649e-03, loss_ics_u: 3.678e-03, loss_ics_u_t: 5.189e-04, Loss_res: 1.594e-02 , Time: 55.16\n",
            "It: 21200, Loss: 1.120e-01,  loss_bc1: 4.471e-03,  loss_bc2: 2.572e-03, loss_ics_u: 3.554e-03, loss_ics_u_t: 4.067e-04, Loss_res: 5.994e-03 , Time: 54.79\n",
            "It: 21300, Loss: 1.741e-01,  loss_bc1: 4.561e-03,  loss_bc2: 2.730e-03, loss_ics_u: 7.592e-03, loss_ics_u_t: 4.525e-03, Loss_res: 2.528e-02 , Time: 53.95\n",
            "It: 21400, Loss: 1.169e-01,  loss_bc1: 4.377e-03,  loss_bc2: 2.547e-03, loss_ics_u: 3.804e-03, loss_ics_u_t: 8.050e-04, Loss_res: 9.664e-03 , Time: 55.39\n",
            "It: 21500, Loss: 1.123e-01,  loss_bc1: 4.331e-03,  loss_bc2: 2.499e-03, loss_ics_u: 3.357e-03, loss_ics_u_t: 3.812e-04, Loss_res: 1.044e-02 , Time: 54.65\n",
            "It: 21600, Loss: 1.285e-01,  loss_bc1: 4.284e-03,  loss_bc2: 2.506e-03, loss_ics_u: 3.612e-03, loss_ics_u_t: 7.058e-04, Loss_res: 2.444e-02 , Time: 52.90\n",
            "It: 21700, Loss: 1.050e-01,  loss_bc1: 4.237e-03,  loss_bc2: 2.481e-03, loss_ics_u: 3.228e-03, loss_ics_u_t: 3.622e-04, Loss_res: 5.504e-03 , Time: 53.45\n",
            "It: 21800, Loss: 1.047e-01,  loss_bc1: 4.166e-03,  loss_bc2: 2.483e-03, loss_ics_u: 3.258e-03, loss_ics_u_t: 4.129e-04, Loss_res: 5.660e-03 , Time: 54.28\n",
            "It: 21900, Loss: 1.031e-01,  loss_bc1: 4.143e-03,  loss_bc2: 2.444e-03, loss_ics_u: 3.159e-03, loss_ics_u_t: 3.656e-04, Loss_res: 5.644e-03 , Time: 50.05\n",
            "It: 22000, Loss: 1.210e-01,  loss_bc1: 4.109e-03,  loss_bc2: 2.455e-03, loss_ics_u: 3.735e-03, loss_ics_u_t: 9.826e-04, Loss_res: 1.799e-02 , Time: 47.06\n",
            "loss_bc1: 4.109e+00\n",
            "loss_bc2: 2.455e+00\n",
            "loss_ics_u: 3.735e+00\n",
            "lam_r_val: 1.799e+01\n",
            "It: 22100, Loss: 1.005e-01,  loss_bc1: 4.049e-03,  loss_bc2: 2.408e-03, loss_ics_u: 3.044e-03, loss_ics_u_t: 3.626e-04, Loss_res: 5.537e-03 , Time: 51.88\n",
            "It: 22200, Loss: 9.980e-02,  loss_bc1: 4.016e-03,  loss_bc2: 2.363e-03, loss_ics_u: 3.029e-03, loss_ics_u_t: 3.638e-04, Loss_res: 5.720e-03 , Time: 52.34\n",
            "It: 22300, Loss: 9.844e-02,  loss_bc1: 3.954e-03,  loss_bc2: 2.372e-03, loss_ics_u: 2.959e-03, loss_ics_u_t: 3.580e-04, Loss_res: 5.596e-03 , Time: 54.40\n",
            "It: 22400, Loss: 9.752e-02,  loss_bc1: 3.912e-03,  loss_bc2: 2.358e-03, loss_ics_u: 2.920e-03, loss_ics_u_t: 3.594e-04, Loss_res: 5.627e-03 , Time: 53.39\n",
            "It: 22500, Loss: 9.640e-02,  loss_bc1: 3.861e-03,  loss_bc2: 2.325e-03, loss_ics_u: 2.890e-03, loss_ics_u_t: 3.589e-04, Loss_res: 5.638e-03 , Time: 50.32\n",
            "It: 22600, Loss: 9.531e-02,  loss_bc1: 3.819e-03,  loss_bc2: 2.321e-03, loss_ics_u: 2.839e-03, loss_ics_u_t: 3.629e-04, Loss_res: 5.519e-03 , Time: 47.92\n",
            "It: 22700, Loss: 9.437e-02,  loss_bc1: 3.779e-03,  loss_bc2: 2.283e-03, loss_ics_u: 2.806e-03, loss_ics_u_t: 3.574e-04, Loss_res: 5.699e-03 , Time: 46.87\n",
            "It: 22800, Loss: 1.011e-01,  loss_bc1: 3.738e-03,  loss_bc2: 2.286e-03, loss_ics_u: 3.134e-03, loss_ics_u_t: 7.418e-04, Loss_res: 9.547e-03 , Time: 46.75\n",
            "It: 22900, Loss: 1.550e-01,  loss_bc1: 3.703e-03,  loss_bc2: 2.259e-03, loss_ics_u: 3.118e-03, loss_ics_u_t: 7.545e-04, Loss_res: 6.422e-02 , Time: 46.88\n",
            "It: 23000, Loss: 1.222e-01,  loss_bc1: 3.661e-03,  loss_bc2: 2.242e-03, loss_ics_u: 4.571e-03, loss_ics_u_t: 2.236e-03, Loss_res: 1.751e-02 , Time: 46.80\n",
            "loss_bc1: 3.661e+00\n",
            "loss_bc2: 2.242e+00\n",
            "loss_ics_u: 4.571e+00\n",
            "lam_r_val: 1.751e+01\n",
            "It: 23100, Loss: 9.378e-02,  loss_bc1: 3.559e-03,  loss_bc2: 2.272e-03, loss_ics_u: 2.761e-03, loss_ics_u_t: 4.740e-04, Loss_res: 7.867e-03 , Time: 47.53\n",
            "It: 23200, Loss: 1.271e-01,  loss_bc1: 3.562e-03,  loss_bc2: 2.223e-03, loss_ics_u: 4.422e-03, loss_ics_u_t: 2.148e-03, Loss_res: 2.500e-02 , Time: 47.54\n",
            "It: 23300, Loss: 8.820e-02,  loss_bc1: 3.506e-03,  loss_bc2: 2.175e-03, loss_ics_u: 2.578e-03, loss_ics_u_t: 3.543e-04, Loss_res: 5.621e-03 , Time: 50.32\n",
            "It: 23400, Loss: 8.704e-02,  loss_bc1: 3.441e-03,  loss_bc2: 2.183e-03, loss_ics_u: 2.533e-03, loss_ics_u_t: 3.542e-04, Loss_res: 5.476e-03 , Time: 52.33\n",
            "It: 23500, Loss: 8.666e-02,  loss_bc1: 3.422e-03,  loss_bc2: 2.140e-03, loss_ics_u: 2.555e-03, loss_ics_u_t: 3.881e-04, Loss_res: 5.489e-03 , Time: 52.06\n",
            "It: 23600, Loss: 9.705e-02,  loss_bc1: 3.339e-03,  loss_bc2: 2.204e-03, loss_ics_u: 2.660e-03, loss_ics_u_t: 5.389e-04, Loss_res: 1.502e-02 , Time: 52.36\n",
            "It: 23700, Loss: 8.412e-02,  loss_bc1: 3.306e-03,  loss_bc2: 2.131e-03, loss_ics_u: 2.429e-03, loss_ics_u_t: 3.541e-04, Loss_res: 5.463e-03 , Time: 52.42\n",
            "It: 23800, Loss: 8.335e-02,  loss_bc1: 3.281e-03,  loss_bc2: 2.085e-03, loss_ics_u: 2.423e-03, loss_ics_u_t: 3.530e-04, Loss_res: 5.459e-03 , Time: 52.11\n",
            "It: 23900, Loss: 8.370e-02,  loss_bc1: 3.227e-03,  loss_bc2: 2.112e-03, loss_ics_u: 2.441e-03, loss_ics_u_t: 4.194e-04, Loss_res: 5.893e-03 , Time: 51.68\n",
            "It: 24000, Loss: 8.126e-02,  loss_bc1: 3.174e-03,  loss_bc2: 2.077e-03, loss_ics_u: 2.335e-03, loss_ics_u_t: 3.529e-04, Loss_res: 5.398e-03 , Time: 51.36\n",
            "loss_bc1: 3.174e+00\n",
            "loss_bc2: 2.077e+00\n",
            "loss_ics_u: 2.335e+00\n",
            "lam_r_val: 5.398e+00\n",
            "It: 24100, Loss: 8.068e-02,  loss_bc1: 3.144e-03,  loss_bc2: 2.059e-03, loss_ics_u: 2.325e-03, loss_ics_u_t: 3.527e-04, Loss_res: 5.405e-03 , Time: 51.35\n",
            "It: 24200, Loss: 7.953e-02,  loss_bc1: 3.098e-03,  loss_bc2: 2.042e-03, loss_ics_u: 2.279e-03, loss_ics_u_t: 3.519e-04, Loss_res: 5.342e-03 , Time: 51.30\n",
            "It: 24300, Loss: 7.883e-02,  loss_bc1: 3.034e-03,  loss_bc2: 2.036e-03, loss_ics_u: 2.269e-03, loss_ics_u_t: 3.561e-04, Loss_res: 5.435e-03 , Time: 51.78\n",
            "It: 24400, Loss: 7.868e-02,  loss_bc1: 3.010e-03,  loss_bc2: 2.011e-03, loss_ics_u: 2.291e-03, loss_ics_u_t: 4.076e-04, Loss_res: 5.560e-03 , Time: 52.18\n",
            "It: 24500, Loss: 7.678e-02,  loss_bc1: 2.968e-03,  loss_bc2: 1.987e-03, loss_ics_u: 2.192e-03, loss_ics_u_t: 3.516e-04, Loss_res: 5.309e-03 , Time: 52.14\n",
            "It: 24600, Loss: 7.598e-02,  loss_bc1: 2.932e-03,  loss_bc2: 1.971e-03, loss_ics_u: 2.172e-03, loss_ics_u_t: 3.501e-04, Loss_res: 5.244e-03 , Time: 51.65\n",
            "It: 24700, Loss: 9.194e-02,  loss_bc1: 2.896e-03,  loss_bc2: 1.986e-03, loss_ics_u: 2.981e-03, loss_ics_u_t: 1.177e-03, Loss_res: 1.331e-02 , Time: 52.76\n",
            "It: 24800, Loss: 8.643e-02,  loss_bc1: 2.851e-03,  loss_bc2: 1.984e-03, loss_ics_u: 2.576e-03, loss_ics_u_t: 8.081e-04, Loss_res: 1.232e-02 , Time: 54.65\n",
            "It: 24900, Loss: 7.318e-02,  loss_bc1: 2.802e-03,  loss_bc2: 1.915e-03, loss_ics_u: 2.080e-03, loss_ics_u_t: 3.491e-04, Loss_res: 5.203e-03 , Time: 52.10\n",
            "It: 25000, Loss: 7.244e-02,  loss_bc1: 2.766e-03,  loss_bc2: 1.902e-03, loss_ics_u: 2.060e-03, loss_ics_u_t: 3.487e-04, Loss_res: 5.160e-03 , Time: 51.91\n",
            "loss_bc1: 2.766e+00\n",
            "loss_bc2: 1.902e+00\n",
            "loss_ics_u: 2.060e+00\n",
            "lam_r_val: 5.160e+00\n",
            "It: 25100, Loss: 1.951e-01,  loss_bc1: 2.846e-03,  loss_bc2: 1.957e-03, loss_ics_u: 9.997e-03, loss_ics_u_t: 8.305e-03, Loss_res: 4.713e-02 , Time: 52.39\n",
            "It: 25200, Loss: 7.121e-02,  loss_bc1: 2.668e-03,  loss_bc2: 1.869e-03, loss_ics_u: 2.007e-03, loss_ics_u_t: 3.478e-04, Loss_res: 5.775e-03 , Time: 53.60\n",
            "It: 25300, Loss: 6.977e-02,  loss_bc1: 2.642e-03,  loss_bc2: 1.848e-03, loss_ics_u: 1.978e-03, loss_ics_u_t: 3.461e-04, Loss_res: 5.087e-03 , Time: 54.38\n",
            "It: 25400, Loss: 2.001e-01,  loss_bc1: 2.741e-03,  loss_bc2: 1.920e-03, loss_ics_u: 6.600e-03, loss_ics_u_t: 4.994e-03, Loss_res: 8.752e-02 , Time: 54.48\n",
            "It: 25500, Loss: 6.807e-02,  loss_bc1: 2.567e-03,  loss_bc2: 1.807e-03, loss_ics_u: 1.930e-03, loss_ics_u_t: 3.443e-04, Loss_res: 5.035e-03 , Time: 57.00\n",
            "It: 25600, Loss: 7.741e-02,  loss_bc1: 2.547e-03,  loss_bc2: 1.856e-03, loss_ics_u: 2.414e-03, loss_ics_u_t: 8.613e-04, Loss_res: 9.247e-03 , Time: 54.65\n",
            "It: 25700, Loss: 7.797e-02,  loss_bc1: 2.480e-03,  loss_bc2: 1.784e-03, loss_ics_u: 2.068e-03, loss_ics_u_t: 5.415e-04, Loss_res: 1.466e-02 , Time: 55.87\n",
            "It: 25800, Loss: 6.558e-02,  loss_bc1: 2.450e-03,  loss_bc2: 1.757e-03, loss_ics_u: 1.855e-03, loss_ics_u_t: 3.418e-04, Loss_res: 4.959e-03 , Time: 56.74\n",
            "It: 25900, Loss: 6.990e-02,  loss_bc1: 2.403e-03,  loss_bc2: 1.774e-03, loss_ics_u: 2.084e-03, loss_ics_u_t: 5.965e-04, Loss_res: 7.294e-03 , Time: 55.49\n",
            "It: 26000, Loss: 6.814e-02,  loss_bc1: 2.376e-03,  loss_bc2: 1.737e-03, loss_ics_u: 2.045e-03, loss_ics_u_t: 5.737e-04, Loss_res: 6.553e-03 , Time: 52.77\n",
            "loss_bc1: 2.376e+00\n",
            "loss_bc2: 1.737e+00\n",
            "loss_ics_u: 2.045e+00\n",
            "lam_r_val: 6.553e+00\n",
            "It: 26100, Loss: 6.311e-02,  loss_bc1: 2.332e-03,  loss_bc2: 1.712e-03, loss_ics_u: 1.778e-03, loss_ics_u_t: 3.392e-04, Loss_res: 4.891e-03 , Time: 52.80\n",
            "It: 26200, Loss: 6.248e-02,  loss_bc1: 2.291e-03,  loss_bc2: 1.707e-03, loss_ics_u: 1.760e-03, loss_ics_u_t: 3.407e-04, Loss_res: 4.902e-03 , Time: 52.33\n",
            "It: 26300, Loss: 8.160e-02,  loss_bc1: 2.274e-03,  loss_bc2: 1.672e-03, loss_ics_u: 2.621e-03, loss_ics_u_t: 1.222e-03, Loss_res: 1.593e-02 , Time: 53.05\n",
            "It: 26400, Loss: 6.093e-02,  loss_bc1: 2.225e-03,  loss_bc2: 1.660e-03, loss_ics_u: 1.711e-03, loss_ics_u_t: 3.354e-04, Loss_res: 4.975e-03 , Time: 52.63\n",
            "It: 26500, Loss: 6.003e-02,  loss_bc1: 2.183e-03,  loss_bc2: 1.653e-03, loss_ics_u: 1.685e-03, loss_ics_u_t: 3.344e-04, Loss_res: 4.815e-03 , Time: 52.49\n",
            "It: 26600, Loss: 5.927e-02,  loss_bc1: 2.153e-03,  loss_bc2: 1.627e-03, loss_ics_u: 1.667e-03, loss_ics_u_t: 3.330e-04, Loss_res: 4.805e-03 , Time: 51.44\n",
            "It: 26700, Loss: 5.872e-02,  loss_bc1: 2.109e-03,  loss_bc2: 1.620e-03, loss_ics_u: 1.644e-03, loss_ics_u_t: 3.333e-04, Loss_res: 4.979e-03 , Time: 51.77\n",
            "It: 26800, Loss: 5.796e-02,  loss_bc1: 2.082e-03,  loss_bc2: 1.595e-03, loss_ics_u: 1.632e-03, loss_ics_u_t: 3.411e-04, Loss_res: 4.876e-03 , Time: 52.03\n",
            "It: 26900, Loss: 5.738e-02,  loss_bc1: 2.040e-03,  loss_bc2: 1.588e-03, loss_ics_u: 1.621e-03, loss_ics_u_t: 3.543e-04, Loss_res: 4.885e-03 , Time: 52.30\n",
            "It: 27000, Loss: 7.975e-02,  loss_bc1: 2.021e-03,  loss_bc2: 1.566e-03, loss_ics_u: 1.592e-03, loss_ics_u_t: 3.481e-04, Loss_res: 2.796e-02 , Time: 52.13\n",
            "loss_bc1: 2.021e+00\n",
            "loss_bc2: 1.566e+00\n",
            "loss_ics_u: 1.592e+00\n",
            "lam_r_val: 2.796e+01\n",
            "It: 27100, Loss: 5.938e-02,  loss_bc1: 1.975e-03,  loss_bc2: 1.544e-03, loss_ics_u: 1.691e-03, loss_ics_u_t: 4.654e-04, Loss_res: 7.286e-03 , Time: 52.09\n",
            "It: 27200, Loss: 5.509e-02,  loss_bc1: 1.939e-03,  loss_bc2: 1.533e-03, loss_ics_u: 1.533e-03, loss_ics_u_t: 3.263e-04, Loss_res: 5.030e-03 , Time: 51.50\n",
            "It: 27300, Loss: 5.449e-02,  loss_bc1: 1.909e-03,  loss_bc2: 1.507e-03, loss_ics_u: 1.514e-03, loss_ics_u_t: 3.261e-04, Loss_res: 5.192e-03 , Time: 52.67\n",
            "It: 27400, Loss: 7.616e-02,  loss_bc1: 1.869e-03,  loss_bc2: 1.496e-03, loss_ics_u: 1.728e-03, loss_ics_u_t: 5.515e-04, Loss_res: 2.524e-02 , Time: 51.30\n",
            "It: 27500, Loss: 5.391e-02,  loss_bc1: 1.842e-03,  loss_bc2: 1.486e-03, loss_ics_u: 1.535e-03, loss_ics_u_t: 3.889e-04, Loss_res: 5.275e-03 , Time: 51.96\n",
            "It: 27600, Loss: 5.232e-02,  loss_bc1: 1.812e-03,  loss_bc2: 1.457e-03, loss_ics_u: 1.472e-03, loss_ics_u_t: 3.409e-04, Loss_res: 4.901e-03 , Time: 52.63\n",
            "It: 27700, Loss: 5.113e-02,  loss_bc1: 1.776e-03,  loss_bc2: 1.447e-03, loss_ics_u: 1.427e-03, loss_ics_u_t: 3.178e-04, Loss_res: 4.621e-03 , Time: 52.05\n",
            "It: 27800, Loss: 5.053e-02,  loss_bc1: 1.748e-03,  loss_bc2: 1.424e-03, loss_ics_u: 1.412e-03, loss_ics_u_t: 3.188e-04, Loss_res: 4.691e-03 , Time: 51.85\n",
            "It: 27900, Loss: 5.143e-02,  loss_bc1: 1.716e-03,  loss_bc2: 1.418e-03, loss_ics_u: 1.498e-03, loss_ics_u_t: 4.251e-04, Loss_res: 5.114e-03 , Time: 52.00\n",
            "It: 28000, Loss: 9.244e-02,  loss_bc1: 1.701e-03,  loss_bc2: 1.401e-03, loss_ics_u: 1.569e-03, loss_ics_u_t: 5.185e-04, Loss_res: 4.573e-02 , Time: 51.71\n",
            "loss_bc1: 1.701e+00\n",
            "loss_bc2: 1.401e+00\n",
            "loss_ics_u: 1.569e+00\n",
            "lam_r_val: 4.573e+01\n",
            "It: 28100, Loss: 6.074e-02,  loss_bc1: 1.663e-03,  loss_bc2: 1.372e-03, loss_ics_u: 1.928e-03, loss_ics_u_t: 8.898e-04, Loss_res: 1.111e-02 , Time: 51.00\n",
            "It: 28200, Loss: 5.339e-02,  loss_bc1: 1.630e-03,  loss_bc2: 1.390e-03, loss_ics_u: 1.658e-03, loss_ics_u_t: 6.167e-04, Loss_res: 6.612e-03 , Time: 47.91\n",
            "It: 28300, Loss: 1.188e-01,  loss_bc1: 1.690e-03,  loss_bc2: 1.396e-03, loss_ics_u: 5.292e-03, loss_ics_u_t: 4.285e-03, Loss_res: 3.502e-02 , Time: 48.76\n",
            "It: 28400, Loss: 4.636e-02,  loss_bc1: 1.568e-03,  loss_bc2: 1.327e-03, loss_ics_u: 1.287e-03, loss_ics_u_t: 2.991e-04, Loss_res: 4.531e-03 , Time: 51.75\n",
            "It: 28500, Loss: 4.567e-02,  loss_bc1: 1.536e-03,  loss_bc2: 1.317e-03, loss_ics_u: 1.269e-03, loss_ics_u_t: 2.988e-04, Loss_res: 4.454e-03 , Time: 46.84\n",
            "It: 28600, Loss: 4.505e-02,  loss_bc1: 1.511e-03,  loss_bc2: 1.296e-03, loss_ics_u: 1.251e-03, loss_ics_u_t: 2.946e-04, Loss_res: 4.471e-03 , Time: 34.63\n",
            "It: 28700, Loss: 4.466e-02,  loss_bc1: 1.481e-03,  loss_bc2: 1.286e-03, loss_ics_u: 1.235e-03, loss_ics_u_t: 2.962e-04, Loss_res: 4.640e-03 , Time: 35.73\n",
            "It: 28800, Loss: 4.405e-02,  loss_bc1: 1.455e-03,  loss_bc2: 1.263e-03, loss_ics_u: 1.230e-03, loss_ics_u_t: 3.043e-04, Loss_res: 4.572e-03 , Time: 35.84\n",
            "It: 28900, Loss: 4.387e-02,  loss_bc1: 1.423e-03,  loss_bc2: 1.255e-03, loss_ics_u: 1.198e-03, loss_ics_u_t: 2.898e-04, Loss_res: 5.106e-03 , Time: 36.43\n",
            "It: 29000, Loss: 4.328e-02,  loss_bc1: 1.403e-03,  loss_bc2: 1.231e-03, loss_ics_u: 1.202e-03, loss_ics_u_t: 3.090e-04, Loss_res: 4.918e-03 , Time: 35.04\n",
            "loss_bc1: 1.403e+00\n",
            "loss_bc2: 1.231e+00\n",
            "loss_ics_u: 1.202e+00\n",
            "lam_r_val: 4.918e+00\n",
            "It: 29100, Loss: 4.204e-02,  loss_bc1: 1.373e-03,  loss_bc2: 1.218e-03, loss_ics_u: 1.165e-03, loss_ics_u_t: 2.861e-04, Loss_res: 4.479e-03 , Time: 35.03\n",
            "It: 29200, Loss: 4.147e-02,  loss_bc1: 1.349e-03,  loss_bc2: 1.199e-03, loss_ics_u: 1.148e-03, loss_ics_u_t: 2.843e-04, Loss_res: 4.505e-03 , Time: 35.85\n",
            "It: 29300, Loss: 4.088e-02,  loss_bc1: 1.320e-03,  loss_bc2: 1.188e-03, loss_ics_u: 1.132e-03, loss_ics_u_t: 2.832e-04, Loss_res: 4.486e-03 , Time: 34.82\n",
            "It: 29400, Loss: 4.015e-02,  loss_bc1: 1.298e-03,  loss_bc2: 1.167e-03, loss_ics_u: 1.111e-03, loss_ics_u_t: 2.755e-04, Loss_res: 4.391e-03 , Time: 34.71\n",
            "It: 29500, Loss: 3.960e-02,  loss_bc1: 1.270e-03,  loss_bc2: 1.157e-03, loss_ics_u: 1.094e-03, loss_ics_u_t: 2.729e-04, Loss_res: 4.389e-03 , Time: 33.64\n",
            "It: 29600, Loss: 3.965e-02,  loss_bc1: 1.249e-03,  loss_bc2: 1.140e-03, loss_ics_u: 1.108e-03, loss_ics_u_t: 2.975e-04, Loss_res: 4.688e-03 , Time: 33.23\n",
            "It: 29700, Loss: 4.088e-02,  loss_bc1: 1.222e-03,  loss_bc2: 1.128e-03, loss_ics_u: 1.200e-03, loss_ics_u_t: 4.046e-04, Loss_res: 5.382e-03 , Time: 33.10\n",
            "It: 29800, Loss: 4.695e-02,  loss_bc1: 1.196e-03,  loss_bc2: 1.104e-03, loss_ics_u: 1.059e-03, loss_ics_u_t: 2.731e-04, Loss_res: 1.336e-02 , Time: 33.73\n",
            "It: 29900, Loss: 4.489e-02,  loss_bc1: 1.169e-03,  loss_bc2: 1.101e-03, loss_ics_u: 1.084e-03, loss_ics_u_t: 3.126e-04, Loss_res: 1.134e-02 , Time: 33.76\n",
            "It: 30000, Loss: 6.903e-02,  loss_bc1: 1.152e-03,  loss_bc2: 1.081e-03, loss_ics_u: 1.490e-03, loss_ics_u_t: 7.284e-04, Loss_res: 3.180e-02 , Time: 33.22\n",
            "loss_bc1: 1.152e+00\n",
            "loss_bc2: 1.081e+00\n",
            "loss_ics_u: 1.490e+00\n",
            "lam_r_val: 3.180e+01\n",
            "It: 30100, Loss: 3.644e-02,  loss_bc1: 1.129e-03,  loss_bc2: 1.058e-03, loss_ics_u: 1.002e-03, loss_ics_u_t: 2.578e-04, Loss_res: 4.547e-03 , Time: 33.23\n",
            "It: 30200, Loss: 3.612e-02,  loss_bc1: 1.105e-03,  loss_bc2: 1.046e-03, loss_ics_u: 1.011e-03, loss_ics_u_t: 2.798e-04, Loss_res: 4.492e-03 , Time: 36.79\n",
            "It: 30300, Loss: 3.657e-02,  loss_bc1: 1.086e-03,  loss_bc2: 1.029e-03, loss_ics_u: 9.734e-04, loss_ics_u_t: 2.539e-04, Loss_res: 5.689e-03 , Time: 37.06\n",
            "It: 30400, Loss: 3.498e-02,  loss_bc1: 1.062e-03,  loss_bc2: 1.014e-03, loss_ics_u: 9.703e-04, loss_ics_u_t: 2.629e-04, Loss_res: 4.513e-03 , Time: 35.07\n",
            "It: 30500, Loss: 4.488e-02,  loss_bc1: 1.045e-03,  loss_bc2: 9.997e-04, loss_ics_u: 9.495e-04, loss_ics_u_t: 2.521e-04, Loss_res: 1.494e-02 , Time: 35.32\n",
            "It: 30600, Loss: 3.754e-02,  loss_bc1: 1.025e-03,  loss_bc2: 9.858e-04, loss_ics_u: 1.155e-03, loss_ics_u_t: 4.706e-04, Loss_res: 5.876e-03 , Time: 34.42\n",
            "It: 30700, Loss: 3.738e-02,  loss_bc1: 9.999e-04,  loss_bc2: 9.679e-04, loss_ics_u: 9.187e-04, loss_ics_u_t: 2.438e-04, Loss_res: 8.517e-03 , Time: 34.48\n",
            "It: 30800, Loss: 3.597e-02,  loss_bc1: 9.785e-04,  loss_bc2: 9.590e-04, loss_ics_u: 1.076e-03, loss_ics_u_t: 4.115e-04, Loss_res: 5.837e-03 , Time: 34.37\n",
            "It: 30900, Loss: 3.220e-02,  loss_bc1: 9.560e-04,  loss_bc2: 9.358e-04, loss_ics_u: 8.911e-04, loss_ics_u_t: 2.375e-04, Loss_res: 4.370e-03 , Time: 33.79\n",
            "It: 31000, Loss: 3.174e-02,  loss_bc1: 9.338e-04,  loss_bc2: 9.250e-04, loss_ics_u: 8.775e-04, loss_ics_u_t: 2.352e-04, Loss_res: 4.375e-03 , Time: 33.44\n",
            "loss_bc1: 9.338e-01\n",
            "loss_bc2: 9.250e-01\n",
            "loss_ics_u: 8.775e-01\n",
            "lam_r_val: 4.375e+00\n",
            "It: 31100, Loss: 3.136e-02,  loss_bc1: 9.155e-04,  loss_bc2: 9.084e-04, loss_ics_u: 8.723e-04, loss_ics_u_t: 2.393e-04, Loss_res: 4.397e-03 , Time: 33.49\n",
            "It: 31200, Loss: 3.093e-02,  loss_bc1: 8.942e-04,  loss_bc2: 8.953e-04, loss_ics_u: 8.532e-04, loss_ics_u_t: 2.307e-04, Loss_res: 4.500e-03 , Time: 33.69\n",
            "It: 31300, Loss: 3.104e-02,  loss_bc1: 8.782e-04,  loss_bc2: 8.782e-04, loss_ics_u: 8.546e-04, loss_ics_u_t: 2.421e-04, Loss_res: 4.935e-03 , Time: 33.50\n",
            "It: 31400, Loss: 3.079e-02,  loss_bc1: 8.561e-04,  loss_bc2: 8.680e-04, loss_ics_u: 8.822e-04, loss_ics_u_t: 2.784e-04, Loss_res: 4.725e-03 , Time: 34.06\n",
            "It: 31500, Loss: 7.846e-02,  loss_bc1: 8.752e-04,  loss_bc2: 8.708e-04, loss_ics_u: 2.102e-03, loss_ics_u_t: 1.510e-03, Loss_res: 3.998e-02 , Time: 34.12\n",
            "It: 31600, Loss: 2.897e-02,  loss_bc1: 8.216e-04,  loss_bc2: 8.347e-04, loss_ics_u: 8.051e-04, loss_ics_u_t: 2.207e-04, Loss_res: 4.352e-03 , Time: 37.16\n",
            "It: 31700, Loss: 2.855e-02,  loss_bc1: 8.014e-04,  loss_bc2: 8.239e-04, loss_ics_u: 7.939e-04, loss_ics_u_t: 2.187e-04, Loss_res: 4.357e-03 , Time: 34.92\n",
            "It: 31800, Loss: 2.832e-02,  loss_bc1: 7.879e-04,  loss_bc2: 8.060e-04, loss_ics_u: 7.870e-04, loss_ics_u_t: 2.194e-04, Loss_res: 4.507e-03 , Time: 35.62\n",
            "It: 31900, Loss: 5.928e-02,  loss_bc1: 7.739e-04,  loss_bc2: 7.979e-04, loss_ics_u: 7.906e-04, loss_ics_u_t: 2.322e-04, Loss_res: 3.566e-02 , Time: 35.58\n",
            "It: 32000, Loss: 2.729e-02,  loss_bc1: 7.516e-04,  loss_bc2: 7.819e-04, loss_ics_u: 7.621e-04, loss_ics_u_t: 2.122e-04, Loss_res: 4.334e-03 , Time: 40.85\n",
            "loss_bc1: 7.516e-01\n",
            "loss_bc2: 7.819e-01\n",
            "loss_ics_u: 7.621e-01\n",
            "lam_r_val: 4.334e+00\n",
            "It: 32100, Loss: 2.732e-02,  loss_bc1: 7.363e-04,  loss_bc2: 7.681e-04, loss_ics_u: 7.675e-04, loss_ics_u_t: 2.260e-04, Loss_res: 4.602e-03 , Time: 48.30\n",
            "It: 32200, Loss: 2.649e-02,  loss_bc1: 7.206e-04,  loss_bc2: 7.531e-04, loss_ics_u: 7.416e-04, loss_ics_u_t: 2.079e-04, Loss_res: 4.336e-03 , Time: 40.41\n",
            "It: 32300, Loss: 2.611e-02,  loss_bc1: 7.036e-04,  loss_bc2: 7.431e-04, loss_ics_u: 7.311e-04, loss_ics_u_t: 2.060e-04, Loss_res: 4.327e-03 , Time: 49.90\n",
            "It: 32400, Loss: 2.574e-02,  loss_bc1: 6.899e-04,  loss_bc2: 7.282e-04, loss_ics_u: 7.237e-04, loss_ics_u_t: 2.054e-04, Loss_res: 4.327e-03 , Time: 52.46\n",
            "It: 32500, Loss: 2.605e-02,  loss_bc1: 6.729e-04,  loss_bc2: 7.183e-04, loss_ics_u: 7.464e-04, loss_ics_u_t: 2.366e-04, Loss_res: 4.673e-03 , Time: 53.21\n",
            "It: 32600, Loss: 3.124e-02,  loss_bc1: 6.642e-04,  loss_bc2: 7.103e-04, loss_ics_u: 9.956e-04, loss_ics_u_t: 4.913e-04, Loss_res: 7.536e-03 , Time: 52.74\n",
            "It: 32700, Loss: 2.460e-02,  loss_bc1: 6.469e-04,  loss_bc2: 6.890e-04, loss_ics_u: 6.937e-04, loss_ics_u_t: 1.980e-04, Loss_res: 4.308e-03 , Time: 51.77\n",
            "It: 32800, Loss: 2.427e-02,  loss_bc1: 6.308e-04,  loss_bc2: 6.789e-04, loss_ics_u: 6.844e-04, loss_ics_u_t: 1.963e-04, Loss_res: 4.326e-03 , Time: 51.40\n",
            "It: 32900, Loss: 2.844e-02,  loss_bc1: 6.176e-04,  loss_bc2: 6.681e-04, loss_ics_u: 8.781e-04, loss_ics_u_t: 3.991e-04, Loss_res: 6.800e-03 , Time: 53.57\n",
            "It: 33000, Loss: 2.354e-02,  loss_bc1: 6.053e-04,  loss_bc2: 6.532e-04, loss_ics_u: 6.666e-04, loss_ics_u_t: 1.923e-04, Loss_res: 4.287e-03 , Time: 54.60\n",
            "loss_bc1: 6.053e-01\n",
            "loss_bc2: 6.532e-01\n",
            "loss_ics_u: 6.666e-01\n",
            "lam_r_val: 4.287e+00\n",
            "It: 33100, Loss: 2.349e-02,  loss_bc1: 5.906e-04,  loss_bc2: 6.446e-04, loss_ics_u: 6.679e-04, loss_ics_u_t: 2.004e-04, Loss_res: 4.456e-03 , Time: 54.02\n",
            "It: 33200, Loss: 2.362e-02,  loss_bc1: 5.795e-04,  loss_bc2: 6.313e-04, loss_ics_u: 6.536e-04, loss_ics_u_t: 1.918e-04, Loss_res: 4.979e-03 , Time: 53.57\n",
            "It: 33300, Loss: 2.369e-02,  loss_bc1: 5.661e-04,  loss_bc2: 6.206e-04, loss_ics_u: 7.007e-04, loss_ics_u_t: 2.472e-04, Loss_res: 4.813e-03 , Time: 53.49\n",
            "It: 33400, Loss: 3.373e-02,  loss_bc1: 5.653e-04,  loss_bc2: 6.159e-04, loss_ics_u: 1.092e-03, loss_ics_u_t: 6.409e-04, Loss_res: 1.100e-02 , Time: 53.17\n",
            "It: 33500, Loss: 2.389e-02,  loss_bc1: 5.419e-04,  loss_bc2: 5.951e-04, loss_ics_u: 6.265e-04, loss_ics_u_t: 1.851e-04, Loss_res: 6.257e-03 , Time: 53.34\n",
            "It: 33600, Loss: 2.157e-02,  loss_bc1: 5.301e-04,  loss_bc2: 5.859e-04, loss_ics_u: 6.169e-04, loss_ics_u_t: 1.821e-04, Loss_res: 4.243e-03 , Time: 53.52\n",
            "It: 33700, Loss: 2.130e-02,  loss_bc1: 5.187e-04,  loss_bc2: 5.750e-04, loss_ics_u: 6.103e-04, loss_ics_u_t: 1.810e-04, Loss_res: 4.261e-03 , Time: 53.16\n",
            "It: 33800, Loss: 2.181e-02,  loss_bc1: 5.084e-04,  loss_bc2: 5.696e-04, loss_ics_u: 6.244e-04, loss_ics_u_t: 2.005e-04, Loss_res: 4.788e-03 , Time: 53.20\n",
            "It: 33900, Loss: 2.153e-02,  loss_bc1: 4.976e-04,  loss_bc2: 5.530e-04, loss_ics_u: 6.135e-04, loss_ics_u_t: 1.972e-04, Loss_res: 4.890e-03 , Time: 53.25\n",
            "It: 34000, Loss: 2.280e-02,  loss_bc1: 4.906e-04,  loss_bc2: 5.458e-04, loss_ics_u: 6.687e-04, loss_ics_u_t: 2.575e-04, Loss_res: 5.746e-03 , Time: 53.64\n",
            "loss_bc1: 4.906e-01\n",
            "loss_bc2: 5.458e-01\n",
            "loss_ics_u: 6.687e-01\n",
            "lam_r_val: 5.746e+00\n",
            "It: 34100, Loss: 2.007e-02,  loss_bc1: 4.765e-04,  loss_bc2: 5.327e-04, loss_ics_u: 5.793e-04, loss_ics_u_t: 1.738e-04, Loss_res: 4.187e-03 , Time: 53.38\n",
            "It: 34200, Loss: 1.981e-02,  loss_bc1: 4.623e-04,  loss_bc2: 5.265e-04, loss_ics_u: 5.742e-04, loss_ics_u_t: 1.732e-04, Loss_res: 4.183e-03 , Time: 52.98\n",
            "It: 34300, Loss: 1.953e-02,  loss_bc1: 4.552e-04,  loss_bc2: 5.150e-04, loss_ics_u: 5.665e-04, loss_ics_u_t: 1.711e-04, Loss_res: 4.167e-03 , Time: 53.53\n",
            "It: 34400, Loss: 3.376e-02,  loss_bc1: 4.511e-04,  loss_bc2: 5.121e-04, loss_ics_u: 8.011e-04, loss_ics_u_t: 4.103e-04, Loss_res: 1.612e-02 , Time: 54.08\n",
            "It: 34500, Loss: 1.898e-02,  loss_bc1: 4.363e-04,  loss_bc2: 4.957e-04, loss_ics_u: 5.527e-04, loss_ics_u_t: 1.678e-04, Loss_res: 4.135e-03 , Time: 54.31\n",
            "It: 34600, Loss: 3.093e-02,  loss_bc1: 4.328e-04,  loss_bc2: 4.924e-04, loss_ics_u: 7.638e-04, loss_ics_u_t: 3.791e-04, Loss_res: 1.404e-02 , Time: 52.71\n",
            "It: 34700, Loss: 1.891e-02,  loss_bc1: 4.173e-04,  loss_bc2: 4.770e-04, loss_ics_u: 5.406e-04, loss_ics_u_t: 1.655e-04, Loss_res: 4.561e-03 , Time: 48.21\n",
            "It: 34800, Loss: 1.820e-02,  loss_bc1: 4.086e-04,  loss_bc2: 4.686e-04, loss_ics_u: 5.335e-04, loss_ics_u_t: 1.636e-04, Loss_res: 4.096e-03 , Time: 48.59\n",
            "It: 34900, Loss: 1.805e-02,  loss_bc1: 3.998e-04,  loss_bc2: 4.601e-04, loss_ics_u: 5.308e-04, loss_ics_u_t: 1.651e-04, Loss_res: 4.144e-03 , Time: 48.92\n",
            "It: 35000, Loss: 1.783e-02,  loss_bc1: 3.917e-04,  loss_bc2: 4.518e-04, loss_ics_u: 5.296e-04, loss_ics_u_t: 1.692e-04, Loss_res: 4.098e-03 , Time: 49.45\n",
            "loss_bc1: 3.917e-01\n",
            "loss_bc2: 4.518e-01\n",
            "loss_ics_u: 5.296e-01\n",
            "lam_r_val: 4.098e+00\n",
            "It: 35100, Loss: 1.941e-02,  loss_bc1: 3.835e-04,  loss_bc2: 4.419e-04, loss_ics_u: 5.424e-04, loss_ics_u_t: 1.877e-04, Loss_res: 5.733e-03 , Time: 57.52\n",
            "It: 35200, Loss: 1.822e-02,  loss_bc1: 3.743e-04,  loss_bc2: 4.379e-04, loss_ics_u: 5.686e-04, loss_ics_u_t: 2.163e-04, Loss_res: 4.414e-03 , Time: 52.98\n",
            "It: 35300, Loss: 2.925e-02,  loss_bc1: 3.793e-04,  loss_bc2: 4.394e-04, loss_ics_u: 1.171e-03, loss_ics_u_t: 8.214e-04, Loss_res: 9.352e-03 , Time: 53.17\n",
            "It: 35400, Loss: 2.052e-02,  loss_bc1: 3.575e-04,  loss_bc2: 4.182e-04, loss_ics_u: 5.352e-04, loss_ics_u_t: 1.926e-04, Loss_res: 7.408e-03 , Time: 53.84\n",
            "It: 35500, Loss: 1.952e-02,  loss_bc1: 3.512e-04,  loss_bc2: 4.106e-04, loss_ics_u: 4.941e-04, loss_ics_u_t: 1.560e-04, Loss_res: 6.965e-03 , Time: 54.16\n",
            "It: 35600, Loss: 2.461e-02,  loss_bc1: 3.428e-04,  loss_bc2: 4.028e-04, loss_ics_u: 6.169e-04, loss_ics_u_t: 2.821e-04, Loss_res: 1.098e-02 , Time: 53.50\n",
            "It: 35700, Loss: 1.614e-02,  loss_bc1: 3.347e-04,  loss_bc2: 3.960e-04, loss_ics_u: 4.855e-04, loss_ics_u_t: 1.557e-04, Loss_res: 3.974e-03 , Time: 51.71\n",
            "It: 35800, Loss: 1.593e-02,  loss_bc1: 3.279e-04,  loss_bc2: 3.876e-04, loss_ics_u: 4.763e-04, loss_ics_u_t: 1.503e-04, Loss_res: 4.015e-03 , Time: 52.13\n",
            "It: 35900, Loss: 1.566e-02,  loss_bc1: 3.204e-04,  loss_bc2: 3.811e-04, loss_ics_u: 4.712e-04, loss_ics_u_t: 1.494e-04, Loss_res: 3.931e-03 , Time: 53.73\n",
            "It: 36000, Loss: 1.547e-02,  loss_bc1: 3.140e-04,  loss_bc2: 3.738e-04, loss_ics_u: 4.664e-04, loss_ics_u_t: 1.482e-04, Loss_res: 3.927e-03 , Time: 53.40\n",
            "loss_bc1: 3.140e-01\n",
            "loss_bc2: 3.738e-01\n",
            "loss_ics_u: 4.664e-01\n",
            "lam_r_val: 3.927e+00\n",
            "It: 36100, Loss: 1.526e-02,  loss_bc1: 3.068e-04,  loss_bc2: 3.675e-04, loss_ics_u: 4.617e-04, loss_ics_u_t: 1.475e-04, Loss_res: 3.902e-03 , Time: 56.66\n",
            "It: 36200, Loss: 1.515e-02,  loss_bc1: 3.007e-04,  loss_bc2: 3.604e-04, loss_ics_u: 4.559e-04, loss_ics_u_t: 1.454e-04, Loss_res: 3.977e-03 , Time: 56.30\n",
            "It: 36300, Loss: 1.533e-02,  loss_bc1: 2.948e-04,  loss_bc2: 3.553e-04, loss_ics_u: 4.842e-04, loss_ics_u_t: 1.773e-04, Loss_res: 3.985e-03 , Time: 57.86\n",
            "It: 36400, Loss: 1.643e-02,  loss_bc1: 2.883e-04,  loss_bc2: 3.490e-04, loss_ics_u: 4.734e-04, loss_ics_u_t: 1.696e-04, Loss_res: 5.321e-03 , Time: 52.60\n",
            "It: 36500, Loss: 1.468e-02,  loss_bc1: 2.825e-04,  loss_bc2: 3.405e-04, loss_ics_u: 4.457e-04, loss_ics_u_t: 1.457e-04, Loss_res: 3.988e-03 , Time: 52.67\n",
            "It: 36600, Loss: 1.444e-02,  loss_bc1: 2.757e-04,  loss_bc2: 3.358e-04, loss_ics_u: 4.435e-04, loss_ics_u_t: 1.473e-04, Loss_res: 3.890e-03 , Time: 52.99\n",
            "It: 36700, Loss: 1.423e-02,  loss_bc1: 2.710e-04,  loss_bc2: 3.290e-04, loss_ics_u: 4.376e-04, loss_ics_u_t: 1.443e-04, Loss_res: 3.857e-03 , Time: 51.61\n",
            "It: 36800, Loss: 1.400e-02,  loss_bc1: 2.651e-04,  loss_bc2: 3.239e-04, loss_ics_u: 4.280e-04, loss_ics_u_t: 1.383e-04, Loss_res: 3.832e-03 , Time: 50.88\n",
            "It: 36900, Loss: 1.381e-02,  loss_bc1: 2.599e-04,  loss_bc2: 3.180e-04, loss_ics_u: 4.237e-04, loss_ics_u_t: 1.372e-04, Loss_res: 3.798e-03 , Time: 50.95\n",
            "It: 37000, Loss: 1.366e-02,  loss_bc1: 2.543e-04,  loss_bc2: 3.133e-04, loss_ics_u: 4.191e-04, loss_ics_u_t: 1.358e-04, Loss_res: 3.794e-03 , Time: 51.09\n",
            "loss_bc1: 2.543e-01\n",
            "loss_bc2: 3.133e-01\n",
            "loss_ics_u: 4.191e-01\n",
            "lam_r_val: 3.794e+00\n",
            "It: 37100, Loss: 1.354e-02,  loss_bc1: 2.506e-04,  loss_bc2: 3.066e-04, loss_ics_u: 4.184e-04, loss_ics_u_t: 1.378e-04, Loss_res: 3.785e-03 , Time: 51.09\n",
            "It: 37200, Loss: 1.334e-02,  loss_bc1: 2.448e-04,  loss_bc2: 3.023e-04, loss_ics_u: 4.112e-04, loss_ics_u_t: 1.339e-04, Loss_res: 3.761e-03 , Time: 50.88\n",
            "It: 37300, Loss: 1.333e-02,  loss_bc1: 2.406e-04,  loss_bc2: 2.969e-04, loss_ics_u: 4.097e-04, loss_ics_u_t: 1.356e-04, Loss_res: 3.860e-03 , Time: 50.82\n",
            "It: 37400, Loss: 1.315e-02,  loss_bc1: 2.359e-04,  loss_bc2: 2.928e-04, loss_ics_u: 4.102e-04, loss_ics_u_t: 1.389e-04, Loss_res: 3.757e-03 , Time: 50.98\n",
            "It: 37500, Loss: 1.416e-02,  loss_bc1: 2.316e-04,  loss_bc2: 2.865e-04, loss_ics_u: 4.297e-04, loss_ics_u_t: 1.608e-04, Loss_res: 4.679e-03 , Time: 50.98\n",
            "It: 37600, Loss: 2.465e-02,  loss_bc1: 2.266e-04,  loss_bc2: 2.832e-04, loss_ics_u: 4.164e-04, loss_ics_u_t: 1.501e-04, Loss_res: 1.539e-02 , Time: 50.92\n",
            "It: 37700, Loss: 1.256e-02,  loss_bc1: 2.226e-04,  loss_bc2: 2.781e-04, loss_ics_u: 3.913e-04, loss_ics_u_t: 1.282e-04, Loss_res: 3.635e-03 , Time: 51.90\n",
            "It: 37800, Loss: 1.244e-02,  loss_bc1: 2.190e-04,  loss_bc2: 2.732e-04, loss_ics_u: 3.894e-04, loss_ics_u_t: 1.286e-04, Loss_res: 3.624e-03 , Time: 51.93\n",
            "It: 37900, Loss: 1.230e-02,  loss_bc1: 2.144e-04,  loss_bc2: 2.698e-04, loss_ics_u: 3.850e-04, loss_ics_u_t: 1.269e-04, Loss_res: 3.613e-03 , Time: 51.09\n",
            "It: 38000, Loss: 1.253e-02,  loss_bc1: 2.115e-04,  loss_bc2: 2.647e-04, loss_ics_u: 3.943e-04, loss_ics_u_t: 1.391e-04, Loss_res: 3.821e-03 , Time: 51.39\n",
            "loss_bc1: 2.115e-01\n",
            "loss_bc2: 2.647e-01\n",
            "loss_ics_u: 3.943e-01\n",
            "lam_r_val: 3.821e+00\n",
            "It: 38100, Loss: 1.202e-02,  loss_bc1: 2.073e-04,  loss_bc2: 2.606e-04, loss_ics_u: 3.773e-04, loss_ics_u_t: 1.242e-04, Loss_res: 3.570e-03 , Time: 51.73\n",
            "It: 38200, Loss: 1.195e-02,  loss_bc1: 2.030e-04,  loss_bc2: 2.570e-04, loss_ics_u: 3.743e-04, loss_ics_u_t: 1.236e-04, Loss_res: 3.605e-03 , Time: 51.95\n",
            "It: 38300, Loss: 1.179e-02,  loss_bc1: 2.000e-04,  loss_bc2: 2.528e-04, loss_ics_u: 3.714e-04, loss_ics_u_t: 1.232e-04, Loss_res: 3.546e-03 , Time: 51.35\n",
            "It: 38400, Loss: 1.280e-02,  loss_bc1: 1.972e-04,  loss_bc2: 2.514e-04, loss_ics_u: 4.305e-04, loss_ics_u_t: 1.838e-04, Loss_res: 4.014e-03 , Time: 51.65\n",
            "It: 38500, Loss: 1.152e-02,  loss_bc1: 1.928e-04,  loss_bc2: 2.455e-04, loss_ics_u: 3.639e-04, loss_ics_u_t: 1.203e-04, Loss_res: 3.503e-03 , Time: 51.90\n",
            "It: 38600, Loss: 1.143e-02,  loss_bc1: 1.896e-04,  loss_bc2: 2.417e-04, loss_ics_u: 3.624e-04, loss_ics_u_t: 1.208e-04, Loss_res: 3.492e-03 , Time: 52.06\n",
            "It: 38700, Loss: 1.161e-02,  loss_bc1: 1.856e-04,  loss_bc2: 2.390e-04, loss_ics_u: 3.604e-04, loss_ics_u_t: 1.212e-04, Loss_res: 3.765e-03 , Time: 50.32\n",
            "It: 38800, Loss: 1.120e-02,  loss_bc1: 1.831e-04,  loss_bc2: 2.347e-04, loss_ics_u: 3.555e-04, loss_ics_u_t: 1.185e-04, Loss_res: 3.471e-03 , Time: 49.48\n",
            "It: 38900, Loss: 1.107e-02,  loss_bc1: 1.799e-04,  loss_bc2: 2.312e-04, loss_ics_u: 3.518e-04, loss_ics_u_t: 1.167e-04, Loss_res: 3.440e-03 , Time: 47.63\n",
            "It: 39000, Loss: 1.119e-02,  loss_bc1: 1.769e-04,  loss_bc2: 2.282e-04, loss_ics_u: 3.501e-04, loss_ics_u_t: 1.169e-04, Loss_res: 3.636e-03 , Time: 47.51\n",
            "loss_bc1: 1.769e-01\n",
            "loss_bc2: 2.282e-01\n",
            "loss_ics_u: 3.501e-01\n",
            "lam_r_val: 3.636e+00\n",
            "It: 39100, Loss: 1.106e-02,  loss_bc1: 1.738e-04,  loss_bc2: 2.248e-04, loss_ics_u: 3.484e-04, loss_ics_u_t: 1.178e-04, Loss_res: 3.588e-03 , Time: 48.35\n",
            "It: 39200, Loss: 1.140e-02,  loss_bc1: 1.703e-04,  loss_bc2: 2.220e-04, loss_ics_u: 3.488e-04, loss_ics_u_t: 1.198e-04, Loss_res: 3.994e-03 , Time: 49.93\n",
            "It: 39300, Loss: 1.384e-02,  loss_bc1: 1.689e-04,  loss_bc2: 2.186e-04, loss_ics_u: 3.635e-04, loss_ics_u_t: 1.368e-04, Loss_res: 6.327e-03 , Time: 51.28\n",
            "It: 39400, Loss: 1.647e-02,  loss_bc1: 1.660e-04,  loss_bc2: 2.160e-04, loss_ics_u: 3.401e-04, loss_ics_u_t: 1.151e-04, Loss_res: 9.250e-03 , Time: 50.09\n",
            "It: 39500, Loss: 1.070e-02,  loss_bc1: 1.627e-04,  loss_bc2: 2.127e-04, loss_ics_u: 3.532e-04, loss_ics_u_t: 1.301e-04, Loss_res: 3.411e-03 , Time: 51.14\n",
            "It: 39600, Loss: 1.196e-02,  loss_bc1: 1.594e-04,  loss_bc2: 2.096e-04, loss_ics_u: 3.353e-04, loss_ics_u_t: 1.139e-04, Loss_res: 4.920e-03 , Time: 50.51\n",
            "It: 39700, Loss: 1.024e-02,  loss_bc1: 1.569e-04,  loss_bc2: 2.070e-04, loss_ics_u: 3.292e-04, loss_ics_u_t: 1.096e-04, Loss_res: 3.307e-03 , Time: 50.77\n",
            "It: 39800, Loss: 1.016e-02,  loss_bc1: 1.545e-04,  loss_bc2: 2.041e-04, loss_ics_u: 3.267e-04, loss_ics_u_t: 1.089e-04, Loss_res: 3.303e-03 , Time: 50.79\n",
            "It: 39900, Loss: 1.005e-02,  loss_bc1: 1.518e-04,  loss_bc2: 2.015e-04, loss_ics_u: 3.241e-04, loss_ics_u_t: 1.081e-04, Loss_res: 3.278e-03 , Time: 50.30\n",
            "elapsed: 2.19e+04\n",
            "Relative L2 error_u: 5.11e-02\n",
            "elapsed: 2.19e+04\n",
            "Relative L2 error_u: 5.11e-02\n",
            "\n",
            "\n",
            "Method:  full_batch\n",
            "\n",
            "average of time_list: 21897.446618318558\n",
            "average of error_u_list: 0.051065058102569644\n"
          ]
        }
      ],
      "source": [
        "# Define PINN model\n",
        "a = 0.5\n",
        "c = 2\n",
        "\n",
        "kernel_size = 300\n",
        "\n",
        "# Domain boundaries\n",
        "ics_coords = np.array([[0.0, 0.0],  [0.0, 1.0]])\n",
        "bc1_coords = np.array([[0.0, 0.0],  [1.0, 0.0]])\n",
        "bc2_coords = np.array([[0.0, 1.0],  [1.0, 1.0]])\n",
        "dom_coords = np.array([[0.0, 0.0],  [1.0, 1.0]])\n",
        "\n",
        "# Create initial conditions samplers\n",
        "ics_sampler = Sampler(2, ics_coords, lambda x: u(x, a, c), name='Initial Condition 1')\n",
        "\n",
        "# Create boundary conditions samplers\n",
        "bc1 = Sampler(2, bc1_coords, lambda x: u(x, a, c), name='Dirichlet BC1')\n",
        "bc2 = Sampler(2, bc2_coords, lambda x: u(x, a, c), name='Dirichlet BC2')\n",
        "bcs_sampler = [bc1, bc2]\n",
        "\n",
        "# Create residual sampler\n",
        "res_sampler = Sampler(2, dom_coords, lambda x: r(x, a, c), name='Forcing')\n",
        "\n",
        "\n",
        "\n",
        "nIter =40000\n",
        "bcbatch_size = 500\n",
        "ubatch_size = 5000\n",
        "mbbatch_size = 300\n",
        "\n",
        "\n",
        "\n",
        "# Define model\n",
        "mode = 'M4'\n",
        "layers = [2, 500, 500, 500, 1]\n",
        "\n",
        "\n",
        "nn = 200\n",
        "t = np.linspace(dom_coords[0, 0], dom_coords[1, 0], nn)[:, None]\n",
        "x = np.linspace(dom_coords[0, 1], dom_coords[1, 1], nn)[:, None]\n",
        "t, x = np.meshgrid(t, x)\n",
        "X_star = np.hstack((t.flatten()[:, None], x.flatten()[:, None]))\n",
        "\n",
        "u_star = u(X_star, a,c)\n",
        "r_star = r(X_star, a, c)\n",
        "\n",
        "iterations = 1\n",
        "methods = [  \"full_batch\"]\n",
        "\n",
        "result_dict =  dict((mtd, []) for mtd in methods)\n",
        "\n",
        "for mtd in methods:\n",
        "    print(\"Method: \", mtd)\n",
        "    time_list = []\n",
        "    error_u_list = []\n",
        "    \n",
        "    for index in range(iterations):\n",
        "\n",
        "        print(\"Epoch: \", str(index+1))\n",
        "\n",
        "        # Create residual sampler\n",
        "\n",
        "        [elapsed, error_u] = test_method(mtd , layers,  ics_sampler, bcs_sampler, res_sampler, c ,kernel_size , X_star , u_star , r_star , nIter ,mbbatch_size , bcbatch_size , ubatch_size )\n",
        "\n",
        "\n",
        "        print('elapsed: {:.2e}'.format(elapsed))\n",
        "        print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
        "\n",
        "        time_list.append(elapsed)\n",
        "        error_u_list.append(error_u)\n",
        "\n",
        "    print(\"\\n\\nMethod: \", mtd)\n",
        "    print(\"\\naverage of time_list:\" , sum(time_list) / len(time_list) )\n",
        "    print(\"average of error_u_list:\" , sum(error_u_list) / len(error_u_list) )\n",
        "    # print(\"average of error_r_list:\" , sum(error_r_list) / len(error_r_list) )\n",
        "\n",
        "    result_dict[mtd] = [time_list ,error_u_list]\n",
        "    # scipy.io.savemat(\"M2_result_\"+str(iterations)+\"_\"+mtd+\".mat\" , {'time_list':np.array(time_list),'error_u_list':np.array(error_u_list),'error_f_list':np.array(error_f_list)})\n",
        "\n",
        "    scipy.io.savemat(\"./1DWave_database/\"+mtd+\"_1Dwave_\"+mode+\"_result_mb\"+str(mbbatch_size)+\"_fb\"+str(ubatch_size)+\"_bc\"+str(mbbatch_size)+\"_\"+str(iterations)+\".mat\" , result_dict)\n",
        "\n",
        "###############################################################################################################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGFobW0EatXj"
      },
      "outputs": [],
      "source": [
        "# Define PINN model\n",
        "a = 0.5\n",
        "c = 2\n",
        "\n",
        "kernel_size = 300\n",
        "\n",
        "# Domain boundaries\n",
        "ics_coords = np.array([[0.0, 0.0],  [0.0, 1.0]])\n",
        "bc1_coords = np.array([[0.0, 0.0],  [1.0, 0.0]])\n",
        "bc2_coords = np.array([[0.0, 1.0],  [1.0, 1.0]])\n",
        "dom_coords = np.array([[0.0, 0.0],  [1.0, 1.0]])\n",
        "\n",
        "# Create initial conditions samplers\n",
        "ics_sampler = Sampler(2, ics_coords, lambda x: u(x, a, c), name='Initial Condition 1')\n",
        "\n",
        "# Create boundary conditions samplers\n",
        "bc1 = Sampler(2, bc1_coords, lambda x: u(x, a, c), name='Dirichlet BC1')\n",
        "bc2 = Sampler(2, bc2_coords, lambda x: u(x, a, c), name='Dirichlet BC2')\n",
        "bcs_sampler = [bc1, bc2]\n",
        "\n",
        "# Create residual sampler\n",
        "res_sampler = Sampler(2, dom_coords, lambda x: r(x, a, c), name='Forcing')\n",
        "\n",
        "\n",
        "\n",
        "nIter =40000\n",
        "bcbatch_size = 500\n",
        "ubatch_size = 5000\n",
        "mbbatch_size = 300\n",
        "\n",
        "\n",
        "\n",
        "# Define model\n",
        "mode = 'M4'\n",
        "layers = [2, 500, 500, 500, 1]\n",
        "\n",
        "\n",
        "nn = 200\n",
        "t = np.linspace(dom_coords[0, 0], dom_coords[1, 0], nn)[:, None]\n",
        "x = np.linspace(dom_coords[0, 1], dom_coords[1, 1], nn)[:, None]\n",
        "t, x = np.meshgrid(t, x)\n",
        "X_star = np.hstack((t.flatten()[:, None], x.flatten()[:, None]))\n",
        "\n",
        "u_star = u(X_star, a,c)\n",
        "r_star = r(X_star, a, c)\n",
        "\n",
        "iterations = 1\n",
        "methods = [  \"mini_batch\"]\n",
        "\n",
        "result_dict =  dict((mtd, []) for mtd in methods)\n",
        "\n",
        "for mtd in methods:\n",
        "    print(\"Method: \", mtd)\n",
        "    time_list = []\n",
        "    error_u_list = []\n",
        "    \n",
        "    for index in range(iterations):\n",
        "\n",
        "        print(\"Epoch: \", str(index+1))\n",
        "\n",
        "        # Create residual sampler\n",
        "\n",
        "        [elapsed, error_u] = test_method(mtd , layers,  ics_sampler, bcs_sampler, res_sampler, c ,kernel_size , X_star , u_star , r_star , nIter ,mbbatch_size , bcbatch_size , ubatch_size )\n",
        "\n",
        "\n",
        "        print('elapsed: {:.2e}'.format(elapsed))\n",
        "        print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
        "\n",
        "        time_list.append(elapsed)\n",
        "        error_u_list.append(error_u)\n",
        "\n",
        "    print(\"\\n\\nMethod: \", mtd)\n",
        "    print(\"\\naverage of time_list:\" , sum(time_list) / len(time_list) )\n",
        "    print(\"average of error_u_list:\" , sum(error_u_list) / len(error_u_list) )\n",
        "    # print(\"average of error_r_list:\" , sum(error_r_list) / len(error_r_list) )\n",
        "\n",
        "    result_dict[mtd] = [time_list ,error_u_list]\n",
        "    # scipy.io.savemat(\"M2_result_\"+str(iterations)+\"_\"+mtd+\".mat\" , {'time_list':np.array(time_list),'error_u_list':np.array(error_u_list),'error_f_list':np.array(error_f_list)})\n",
        "\n",
        "    scipy.io.savemat(\"./1DWave_database/\"+mtd+\"_1Dwave_\"+mode+\"_result_mb\"+str(mbbatch_size)+\"_fb\"+str(ubatch_size)+\"_bc\"+str(mbbatch_size)+\"_\"+str(iterations)+\".mat\" , result_dict)\n",
        "\n",
        "###############################################################################################################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define PINN model\n",
        "a = 0.5\n",
        "c = 2\n",
        "\n",
        "kernel_size = 300\n",
        "\n",
        "# Domain boundaries\n",
        "ics_coords = np.array([[0.0, 0.0],  [0.0, 1.0]])\n",
        "bc1_coords = np.array([[0.0, 0.0],  [1.0, 0.0]])\n",
        "bc2_coords = np.array([[0.0, 1.0],  [1.0, 1.0]])\n",
        "dom_coords = np.array([[0.0, 0.0],  [1.0, 1.0]])\n",
        "\n",
        "# Create initial conditions samplers\n",
        "ics_sampler = Sampler(2, ics_coords, lambda x: u(x, a, c), name='Initial Condition 1')\n",
        "\n",
        "# Create boundary conditions samplers\n",
        "bc1 = Sampler(2, bc1_coords, lambda x: u(x, a, c), name='Dirichlet BC1')\n",
        "bc2 = Sampler(2, bc2_coords, lambda x: u(x, a, c), name='Dirichlet BC2')\n",
        "bcs_sampler = [bc1, bc2]\n",
        "\n",
        "# Create residual sampler\n",
        "res_sampler = Sampler(2, dom_coords, lambda x: r(x, a, c), name='Forcing')\n",
        "\n",
        "\n",
        "\n",
        "nIter =40000\n",
        "bcbatch_size = 500\n",
        "ubatch_size = 5000\n",
        "mbbatch_size = 300\n",
        "\n",
        "\n",
        "\n",
        "# Define model\n",
        "mode = 'M4'\n",
        "layers = [2, 500, 500, 500, 1]\n",
        "\n",
        "\n",
        "nn = 200\n",
        "t = np.linspace(dom_coords[0, 0], dom_coords[1, 0], nn)[:, None]\n",
        "x = np.linspace(dom_coords[0, 1], dom_coords[1, 1], nn)[:, None]\n",
        "t, x = np.meshgrid(t, x)\n",
        "X_star = np.hstack((t.flatten()[:, None], x.flatten()[:, None]))\n",
        "\n",
        "u_star = u(X_star, a,c)\n",
        "r_star = r(X_star, a, c)\n",
        "\n",
        "iterations = 1\n",
        "methods = [  \"mini_batch\"]\n",
        "\n",
        "result_dict =  dict((mtd, []) for mtd in methods)\n",
        "\n",
        "for mtd in methods:\n",
        "    print(\"Method: \", mtd)\n",
        "    time_list = []\n",
        "    error_u_list = []\n",
        "    \n",
        "    for index in range(iterations):\n",
        "\n",
        "        print(\"Epoch: \", str(index+1))\n",
        "\n",
        "        # Create residual sampler\n",
        "\n",
        "        [elapsed, error_u] = test_method(mtd , layers,  ics_sampler, bcs_sampler, res_sampler, c ,kernel_size , X_star , u_star , r_star , nIter ,mbbatch_size , bcbatch_size , ubatch_size )\n",
        "\n",
        "\n",
        "        print('elapsed: {:.2e}'.format(elapsed))\n",
        "        print('Relative L2 error_u: {:.2e}'.format(error_u))\n",
        "\n",
        "        time_list.append(elapsed)\n",
        "        error_u_list.append(error_u)\n",
        "\n",
        "    print(\"\\n\\nMethod: \", mtd)\n",
        "    print(\"\\naverage of time_list:\" , sum(time_list) / len(time_list) )\n",
        "    print(\"average of error_u_list:\" , sum(error_u_list) / len(error_u_list) )\n",
        "    # print(\"average of error_r_list:\" , sum(error_r_list) / len(error_r_list) )\n",
        "\n",
        "    result_dict[mtd] = [time_list ,error_u_list]\n",
        "    # scipy.io.savemat(\"M2_result_\"+str(iterations)+\"_\"+mtd+\".mat\" , {'time_list':np.array(time_list),'error_u_list':np.array(error_u_list),'error_f_list':np.array(error_f_list)})\n",
        "\n",
        "    scipy.io.savemat(\"./1DWave_database/\"+mtd+\"_1Dwave_\"+mode+\"_result_mb\"+str(mbbatch_size)+\"_fb\"+str(ubatch_size)+\"_bc\"+str(mbbatch_size)+\"_\"+str(iterations)+\".mat\" , result_dict)\n",
        "\n",
        "###############################################################################################################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZtWEM9-brXF",
        "outputId": "371feba5-fed5-41cb-9e3e-5c8497c4fbe6"
      },
      "outputs": [],
      "source": [
        "\n",
        "import scipy.io\n",
        "\n",
        "mode = 'M4'\n",
        "mbbatch_size = 128\n",
        "ubatch_size = 5000\n",
        "bcbatch_size = 500\n",
        "iterations = 40000\n",
        "\n",
        "time_list = []\n",
        "error_u_list = []\n",
        "error_v_list = []\n",
        "error_p_list = []\n",
        "    \n",
        "methods = [\"mini_batch\" , \"full_batch\"]\n",
        "result_dict =  dict((mtd, []) for mtd in methods)\n",
        "\n",
        "##Mini Batch\n",
        "time_list = [3124.91]\n",
        "error_u_list = [ 0.0041]\n",
        "\n",
        "\n",
        "result_dict[\"mini_batch\"] = [time_list ,error_u_list]\n",
        "\n",
        "print(\"\\n\\nMethod: \", mtd)\n",
        "print(\"\\naverage of time_list:\" , sum(time_list) / len(time_list) )\n",
        "print(\"average of error_u_list:\" , sum(error_u_list) / len(error_u_list) )\n",
        "\n",
        "##Full Batch\n",
        "time_list = []\n",
        "error_u_list = [ ]\n",
        "error_v_list = []\n",
        "error_p_list = []\n",
        "\n",
        "result_dict[\"full_batch\"] = [time_list ,error_u_list ,error_v_list ,  error_p_list]\n",
        "\n",
        "print(\"\\n\\nMethod: \", mtd)\n",
        "print(\"\\naverage of time_list:\" , sum(time_list) / len(time_list) )\n",
        "print(\"average of error_u_list:\" , sum(error_u_list) / len(error_u_list) )\n",
        "print(\"average of error_v_list:\" , sum(error_v_list) / len(error_v_list) )\n",
        "print(\"average of error_p_list:\" , sum(error_p_list) / len(error_p_list) )\n",
        "\n",
        "\n",
        "scipy.io.savemat(\"./dataset/NS_model_\"+mode+\"_result_mb\"+str(mbbatch_size)+\"_fb\"+str(ubatch_size)+\"_\"+str(bcbatch_size)+\"_\"+str(iterations)+\".mat\" , result_dict)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vF1hwPUobyPE"
      },
      "outputs": [],
      "source": [
        "# Train model\n",
        "itertaions = 80001\n",
        "log_NTK = True # Compute and store NTK matrix during training\n",
        "update_lam = True # Compute and update the loss weights using the NTK \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiyikOwBjRoZ"
      },
      "source": [
        "**Training Loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "Fw807UNzhu5z",
        "outputId": "f4551313-ffbc-49b5-8fd3-1296fc1641fe"
      },
      "outputs": [],
      "source": [
        "loss_res = model.loss_res_log\n",
        "loss_bcs = model.loss_bcs_log\n",
        "loss_u_t_ics = model.loss_ut_ics_log\n",
        "\n",
        "fig = plt.figure(figsize=(6, 5))\n",
        "plt.plot(loss_res, label='$\\mathcal{L}_{r}$')\n",
        "plt.plot(loss_bcs, label='$\\mathcal{L}_{u}$')\n",
        "plt.plot(loss_u_t_ics, label='$\\mathcal{L}_{u_t}$')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFLIBq5xjZ3v"
      },
      "source": [
        "**Model Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "To0PDN17cc0v",
        "outputId": "1f47f288-322a-46b5-f173-45485191a68d"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Predictions\n",
        "u_pred = model.predict_u(X_star)\n",
        "r_pred = model.predict_r(X_star)\n",
        "error_u = np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
        "\n",
        "print('Relative L2 error_u: %e' % (error_u))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "id": "K428lOuXhdc8",
        "outputId": "015f591b-d8a4-4e47-8020-84fcf219d7ca"
      },
      "outputs": [],
      "source": [
        "U_star = griddata(X_star, u_star.flatten(), (t, x), method='cubic')\n",
        "r_star = griddata(X_star, r_star.flatten(), (t, x), method='cubic')\n",
        "U_pred = griddata(X_star, u_pred.flatten(), (t, x), method='cubic')\n",
        "R_pred = griddata(X_star, r_pred.flatten(), (t, x), method='cubic')\n",
        "\n",
        "\n",
        "plt.figure(figsize=(18, 9))\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.pcolor(t, x, U_star, cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$x_1$')\n",
        "plt.ylabel('$x_2$')\n",
        "plt.title('Exact u(t, x)')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.pcolor(t, x, U_pred, cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$t$')\n",
        "plt.ylabel('$x$')\n",
        "plt.title('Predicted u(t, x)')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.pcolor(t, x, np.abs(U_star - U_pred), cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$t$')\n",
        "plt.ylabel('$x$')\n",
        "plt.title('Absolute error')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(2, 3, 4)\n",
        "plt.pcolor(t, x, r_star, cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$t$')\n",
        "plt.ylabel('$x$')\n",
        "plt.title('Exact r(t, x)')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(2, 3, 5)\n",
        "plt.pcolor(t, x, R_pred, cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$t$')\n",
        "plt.ylabel('$x$')\n",
        "plt.title('Predicted r(t, x)')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(2, 3, 6)\n",
        "plt.pcolor(t, x, np.abs(r_star - R_pred), cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('$t$')\n",
        "plt.ylabel('$x$')\n",
        "plt.title('Absolute error')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EYdfKGLj6h0"
      },
      "source": [
        "**NTK Eigenvalues**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3dByeQjhBYj"
      },
      "outputs": [],
      "source": [
        "# Create empty lists for storing the eigenvalues of NTK\n",
        "lam_K_u_log = []\n",
        "lam_K_ut_log = []\n",
        "lam_K_r_log = []\n",
        "\n",
        "# Restore the NTK\n",
        "K_u_list = model.K_u_log\n",
        "K_ut_list = model.K_ut_log\n",
        "K_r_list = model.K_r_log\n",
        "\n",
        "K_list = []\n",
        "    \n",
        "for k in range(len(K_u_list)):\n",
        "    K_u = K_u_list[k]\n",
        "    K_ut = K_ut_list[k]\n",
        "    K_r = K_r_list[k]\n",
        "    \n",
        "    # Compute eigenvalues\n",
        "    lam_K_u, _ = np.linalg.eig(K_u)\n",
        "    lam_K_ut, _ = np.linalg.eig(K_ut)\n",
        "    lam_K_r, _ = np.linalg.eig(K_r)\n",
        "    # Sort in descresing order\n",
        "    lam_K_u = np.sort(np.real(lam_K_u))[::-1]\n",
        "    lam_K_ut = np.sort(np.real(lam_K_ut))[::-1]\n",
        "    lam_K_r = np.sort(np.real(lam_K_r))[::-1]\n",
        "    \n",
        "    # Store eigenvalues\n",
        "    lam_K_u_log.append(lam_K_u)\n",
        "    lam_K_ut_log.append(lam_K_ut)\n",
        "    lam_K_r_log.append(lam_K_r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "vSn3Q_1IhisN",
        "outputId": "886908b3-c316-48d6-933f-81b1180ff954"
      },
      "outputs": [],
      "source": [
        "#  Eigenvalues of NTK\n",
        "fig = plt.figure(figsize=(18, 5))\n",
        "plt.subplot(1,3,1)\n",
        "\n",
        "plt.plot(lam_K_u_log[0], label = '$n=0$')\n",
        "plt.plot(lam_K_u_log[1], '--', label = '$n=10,000$')\n",
        "plt.plot(lam_K_u_log[4], '--', label = '$n=40,000$')\n",
        "plt.plot(lam_K_u_log[-1], '--', label = '$n=80,000$')\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "\n",
        "plt.title(r'Eigenvalues of ${K}_u$')\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.plot(lam_K_ut_log[0], label = '$n=0$')\n",
        "plt.plot(lam_K_ut_log[1], '--',label = '$n=10,000$')\n",
        "plt.plot(lam_K_ut_log[4], '--', label = '$n=40,000$')\n",
        "plt.plot(lam_K_ut_log[-1], '--', label = '$n=80,000$')\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.title(r'Eigenvalues of ${K}_{u_t}$')\n",
        "\n",
        "ax =plt.subplot(1,3,3)\n",
        "plt.plot(lam_K_r_log[0], label = '$n=0$')\n",
        "plt.plot(lam_K_r_log[1], '--', label = '$n=10,000$')\n",
        "plt.plot(lam_K_r_log[4], '--', label = '$n=40,000$')\n",
        "plt.plot(lam_K_r_log[-1], '--', label = '$n=80,000$')\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.title(r'Eigenvalues of ${K}_{r}$')\n",
        "handles, labels = ax.get_legend_handles_labels()\n",
        "fig.legend(handles, labels, loc=\"upper left\", bbox_to_anchor=(0.35, -0.02),\n",
        "            borderaxespad=0, bbox_transform=fig.transFigure, ncol=4)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbUn_fcowojl"
      },
      "source": [
        "**Evolution of NTK Weights**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYbzkhfMjJ8k"
      },
      "outputs": [],
      "source": [
        "if update_lam == True:\n",
        "\n",
        "  lam_u_log = model.lam_u_log\n",
        "  lam_ut_log = model.lam_ut_log\n",
        "  lam_r_log = model.lam_r_log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "xzFzPCA2w1ML",
        "outputId": "71452cf9-3ebb-4aeb-9708-c7664b88e65d"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(6, 5))\n",
        "plt.plot(lam_u_log, label='$\\lambda_u$')\n",
        "plt.plot(lam_ut_log, label='$\\lambda_{u_t}$')\n",
        "plt.plot(lam_r_log, label='$\\lambda_{r}$')\n",
        "plt.xlabel('iterations')\n",
        "plt.ylabel('$\\lambda$')\n",
        "plt.yscale('log')\n",
        "plt.legend( )\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mimIv2Z5xlip"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PINNsNTK_Wave.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
